{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/utensil/llm-playground/blob/main/notebooks/axolotl/colab/axolotl-falcon-40b-qlora-prepare_ds_only.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97yoSiRvDY7G"
      },
      "source": [
        "# Prepare dataset (on Colab) for Finetuning falcon-40b\n",
        "\n",
        "- Axolotl+QLoRA\n",
        "- minotaur datasets\n",
        "- deepspeed ZeRO 3 8xGPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCpbQuaxDY7H"
      },
      "source": [
        "<!-- https://jupyterlab.readthedocs.io/en/stable/user/commands.html#commands-list -->\n",
        "<button data-commandLinker-command=\"apputils:change-theme\" data-commandlinker-args='{\"theme\": \"JupyterLab Dark\"}' href=\"#\">Dark theme</button>\n",
        "<button data-commandLinker-command=\"filebrowser:go-to-path\" data-commandlinker-args='{\"path\": \"/workspace/llm-playground/\"}' href=\"#\">llm-playground</button>\n",
        "<button data-commandLinker-command=\"filebrowser:go-to-path\" data-commandlinker-args='{\"path\": \"/workspace/axolotl/\"}' href=\"#\">axolotl</button>\n",
        "<button data-commandLinker-command=\"filebrowser:go-to-path\" data-commandlinker-args='{\"path\": \"/workspace/llm-playground/notebooks/axolotl/runpod\"}' href=\"#\">Runpod notebooks</button>\n",
        "<button data-commandLinker-command=\"filebrowser:go-to-path\" data-commandlinker-args='{\"path\": \"/workspace/axolotl/examples\"}' href=\"#\">axolotl configs</button>\n",
        "<button data-commandLinker-command=\"filebrowser:go-to-path\" data-commandlinker-args='{\"path\": \"/workspace/llm-playground/storage\"}' href=\"#\">Storage</button>\n",
        "<button data-commandLinker-command=\"filebrowser:go-to-path\" data-commandlinker-args='{\"path\": \"/workspace/llm-playground/axolotl-trained\"}' href=\"#\">axolotl-trained</button>\n",
        "<button data-commandLinker-command=\"docmanager:open\" data-commandlinker-args='{\"path\": \"/workspace/axolotl/examples/falcon/config-40b-qlora.yml\"}' href=\"#\">Edit config</button>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICK_4OyeQdfn",
        "outputId": "d366b1af-f189-47af-9675-97f00587dc9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'axolotl'...\n",
            "remote: Enumerating objects: 2985, done.\u001b[K\n",
            "remote: Counting objects: 100% (1179/1179), done.\u001b[K\n",
            "remote: Compressing objects: 100% (294/294), done.\u001b[K\n",
            "remote: Total 2985 (delta 976), reused 978 (delta 849), pack-reused 1806\n",
            "Receiving objects: 100% (2985/2985), 1.39 MiB | 7.16 MiB/s, done.\n",
            "Resolving deltas: 100% (1866/1866), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/OpenAccess-AI-Collective/axolotl.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_P9uKMPoOFh6",
        "outputId": "1f1714ef-5bdd-4fbb-e65f-33c61883c642"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/workspace/axolotl\n"
          ]
        }
      ],
      "source": [
        "%cd /workspace/axolotl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hb4i9d9gQydE",
        "outputId": "700a2abf-5bf4-47b6-840c-780528e73ba3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Obtaining file:///content/axolotl/axolotl\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting transformers@ git+https://github.com/huggingface/transformers.git (from axolotl==0.1)\n",
            "  Cloning https://github.com/huggingface/transformers.git to /tmp/pip-install-diw4f8uk/transformers_6a8d81c3f7f0475a8a770fa4ed3a9678\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git /tmp/pip-install-diw4f8uk/transformers_6a8d81c3f7f0475a8a770fa4ed3a9678\n",
            "  Resolved https://github.com/huggingface/transformers.git to commit 8f093fb799246f7dd9104ff44728da0c53a9f67a\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: bitsandbytes>=0.39.0 in /usr/local/lib/python3.10/dist-packages (from axolotl==0.1) (0.39.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (from axolotl==0.1) (0.20.3)\n",
            "Requirement already satisfied: addict in /usr/local/lib/python3.10/dist-packages (from axolotl==0.1) (2.4.0)\n",
            "Requirement already satisfied: fire in /usr/local/lib/python3.10/dist-packages (from axolotl==0.1) (0.5.0)\n",
            "Requirement already satisfied: PyYAML==6.0 in /usr/local/lib/python3.10/dist-packages (from axolotl==0.1) (6.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from axolotl==0.1) (2.12.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from axolotl==0.1) (0.1.99)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (from axolotl==0.1) (0.15.4)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from axolotl==0.1) (0.6.1)\n",
            "Requirement already satisfied: xformers in /usr/local/lib/python3.10/dist-packages (from axolotl==0.1) (0.0.20)\n",
            "Requirement already satisfied: bert-score==0.3.13 in /usr/local/lib/python3.10/dist-packages (from axolotl==0.1) (0.3.13)\n",
            "Requirement already satisfied: evaluate==0.4.0 in /usr/local/lib/python3.10/dist-packages (from axolotl==0.1) (0.4.0)\n",
            "Requirement already satisfied: rouge-score==0.1.2 in /usr/local/lib/python3.10/dist-packages (from axolotl==0.1) (0.1.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from axolotl==0.1) (1.10.1)\n",
            "Requirement already satisfied: scikit-learn==1.2.2 in /usr/local/lib/python3.10/dist-packages (from axolotl==0.1) (1.2.2)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from bert-score==0.3.13->axolotl==0.1) (2.0.1+cu118)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from bert-score==0.3.13->axolotl==0.1) (1.5.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bert-score==0.3.13->axolotl==0.1) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from bert-score==0.3.13->axolotl==0.1) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.10/dist-packages (from bert-score==0.3.13->axolotl==0.1) (4.65.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from bert-score==0.3.13->axolotl==0.1) (3.7.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from bert-score==0.3.13->axolotl==0.1) (23.1)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate==0.4.0->axolotl==0.1) (0.3.6)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate==0.4.0->axolotl==0.1) (3.2.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate==0.4.0->axolotl==0.1) (0.70.14)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate==0.4.0->axolotl==0.1) (2023.4.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate==0.4.0->axolotl==0.1) (0.15.1)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.10/dist-packages (from evaluate==0.4.0->axolotl==0.1) (0.18.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge-score==0.1.2->axolotl==0.1) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge-score==0.1.2->axolotl==0.1) (3.8.1)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge-score==0.1.2->axolotl==0.1) (1.16.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.2.2->axolotl==0.1) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.2.2->axolotl==0.1) (3.1.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate->axolotl==0.1) (5.9.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->axolotl==0.1) (9.0.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->axolotl==0.1) (3.8.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers@ git+https://github.com/huggingface/transformers.git->axolotl==0.1) (3.12.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers@ git+https://github.com/huggingface/transformers.git->axolotl==0.1) (2022.10.31)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers@ git+https://github.com/huggingface/transformers.git->axolotl==0.1) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers@ git+https://github.com/huggingface/transformers.git->axolotl==0.1) (0.3.1)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire->axolotl==0.1) (2.3.0)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.10/dist-packages (from wandb->axolotl==0.1) (8.1.3)\n",
            "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->axolotl==0.1) (3.1.31)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->axolotl==0.1) (1.25.1)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb->axolotl==0.1) (0.4.0)\n",
            "Requirement already satisfied: pathtools in /usr/local/lib/python3.10/dist-packages (from wandb->axolotl==0.1) (0.1.2)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb->axolotl==0.1) (1.3.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb->axolotl==0.1) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb->axolotl==0.1) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb->axolotl==0.1) (3.20.3)\n",
            "Requirement already satisfied: pyre-extensions==0.0.29 in /usr/local/lib/python3.10/dist-packages (from xformers->axolotl==0.1) (0.0.29)\n",
            "Requirement already satisfied: typing-inspect in /usr/local/lib/python3.10/dist-packages (from pyre-extensions==0.0.29->xformers->axolotl==0.1) (0.9.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from pyre-extensions==0.0.29->xformers->axolotl==0.1) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score==0.3.13->axolotl==0.1) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score==0.3.13->axolotl==0.1) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score==0.3.13->axolotl==0.1) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score==0.3.13->axolotl==0.1) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.0.0->bert-score==0.3.13->axolotl==0.1) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.0.0->bert-score==0.3.13->axolotl==0.1) (16.0.5)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->axolotl==0.1) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->axolotl==0.1) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->axolotl==0.1) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->axolotl==0.1) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->axolotl==0.1) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->axolotl==0.1) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->axolotl==0.1) (1.3.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from GitPython!=3.1.29,>=1.0.0->wandb->axolotl==0.1) (4.0.10)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert-score==0.3.13->axolotl==0.1) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert-score==0.3.13->axolotl==0.1) (2022.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score==0.3.13->axolotl==0.1) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score==0.3.13->axolotl==0.1) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score==0.3.13->axolotl==0.1) (3.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score==0.3.13->axolotl==0.1) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score==0.3.13->axolotl==0.1) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score==0.3.13->axolotl==0.1) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score==0.3.13->axolotl==0.1) (1.4.4)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score==0.3.13->axolotl==0.1) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score==0.3.13->axolotl==0.1) (3.0.9)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb->axolotl==0.1) (5.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.0.0->bert-score==0.3.13->axolotl==0.1) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.0.0->bert-score==0.3.13->axolotl==0.1) (1.3.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect->pyre-extensions==0.0.29->xformers->axolotl==0.1) (1.0.0)\n",
            "Installing collected packages: axolotl\n",
            "  Attempting uninstall: axolotl\n",
            "    Found existing installation: axolotl 0.1\n",
            "    Uninstalling axolotl-0.1:\n",
            "      Successfully uninstalled axolotl-0.1\n",
            "  Running setup.py develop for axolotl\n",
            "Successfully installed axolotl-0.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/huggingface/peft.git\n",
            "  Cloning https://github.com/huggingface/peft.git to /tmp/pip-req-build-40kxgx4y\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/peft.git /tmp/pip-req-build-40kxgx4y\n",
            "  Resolved https://github.com/huggingface/peft.git to commit 189a6b8e357ecda05ccde13999e4c35759596a67\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from peft==0.4.0.dev0) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from peft==0.4.0.dev0) (23.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft==0.4.0.dev0) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from peft==0.4.0.dev0) (6.0)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft==0.4.0.dev0) (2.0.1+cu118)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from peft==0.4.0.dev0) (4.31.0.dev0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (from peft==0.4.0.dev0) (0.20.3)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft==0.4.0.dev0) (0.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.4.0.dev0) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.4.0.dev0) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.4.0.dev0) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.4.0.dev0) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.4.0.dev0) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.4.0.dev0) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.13.0->peft==0.4.0.dev0) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.13.0->peft==0.4.0.dev0) (16.0.5)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers->peft==0.4.0.dev0) (0.15.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->peft==0.4.0.dev0) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers->peft==0.4.0.dev0) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers->peft==0.4.0.dev0) (0.13.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers->peft==0.4.0.dev0) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers->peft==0.4.0.dev0) (2023.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft==0.4.0.dev0) (2.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->peft==0.4.0.dev0) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->peft==0.4.0.dev0) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->peft==0.4.0.dev0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->peft==0.4.0.dev0) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->peft==0.4.0.dev0) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install -e .\n",
        "!pip install -U git+https://github.com/huggingface/peft.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "3d420532df0e438da7d94ab32e6ebb22",
            "0dd2b6777bec401b867867a5cdbedd23",
            "064dc7a36e3141a7bda70adb723791f4",
            "d3e29b6ef6ab49e987c284dec6a9aedb",
            "8c56af0ee49c4992a2644ad1ff3c0404",
            "e470289f17114e4cb76f7d3e2b755ad7",
            "54ac694cc9a34de2afcc4077b6611936",
            "c62beb828d2f4c1ca13e50736d817232",
            "cd9a2b859a05461f9ddee1ad98d77bf5",
            "16b9ed34f3494401b5bbd8103b67097a",
            "5c68d498914448cda16a6a1d37be1780",
            "79bb8e0094ff4b6d85460391781309b4",
            "c1f0fd41f0b54a59be62e086db7459c3",
            "f8d0567cf49b498092a965abbe041133",
            "6ad4144260cb4733933947fd26bfbc25",
            "8ea6ca6af7a04e7cba7b93eda06ae420",
            "13def2c1464a4eada87d139eaaf8773e",
            "57bf0e73135643b09821981f1bcbd971",
            "5654a4fc9e1a4cf9b48d233329fe3c75",
            "3440a93ed74749358bae76d2bd8861ab",
            "6f7e6381b6fd4301a3ddf02d351caa50",
            "99aab7f417784805a2b7c94e7a9d549f",
            "6effd08048af4f1091973d4b5dc74694",
            "1cb197ba0137492fb8e953b05d73d0d7",
            "febd7a732c4e408cbde580a1c8db57f0",
            "c30292fd334143c3803cfbb69cf9a67f",
            "608f3bf410e942b887c138de6429c2a1",
            "07e43ba6fbe44f2b94fab16e970d3a02",
            "34b6dd2b7e264c2394bb1d79a05bc065",
            "29a22c57ce28449cbb062b493124c68c",
            "89273b45582947faa13889eed2a04ff6",
            "ba4c7ffae5e8419ba99e126666148b49",
            "db970e6ef6154bef98116a5bf180c7f0"
          ]
        },
        "id": "APgdb2JHO8FV",
        "outputId": "f6385a91-95cd-45a5-9a45-6ec85c0bfe58"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "db970e6ef6154bef98116a5bf180c7f0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wWw91DLOC_l"
      },
      "source": [
        "# gsm8k"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMV1BTs_OJYu",
        "outputId": "fd4609c0-e0fb-472f-cc58-8556b025629c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting examples/falcon/config-40b-qlora.yml\n"
          ]
        }
      ],
      "source": [
        "%%writefile examples/falcon/config-40b-qlora.yml\n",
        "# 1b: tiiuae/falcon-rw-1b\n",
        "# 7b: tiiuae/falcon-7b\n",
        "# 40b: tiiuae/falcon-40b\n",
        "base_model: tiiuae/falcon-40b\n",
        "base_model_config: tiiuae/falcon-40b\n",
        "# required by falcon custom model code: https://huggingface.co/tiiuae/falcon-7b/tree/main\n",
        "trust_remote_code: true\n",
        "model_type: AutoModelForCausalLM\n",
        "tokenizer_type: AutoTokenizer\n",
        "load_in_8bit: false\n",
        "# enable 4bit for QLoRA\n",
        "load_in_4bit: true\n",
        "gptq: false\n",
        "strict: false\n",
        "\n",
        "push_dataset_to_hub: utensil\n",
        "hf_use_auth_token: true\n",
        "\n",
        "datasets:\n",
        "  - path: QingyiSi/Alpaca-CoT\n",
        "    data_files:\n",
        "      - Chain-of-Thought/formatted_cot_data/gsm8k_train.json\n",
        "    type: \"alpaca:chat\"\n",
        "\n",
        "dataset_prepared_path: last_run_prepared\n",
        "val_set_size: 0.01\n",
        "# enable QLoRA\n",
        "adapter: qlora\n",
        "lora_model_dir:\n",
        "sequence_len: 2048\n",
        "max_packed_sequence_len:\n",
        "\n",
        "# hyperparameters from QLoRA paper Appendix B.2\n",
        "# \"We find hyperparameters to be largely robust across datasets\"\n",
        "lora_r: 64\n",
        "lora_alpha: 16\n",
        "# 0.1 for models up to 13B\n",
        "# 0.05 for 33B and 65B models\n",
        "lora_dropout: 0.05\n",
        "# add LoRA modules on all linear layers of the base model\n",
        "lora_target_modules:\n",
        "lora_target_linear: true\n",
        "lora_fan_in_fan_out:\n",
        "\n",
        "wandb_project: falcon-qlora\n",
        "wandb_watch:\n",
        "wandb_run_id:\n",
        "wandb_log_model:\n",
        "output_dir: /workspace/llm-playground/axolotl-trained/falcon-qlora-40b-gsm8k/\n",
        "\n",
        "# QLoRA paper Table 9\n",
        "# - 16 for 7b & 13b\n",
        "# - 32 for 33b, 64 for 64b\n",
        "# Max size tested on A6000\n",
        "# - 7b: 40\n",
        "# - 40b: 4\n",
        "# decrease if OOM, increase for max VRAM utilization\n",
        "micro_batch_size: 1\n",
        "gradient_accumulation_steps: 2\n",
        "num_epochs: 3\n",
        "# Optimizer for QLoRA\n",
        "optimizer: paged_adamw_32bit\n",
        "torchdistx_path:\n",
        "lr_scheduler: cosine\n",
        "# QLoRA paper Table 9\n",
        "# - 2e-4 for 7b & 13b\n",
        "# - 1e-4 for 33b & 64b\n",
        "learning_rate: 0.0002\n",
        "train_on_inputs: false\n",
        "group_by_length: false\n",
        "bf16: true\n",
        "fp16: false\n",
        "tf32: true\n",
        "gradient_checkpointing: true\n",
        "# stop training after this many evaluation losses have increased in a row\n",
        "# https://huggingface.co/transformers/v4.2.2/_modules/transformers/trainer_callback.html#EarlyStoppingCallback\n",
        "early_stopping_patience: 3\n",
        "resume_from_checkpoint:\n",
        "auto_resume_from_checkpoints: true\n",
        "local_rank:\n",
        "logging_steps: 1\n",
        "xformers_attention: true\n",
        "flash_attention:\n",
        "gptq_groupsize:\n",
        "gptq_model_v1:\n",
        "warmup_steps: 10\n",
        "eval_steps: 5\n",
        "save_steps: 10\n",
        "debug:\n",
        "deepspeed:\n",
        "weight_decay: 0.01\n",
        "fsdp:\n",
        "fsdp_config:\n",
        "special_tokens:\n",
        "  pad_token: \"<|endoftext|>\"\n",
        "  bos_token: \">>ABSTRACT<<\"\n",
        "  eos_token: \"<|endoftext|>\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aY3eLpM2OMzM",
        "outputId": "182d6c73-0162-4ca6-e5ab-204816a7bdfc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "===================================BUG REPORT===================================\n",
            "Welcome to bitsandbytes. For bug reports, please run\n",
            "\n",
            "python -m bitsandbytes\n",
            "\n",
            " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
            "================================================================================\n",
            "bin /usr/local/lib/python3.10/dist-packages/bitsandbytes/libbitsandbytes_cuda118.so\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: /usr/lib64-nvidia did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/sys/fs/cgroup/memory.events /var/colab/cgroup/jupyter-children/memory.events')}\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('http'), PosixPath('//172.28.0.1'), PosixPath('8013')}\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('--logtostderr --listen_host=172.28.0.12 --target_host=172.28.0.12 --tunnel_background_save_url=https'), PosixPath('//colab.research.google.com/tun/m/cc48301118ce562b961b3c22d803539adc1e0c19/gpu-t4-s-3qu49qpehlmmz --tunnel_background_save_delay=10s --tunnel_periodic_background_save_frequency=30m0s --enable_output_coalescing=true --output_coalescing_required=true')}\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/env/python')}\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('//ipykernel.pylab.backend_inline'), PosixPath('module')}\n",
            "  warn(msg)\n",
            "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching in backup paths...\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: Found duplicate ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] files: {PosixPath('/usr/local/cuda/lib64/libcudart.so.11.0'), PosixPath('/usr/local/cuda/lib64/libcudart.so')}.. We'll flip a coin and try one of these, in order to fail forward.\n",
            "Either way, this might cause trouble in the future:\n",
            "If you get `CUDA error: invalid device function` errors, the above might be the cause and the solution is to make sure only one ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] in the paths that we search based on your env.\n",
            "  warn(msg)\n",
            "CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so.11.0\n",
            "CUDA SETUP: Highest compute capability among GPUs detected: 7.5\n",
            "CUDA SETUP: Detected CUDA version 118\n",
            "CUDA SETUP: Loading binary /usr/local/lib/python3.10/dist-packages/bitsandbytes/libbitsandbytes_cuda118.so...\n",
            "2023-06-12 06:45:03.959717: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "WARNING:root:`trust_remote_code` is set to true. Please make sure that you reviewed the remote code/model.\n",
            "INFO:root:loading tokenizer... tiiuae/falcon-40b\n",
            "Using bos_token, but it is not set yet.\n",
            "Using pad_token, but it is not set yet.\n",
            "Using unk_token, but it is not set yet.\n",
            "INFO:root:Unable to find prepared dataset in last_run_prepared/31a4e867d804a957707db033c9abcd13\n",
            "INFO:root:Loading raw datasets...\n",
            "INFO:root:No seed provided, using default seed of 42\n",
            "WARNING:datasets.builder:Found cached dataset json (/root/.cache/huggingface/datasets/QingyiSi___json/QingyiSi--Alpaca-CoT-2953efcfeb19f105/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\n",
            "100% 1/1 [00:00<00:00, 748.85it/s]\n",
            "INFO:root:tokenizing, merging, and shuffling master dataset\n",
            "INFO:root:Saving merged prepared dataset to disk... last_run_prepared/31a4e867d804a957707db033c9abcd13\n",
            "INFO:root:Saving merged prepared dataset with push_to_hub... utensil/31a4e867d804a957707db033c9abcd13\n",
            "Pushing dataset shards to the dataset hub:   0% 0/1 [00:00<?, ?it/s]\n",
            "Creating parquet from Arrow format:   0% 0/8 [00:00<?, ?ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  38% 3/8 [00:00<00:00, 21.31ba/s]\u001b[A\n",
            "Creating parquet from Arrow format: 100% 8/8 [00:00<00:00, 22.66ba/s]\n",
            "\n",
            "Upload 1 LFS files:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Upload 1 LFS files: 100% 1/1 [00:00<00:00,  1.87it/s]\n",
            "Pushing dataset shards to the dataset hub: 100% 1/1 [00:01<00:00,  1.25s/it]\n",
            "INFO:root:Finished preparing dataset. Exiting...\n"
          ]
        }
      ],
      "source": [
        "!python scripts/finetune.py examples/falcon/config-40b-qlora.yml -prepare_ds_only"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XjMcoRRWSci-"
      },
      "outputs": [],
      "source": [
        "!rm -rf /content/axolotl/last_run_prepared"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2ko6jJPfTFD"
      },
      "source": [
        "# minotaur\n",
        "\n",
        "Datasets from https://huggingface.co/openaccess-ai-collective/minotaur-13b/blob/main/configs/minotaur.yml\n",
        "\n",
        "Plus [this fix](https://discord.com/channels/1104757954588196865/1116465236715786310/1117778180372185149)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2yxeT32XJ_c",
        "outputId": "a6f296b2-31de-4ee7-b0ae-81e6702adeb6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing examples/falcon/config-40b-qlora.yml\n"
          ]
        }
      ],
      "source": [
        "%%writefile examples/falcon/config-40b-qlora.yml\n",
        "# 1b: tiiuae/falcon-rw-1b\n",
        "# 7b: tiiuae/falcon-7b\n",
        "# 40b: tiiuae/falcon-40b\n",
        "base_model: tiiuae/falcon-40b\n",
        "base_model_config: tiiuae/falcon-40b\n",
        "# required by falcon custom model code: https://huggingface.co/tiiuae/falcon-7b/tree/main\n",
        "trust_remote_code: true\n",
        "model_type: AutoModelForCausalLM\n",
        "tokenizer_type: AutoTokenizer\n",
        "load_in_8bit: false\n",
        "# enable 4bit for QLoRA\n",
        "load_in_4bit: true\n",
        "gptq: false\n",
        "strict: false\n",
        "\n",
        "push_dataset_to_hub: utensil\n",
        "hf_use_auth_token: true\n",
        "\n",
        "datasets:\n",
        "  - path: winglian/evals\n",
        "    data_files:\n",
        "      - hf/ARC-Challenge.jsonl\n",
        "      - hf/ARC-Easy.jsonl\n",
        "      - hf/riddle_sense.jsonl\n",
        "    type: explainchoice:chat\n",
        "  - path: winglian/evals\n",
        "    data_files:\n",
        "      - hf/gsm8k.jsonl\n",
        "      - hf/winogrande.jsonl\n",
        "    type: alpaca_chat.load_qa\n",
        "  - path: winglian/evals\n",
        "    data_files:\n",
        "      - custom/n_task.jsonl\n",
        "      - custom/misconceptions.jsonl\n",
        "      - custom/context_insensitivity.jsonl\n",
        "    type: alpaca_chat\n",
        "  - path: camel-ai/math\n",
        "    type: alpaca_chat.load_camel_ai\n",
        "  - path: camel-ai/biology\n",
        "    type: alpaca_chat.load_camel_ai\n",
        "  - path: camel-ai/physics\n",
        "    type: alpaca_chat.load_camel_ai\n",
        "  - path: camel-ai/chemistry\n",
        "    type: alpaca_chat.load_camel_ai\n",
        "  - path: winglian/evals\n",
        "    data_files:\n",
        "      - custom/in_context_qa.jsonl\n",
        "    type: context_qa\n",
        "  - path: winglian/evals\n",
        "    data_files:\n",
        "      - custom/in_context_qa.jsonl\n",
        "    type: context_qa.load_404\n",
        "  - path: winglian/evals\n",
        "    data_files:\n",
        "      - custom/jokes_explained_500up.jsonl\n",
        "    type: sharegpt_jokes\n",
        "  - path: winglian/evals\n",
        "    data_files:\n",
        "      - custom/classify-self-chat.sharegpt.jsonl\n",
        "      - custom/coding-self-chat.sharegpt.jsonl\n",
        "      - custom/prose-gpt4.sharegpt.jsonl\n",
        "      - custom/prose-rewrite-gpt4.sharegpt.jsonl\n",
        "    type: sharegpt_simple.load_role\n",
        "  - path: winglian/evals\n",
        "    data_files:\n",
        "      - openai/tldr.jsonl\n",
        "    type: summarizetldr:chat\n",
        "  - path: winglian/evals\n",
        "    data_files:\n",
        "      - hellaswag/hellaswag.jsonl\n",
        "    type: explainchoice:chat\n",
        "  - path: metaeval/ScienceQA_text_only\n",
        "    type: concisechoice:chat\n",
        "  - path: teknium/GPT4-LLM-Cleaned\n",
        "    type: alpaca_chat\n",
        "  - path: teknium/GPTeacher-General-Instruct\n",
        "    data_files: gpt4-instruct-similarity-0.6-dataset.json\n",
        "    type: gpteacher:chat\n",
        "  - path: QingyiSi/Alpaca-CoT\n",
        "    data_files:\n",
        "      - Chain-of-Thought/formatted_cot_data/aqua_train.json\n",
        "      - Chain-of-Thought/formatted_cot_data/creak_train.json\n",
        "      - Chain-of-Thought/formatted_cot_data/ecqa_train.json\n",
        "      - Chain-of-Thought/formatted_cot_data/esnli_train.json\n",
        "      - Chain-of-Thought/formatted_cot_data/qasc_train.json\n",
        "      - Chain-of-Thought/formatted_cot_data/qed_train.json\n",
        "      - Chain-of-Thought/formatted_cot_data/sensemaking_train.json\n",
        "      - Chain-of-Thought/formatted_cot_data/strategyqa_train.json\n",
        "      - GPTeacher/Roleplay/formatted_roleplay-similarity_0.6-instruct-dataset.json\n",
        "    type: alpaca_chat\n",
        "  - path: ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered\n",
        "    type: alpaca_chat\n",
        "  - path: ehartford/wizard_vicuna_70k_unfiltered\n",
        "    type: sharegpt:chat\n",
        "\n",
        "dataset_prepared_path: last_run_prepared\n",
        "val_set_size: 0.01\n",
        "# enable QLoRA\n",
        "adapter: qlora\n",
        "lora_model_dir:\n",
        "sequence_len: 2048\n",
        "max_packed_sequence_len:\n",
        "\n",
        "# hyperparameters from QLoRA paper Appendix B.2\n",
        "# \"We find hyperparameters to be largely robust across datasets\"\n",
        "lora_r: 64\n",
        "lora_alpha: 16\n",
        "# 0.1 for models up to 13B\n",
        "# 0.05 for 33B and 65B models\n",
        "lora_dropout: 0.05\n",
        "# add LoRA modules on all linear layers of the base model\n",
        "lora_target_modules:\n",
        "lora_target_linear: true\n",
        "lora_fan_in_fan_out:\n",
        "\n",
        "wandb_project: falcon-qlora\n",
        "wandb_watch:\n",
        "wandb_run_id:\n",
        "wandb_log_model:\n",
        "output_dir: /workspace/llm-playground/axolotl-trained/falcon-qlora-40b-gsm8k/\n",
        "\n",
        "# QLoRA paper Table 9\n",
        "# - 16 for 7b & 13b\n",
        "# - 32 for 33b, 64 for 64b\n",
        "# Max size tested on A6000\n",
        "# - 7b: 40\n",
        "# - 40b: 4\n",
        "# decrease if OOM, increase for max VRAM utilization\n",
        "micro_batch_size: 1\n",
        "gradient_accumulation_steps: 2\n",
        "num_epochs: 3\n",
        "# Optimizer for QLoRA\n",
        "optimizer: paged_adamw_32bit\n",
        "torchdistx_path:\n",
        "lr_scheduler: cosine\n",
        "# QLoRA paper Table 9\n",
        "# - 2e-4 for 7b & 13b\n",
        "# - 1e-4 for 33b & 64b\n",
        "learning_rate: 0.0002\n",
        "train_on_inputs: false\n",
        "group_by_length: false\n",
        "bf16: true\n",
        "fp16: false\n",
        "tf32: true\n",
        "gradient_checkpointing: true\n",
        "# stop training after this many evaluation losses have increased in a row\n",
        "# https://huggingface.co/transformers/v4.2.2/_modules/transformers/trainer_callback.html#EarlyStoppingCallback\n",
        "early_stopping_patience: 3\n",
        "resume_from_checkpoint:\n",
        "auto_resume_from_checkpoints: true\n",
        "local_rank:\n",
        "logging_steps: 1\n",
        "xformers_attention: true\n",
        "flash_attention:\n",
        "gptq_groupsize:\n",
        "gptq_model_v1:\n",
        "warmup_steps: 10\n",
        "eval_steps: 5\n",
        "save_steps: 10\n",
        "debug:\n",
        "deepspeed:\n",
        "weight_decay: 0.01\n",
        "fsdp:\n",
        "fsdp_config:\n",
        "special_tokens:\n",
        "  pad_token: \"<|endoftext|>\"\n",
        "  bos_token: \">>ABSTRACT<<\"\n",
        "  eos_token: \"<|endoftext|>\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KvSjgxUrXJ_d",
        "outputId": "38a091d5-8a03-41e3-cb47-ff7c8cc0912b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "===================================BUG REPORT===================================\n",
            "Welcome to bitsandbytes. For bug reports, please run\n",
            "\n",
            "python -m bitsandbytes\n",
            "\n",
            " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
            "================================================================================\n",
            "bin /root/miniconda3/envs/py3.9/lib/python3.9/site-packages/bitsandbytes-0.39.0-py3.9.egg/bitsandbytes/libbitsandbytes_cuda118.so\n",
            "/root/miniconda3/envs/py3.9/lib/python3.9/site-packages/bitsandbytes-0.39.0-py3.9.egg/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/usr/local/nvidia/lib'), PosixPath('/usr/local/nvidia/lib64')}\n",
            "  warn(msg)\n",
            "/root/miniconda3/envs/py3.9/lib/python3.9/site-packages/bitsandbytes-0.39.0-py3.9.egg/bitsandbytes/cuda_setup/main.py:149: UserWarning: /usr/local/nvidia/lib:/usr/local/nvidia/lib64 did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...\n",
            "  warn(msg)\n",
            "/root/miniconda3/envs/py3.9/lib/python3.9/site-packages/bitsandbytes-0.39.0-py3.9.egg/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('module'), PosixPath('//matplotlib_inline.backend_inline')}\n",
            "  warn(msg)\n",
            "/root/miniconda3/envs/py3.9/lib/python3.9/site-packages/bitsandbytes-0.39.0-py3.9.egg/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQDvnE4umHheXhWsDJbbukYvvyc47/mC4z8syS93btA72T90WDrQagOy5O+DrhdXOvr5i/JwsTlAImy57eLRrtRFOrQq73jyi7Dzo0tvrAiNLVgX2q2dFLoplRyXDXiVYLPmPieMWQOeUCLeSb8FC5zzllcocZwjMXpxScDerZqnlAR0ccpSkGyKIod4ZMkn/29A/C5kHEb/wT8cOAq+MWJ/2okZZgbiR0AMV4DynAkrtcx9JnJnTs9chiMyH+dyCS42Ai24sHWJBkQo6TfxXkyKo9GOpu3Y2WLgrHyaot9Lk5mA1mujyIWdlReD2nvjeCQKjl3KW3xZ73m4nD97MydWSWoJfEWlr+VZvk8EWsZk3CYLZCIBLdod6xXJJ0DD0pvTIq11c8VB7XkgVjapuU/sC8M6HFzHW/NBeE+xX/txPkZkIGqrnxeQ0AtBXdN9ukyNGhGzTkPYJNliiYpY0dCvVuz/BJ2FawFTQGnD1EHOenUCRajREFGCbKoYZqi40j8= utensil@Utensils-MacBook-Pro.local')}\n",
            "  warn(msg)\n",
            "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching in backup paths...\n",
            "/root/miniconda3/envs/py3.9/lib/python3.9/site-packages/bitsandbytes-0.39.0-py3.9.egg/bitsandbytes/cuda_setup/main.py:149: UserWarning: Found duplicate ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] files: {PosixPath('/usr/local/cuda/lib64/libcudart.so.11.0'), PosixPath('/usr/local/cuda/lib64/libcudart.so')}.. We'll flip a coin and try one of these, in order to fail forward.\n",
            "Either way, this might cause trouble in the future:\n",
            "If you get `CUDA error: invalid device function` errors, the above might be the cause and the solution is to make sure only one ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] in the paths that we search based on your env.\n",
            "  warn(msg)\n",
            "CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so.11.0\n",
            "CUDA SETUP: Highest compute capability among GPUs detected: 8.6\n",
            "CUDA SETUP: Detected CUDA version 118\n",
            "CUDA SETUP: Loading binary /root/miniconda3/envs/py3.9/lib/python3.9/site-packages/bitsandbytes-0.39.0-py3.9.egg/bitsandbytes/libbitsandbytes_cuda118.so...\n",
            "Setting ds_accelerator to cuda (auto detect)\n",
            "WARNING:root:`trust_remote_code` is set to true. Please make sure that you reviewed the remote code/model.\n",
            "INFO:root:loading tokenizer... tiiuae/falcon-40b\n",
            "Downloading (…)okenizer_config.json: 100%|█████| 175/175 [00:00<00:00, 52.4kB/s]\n",
            "Downloading (…)/main/tokenizer.json: 100%|█| 2.73M/2.73M [00:00<00:00, 4.38MB/s]\n",
            "Downloading (…)cial_tokens_map.json: 100%|██████| 281/281 [00:00<00:00, 204kB/s]\n",
            "Using bos_token, but it is not set yet.\n",
            "Using pad_token, but it is not set yet.\n",
            "Using unk_token, but it is not set yet.\n",
            "INFO:root:Unable to find prepared dataset in last_run_prepared/8c0b88117df31fc5fa3b6f12f4ec9abb\n",
            "INFO:root:Loading raw datasets...\n",
            "INFO:root:No seed provided, using default seed of 42\n",
            "Downloading readme: 100%|██████████████████████| 259/259 [00:00<00:00, 1.38MB/s]\n",
            "Downloading and preparing dataset json/winglian--evals to /root/.cache/huggingface/datasets/winglian___json/winglian--evals-967fbffa8fbc6a56/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4...\n",
            "Downloading data files:   0%|                             | 0/1 [00:00<?, ?it/s]\n",
            "Downloading data:   0%|                             | 0.00/2.05M [00:00<?, ?B/s]\u001b[A\n",
            "Downloading data:   1%|▎                    | 25.6k/2.05M [00:00<00:08, 249kB/s]\u001b[A\n",
            "Downloading data:   5%|█▏                    | 105k/2.05M [00:00<00:03, 559kB/s]\u001b[A\n",
            "Downloading data:  12%|██▋                   | 247k/2.05M [00:00<00:01, 929kB/s]\u001b[A\n",
            "Downloading data:  26%|█████▍               | 531k/2.05M [00:00<00:00, 1.65MB/s]\u001b[A\n",
            "Downloading data: 100%|████████████████████| 2.05M/2.05M [00:00<00:00, 3.84MB/s]\u001b[A\n",
            "\n",
            "Downloading data:   0%|                             | 0.00/3.22M [00:00<?, ?B/s]\u001b[A\n",
            "Downloading data:   1%|▏                    | 24.6k/3.22M [00:00<00:13, 239kB/s]\u001b[A\n",
            "Downloading data:   3%|▋                     | 102k/3.22M [00:00<00:05, 543kB/s]\u001b[A\n",
            "Downloading data:   7%|█▌                    | 233k/3.22M [00:00<00:03, 875kB/s]\u001b[A\n",
            "Downloading data:  16%|███▍                 | 528k/3.22M [00:00<00:01, 1.66MB/s]\u001b[A\n",
            "Downloading data:  34%|██████▊             | 1.10M/3.22M [00:00<00:00, 3.06MB/s]\u001b[A\n",
            "Downloading data: 100%|████████████████████| 3.22M/3.22M [00:00<00:00, 5.05MB/s]\u001b[A\n",
            "\n",
            "Downloading data:   0%|                             | 0.00/3.94M [00:00<?, ?B/s]\u001b[A\n",
            "Downloading data:   1%|▏                    | 32.8k/3.94M [00:00<00:12, 319kB/s]\u001b[A\n",
            "Downloading data:   3%|▌                     | 105k/3.94M [00:00<00:07, 545kB/s]\u001b[A\n",
            "Downloading data:   6%|█▎                    | 237k/3.94M [00:00<00:04, 875kB/s]\u001b[A\n",
            "Downloading data:  13%|██▊                  | 531k/3.94M [00:00<00:02, 1.65MB/s]\u001b[A\n",
            "Downloading data:  28%|█████▌              | 1.09M/3.94M [00:00<00:00, 2.99MB/s]\u001b[A\n",
            "Downloading data: 100%|████████████████████| 3.94M/3.94M [00:00<00:00, 5.99MB/s]\u001b[A\n",
            "Downloading data files: 100%|█████████████████████| 1/1 [00:03<00:00,  4.00s/it]\n",
            "Extracting data files: 100%|█████████████████████| 1/1 [00:00<00:00, 709.82it/s]\n",
            "Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/winglian___json/winglian--evals-967fbffa8fbc6a56/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4. Subsequent calls will reuse this data.\n",
            "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 394.42it/s]\n",
            "Downloading and preparing dataset json/winglian--evals to /root/.cache/huggingface/datasets/winglian___json/winglian--evals-2d9807bf90eb06df/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4...\n",
            "Downloading data files:   0%|                             | 0/1 [00:00<?, ?it/s]\n",
            "Downloading data:   0%|                             | 0.00/7.79M [00:00<?, ?B/s]\u001b[A\n",
            "Downloading data:   0%|                     | 33.8k/7.79M [00:00<00:23, 332kB/s]\u001b[A\n",
            "Downloading data:   1%|▎                     | 105k/7.79M [00:00<00:14, 541kB/s]\u001b[A\n",
            "Downloading data:   3%|▋                     | 243k/7.79M [00:00<00:08, 901kB/s]\u001b[A\n",
            "Downloading data:   7%|█▍                   | 529k/7.79M [00:00<00:04, 1.64MB/s]\u001b[A\n",
            "Downloading data:  14%|██▊                 | 1.10M/7.79M [00:00<00:02, 3.04MB/s]\u001b[A\n",
            "Downloading data:  29%|█████▊              | 2.24M/7.79M [00:00<00:00, 5.75MB/s]\u001b[A\n",
            "Downloading data: 100%|████████████████████| 7.79M/7.79M [00:00<00:00, 10.1MB/s]\u001b[A\n",
            "\n",
            "Downloading data:   0%|                             | 0.00/5.89M [00:00<?, ?B/s]\u001b[A\n",
            "Downloading data:   0%|                     | 26.6k/5.89M [00:00<00:22, 261kB/s]\u001b[A\n",
            "Downloading data:   2%|▍                     | 105k/5.89M [00:00<00:10, 557kB/s]\u001b[A\n",
            "Downloading data:   4%|▉                     | 248k/5.89M [00:00<00:06, 929kB/s]\u001b[A\n",
            "Downloading data:   9%|█▊                   | 524k/5.89M [00:00<00:03, 1.62MB/s]\u001b[A\n",
            "Downloading data:  19%|███▋                | 1.10M/5.89M [00:00<00:01, 3.04MB/s]\u001b[A\n",
            "Downloading data:  38%|███████▌            | 2.23M/5.89M [00:00<00:00, 5.71MB/s]\u001b[A\n",
            "Downloading data: 100%|████████████████████| 5.89M/5.89M [00:00<00:00, 7.97MB/s]\u001b[A\n",
            "Downloading data files: 100%|█████████████████████| 1/1 [00:03<00:00,  3.23s/it]\n",
            "Extracting data files: 100%|████████████████████| 1/1 [00:00<00:00, 1231.08it/s]\n",
            "Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/winglian___json/winglian--evals-2d9807bf90eb06df/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4. Subsequent calls will reuse this data.\n",
            "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 705.99it/s]\n",
            "Downloading and preparing dataset json/winglian--evals to /root/.cache/huggingface/datasets/winglian___json/winglian--evals-5354680ac81acd67/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4...\n",
            "Downloading data files:   0%|                             | 0/1 [00:00<?, ?it/s]\n",
            "Downloading data:   0%|                              | 0.00/172k [00:00<?, ?B/s]\u001b[A\n",
            "Downloading data:  15%|███▍                  | 26.6k/172k [00:00<00:00, 261kB/s]\u001b[A\n",
            "Downloading data: 100%|███████████████████████| 172k/172k [00:00<00:00, 832kB/s]\u001b[A\n",
            "\n",
            "Downloading data:   0%|                              | 0.00/395k [00:00<?, ?B/s]\u001b[A\n",
            "Downloading data:   6%|█▍                    | 25.6k/395k [00:00<00:01, 239kB/s]\u001b[A\n",
            "Downloading data:  27%|██████▎                | 108k/395k [00:00<00:00, 562kB/s]\u001b[A\n",
            "Downloading data: 100%|██████████████████████| 395k/395k [00:00<00:00, 1.24MB/s]\u001b[A\n",
            "\n",
            "Downloading data:   0%|                             | 0.00/79.9k [00:00<?, ?B/s]\u001b[A\n",
            "Downloading data: 100%|█████████████████████| 79.9k/79.9k [00:00<00:00, 725kB/s]\u001b[A\n",
            "Downloading data files: 100%|█████████████████████| 1/1 [00:02<00:00,  2.53s/it]\n",
            "Extracting data files: 100%|█████████████████████| 1/1 [00:00<00:00, 712.23it/s]\n",
            "Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/winglian___json/winglian--evals-5354680ac81acd67/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4. Subsequent calls will reuse this data.\n",
            "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 873.63it/s]\n",
            "Downloading readme: 100%|██████████████████| 2.19k/2.19k [00:00<00:00, 12.0MB/s]\n",
            "Downloading and preparing dataset json/camel-ai--math to /root/.cache/huggingface/datasets/camel-ai___json/camel-ai--math-e65613a5e6088d3f/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4...\n",
            "Downloading data files:   0%|                             | 0/1 [00:00<?, ?it/s]\n",
            "Downloading data:   0%|                             | 0.00/39.8M [00:00<?, ?B/s]\u001b[A\n",
            "Downloading data:   5%|▉                   | 1.98M/39.8M [00:00<00:01, 19.8MB/s]\u001b[A\n",
            "Downloading data:  14%|██▊                 | 5.63M/39.8M [00:00<00:01, 29.0MB/s]\u001b[A\n",
            "Downloading data:  27%|█████▍              | 10.7M/39.8M [00:00<00:00, 38.9MB/s]\u001b[A\n",
            "Downloading data:  43%|████████▋           | 17.3M/39.8M [00:00<00:00, 49.2MB/s]\u001b[A\n",
            "Downloading data:  65%|████████████▉       | 25.7M/39.8M [00:00<00:00, 61.7MB/s]\u001b[A\n",
            "Downloading data: 100%|████████████████████| 39.8M/39.8M [00:00<00:00, 59.5MB/s]\u001b[A\n",
            "Downloading data files: 100%|█████████████████████| 1/1 [00:01<00:00,  1.33s/it]\n",
            "Extracting data files: 100%|██████████████████████| 1/1 [00:05<00:00,  5.90s/it]\n",
            "Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/camel-ai___json/camel-ai--math-e65613a5e6088d3f/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4. Subsequent calls will reuse this data.\n",
            "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.70it/s]\n",
            "Downloading readme: 100%|██████████████████| 2.12k/2.12k [00:00<00:00, 9.21MB/s]\n",
            "Downloading and preparing dataset json/camel-ai--biology to /root/.cache/huggingface/datasets/camel-ai___json/camel-ai--biology-a0dba0b3efd07bc4/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4...\n",
            "Downloading data files:   0%|                             | 0/1 [00:00<?, ?it/s]\n",
            "Downloading data:   0%|                             | 0.00/27.4M [00:00<?, ?B/s]\u001b[A\n",
            "Downloading data:  12%|██▍                 | 3.31M/27.4M [00:00<00:00, 33.1MB/s]\u001b[A\n",
            "Downloading data:  46%|█████████▎          | 12.7M/27.4M [00:00<00:00, 68.7MB/s]\u001b[A\n",
            "Downloading data: 100%|████████████████████| 27.4M/27.4M [00:00<00:00, 77.6MB/s]\u001b[A\n",
            "Downloading data files: 100%|█████████████████████| 1/1 [00:01<00:00,  1.26s/it]\n",
            "Extracting data files: 100%|██████████████████████| 1/1 [00:02<00:00,  2.46s/it]\n",
            "Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/camel-ai___json/camel-ai--biology-a0dba0b3efd07bc4/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4. Subsequent calls will reuse this data.\n",
            "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.88it/s]\n",
            "Downloading readme: 100%|██████████████████| 2.12k/2.12k [00:00<00:00, 9.49MB/s]\n",
            "Downloading and preparing dataset json/camel-ai--physics to /root/.cache/huggingface/datasets/camel-ai___json/camel-ai--physics-c2d5e46897f076a2/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4...\n",
            "Downloading data files:   0%|                             | 0/1 [00:00<?, ?it/s]\n",
            "Downloading data:   0%|                             | 0.00/23.5M [00:00<?, ?B/s]\u001b[A\n",
            "Downloading data:  17%|███▍                | 3.98M/23.5M [00:00<00:00, 39.8MB/s]\u001b[A\n",
            "Downloading data:  49%|█████████▊          | 11.6M/23.5M [00:00<00:00, 61.0MB/s]\u001b[A\n",
            "Downloading data: 100%|████████████████████| 23.5M/23.5M [00:00<00:00, 72.0MB/s]\u001b[A\n",
            "Downloading data files: 100%|█████████████████████| 1/1 [00:00<00:00,  1.01it/s]\n",
            "Extracting data files: 100%|██████████████████████| 1/1 [00:02<00:00,  2.37s/it]\n",
            "Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/camel-ai___json/camel-ai--physics-c2d5e46897f076a2/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4. Subsequent calls will reuse this data.\n",
            "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.24it/s]\n",
            "Downloading readme: 100%|██████████████████| 2.14k/2.14k [00:00<00:00, 10.2MB/s]\n",
            "Downloading and preparing dataset json/camel-ai--chemistry to /root/.cache/huggingface/datasets/camel-ai___json/camel-ai--chemistry-8a34ec93529b52ff/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4...\n",
            "Downloading data files:   0%|                             | 0/1 [00:00<?, ?it/s]\n",
            "Downloading data:   0%|                             | 0.00/21.8M [00:00<?, ?B/s]\u001b[A\n",
            "Downloading data:  22%|████▎               | 4.68M/21.8M [00:00<00:00, 46.6MB/s]\u001b[A\n",
            "Downloading data:  52%|██████████▍         | 11.4M/21.8M [00:00<00:00, 58.6MB/s]\u001b[A\n",
            "Downloading data: 100%|████████████████████| 21.8M/21.8M [00:00<00:00, 69.3MB/s]\u001b[A\n",
            "Downloading data files: 100%|█████████████████████| 1/1 [00:01<00:00,  1.19s/it]\n",
            "Extracting data files: 100%|██████████████████████| 1/1 [00:02<00:00,  2.38s/it]\n",
            "Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/camel-ai___json/camel-ai--chemistry-8a34ec93529b52ff/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4. Subsequent calls will reuse this data.\n",
            "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.07it/s]\n",
            "Downloading and preparing dataset json/winglian--evals to /root/.cache/huggingface/datasets/winglian___json/winglian--evals-81bfad14acee858f/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4...\n",
            "Downloading data files:   0%|                             | 0/1 [00:00<?, ?it/s]\n",
            "Downloading data:   0%|                             | 0.00/1.84M [00:00<?, ?B/s]\u001b[A\n",
            "Downloading data:   1%|▎                    | 26.6k/1.84M [00:00<00:06, 261kB/s]\u001b[A\n",
            "Downloading data:   6%|█▎                    | 105k/1.84M [00:00<00:03, 559kB/s]\u001b[A\n",
            "Downloading data:  13%|██▊                   | 239k/1.84M [00:00<00:01, 893kB/s]\u001b[A\n",
            "Downloading data:  29%|██████               | 529k/1.84M [00:00<00:00, 1.65MB/s]\u001b[A\n",
            "Downloading data: 100%|████████████████████| 1.84M/1.84M [00:00<00:00, 3.49MB/s]\u001b[A\n",
            "Downloading data files: 100%|█████████████████████| 1/1 [00:01<00:00,  1.14s/it]\n",
            "Extracting data files: 100%|████████████████████| 1/1 [00:00<00:00, 1564.46it/s]\n",
            "Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/winglian___json/winglian--evals-81bfad14acee858f/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4. Subsequent calls will reuse this data.\n",
            "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 751.53it/s]\n",
            "WARNING:datasets.builder:Found cached dataset json (/root/.cache/huggingface/datasets/winglian___json/winglian--evals-81bfad14acee858f/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\n",
            "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 567.72it/s]\n",
            "Downloading and preparing dataset json/winglian--evals to /root/.cache/huggingface/datasets/winglian___json/winglian--evals-c3b1db8d176877c7/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4...\n",
            "Downloading data files:   0%|                             | 0/1 [00:00<?, ?it/s]\n",
            "Downloading data:   0%|                             | 0.00/1.58M [00:00<?, ?B/s]\u001b[A\n",
            "Downloading data:   2%|▎                    | 26.6k/1.58M [00:00<00:05, 262kB/s]\u001b[A\n",
            "Downloading data:   7%|█▍                    | 105k/1.58M [00:00<00:02, 560kB/s]\u001b[A\n",
            "Downloading data:  15%|███▏                  | 233k/1.58M [00:00<00:01, 872kB/s]\u001b[A\n",
            "Downloading data:  33%|██████▉              | 524k/1.58M [00:00<00:00, 1.64MB/s]\u001b[A\n",
            "Downloading data: 100%|████████████████████| 1.58M/1.58M [00:00<00:00, 3.04MB/s]\u001b[A\n",
            "Downloading data files: 100%|█████████████████████| 1/1 [00:01<00:00,  1.10s/it]\n",
            "Extracting data files: 100%|████████████████████| 1/1 [00:00<00:00, 1738.93it/s]\n",
            "Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/winglian___json/winglian--evals-c3b1db8d176877c7/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4. Subsequent calls will reuse this data.\n",
            "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 506.86it/s]\n",
            "Downloading and preparing dataset json/winglian--evals to /root/.cache/huggingface/datasets/winglian___json/winglian--evals-f3d8ab7303b30dba/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4...\n",
            "Downloading data files:   0%|                             | 0/1 [00:00<?, ?it/s]\n",
            "Downloading data:   0%|                              | 0.00/626k [00:00<?, ?B/s]\u001b[A\n",
            "Downloading data:   4%|▉                     | 26.6k/626k [00:00<00:02, 259kB/s]\u001b[A\n",
            "Downloading data:  17%|███▉                   | 105k/626k [00:00<00:00, 555kB/s]\u001b[A\n",
            "Downloading data:  38%|████████▊              | 239k/626k [00:00<00:00, 889kB/s]\u001b[A\n",
            "Downloading data: 100%|██████████████████████| 626k/626k [00:00<00:00, 1.50MB/s]\u001b[A\n",
            "\n",
            "Downloading data:   0%|                             | 0.00/7.87M [00:00<?, ?B/s]\u001b[A\n",
            "Downloading data:   0%|                     | 26.6k/7.87M [00:00<00:30, 260kB/s]\u001b[A\n",
            "Downloading data:   1%|▎                    | 98.3k/7.87M [00:00<00:15, 516kB/s]\u001b[A\n",
            "Downloading data:   3%|▋                     | 245k/7.87M [00:00<00:08, 927kB/s]\u001b[A\n",
            "Downloading data:   7%|█▍                   | 527k/7.87M [00:00<00:04, 1.64MB/s]\u001b[A\n",
            "Downloading data:  14%|██▊                 | 1.10M/7.87M [00:00<00:02, 3.03MB/s]\u001b[A\n",
            "Downloading data:  29%|█████▋              | 2.24M/7.87M [00:00<00:00, 5.77MB/s]\u001b[A\n",
            "Downloading data: 100%|████████████████████| 7.87M/7.87M [00:00<00:00, 10.3MB/s]\u001b[A\n",
            "\n",
            "Downloading data:   0%|                             | 0.00/1.12M [00:00<?, ?B/s]\u001b[A\n",
            "Downloading data:   2%|▍                    | 26.6k/1.12M [00:00<00:04, 261kB/s]\u001b[A\n",
            "Downloading data:   9%|█▊                   | 98.3k/1.12M [00:00<00:01, 516kB/s]\u001b[A\n",
            "Downloading data:  21%|████▋                 | 240k/1.12M [00:00<00:00, 907kB/s]\u001b[A\n",
            "Downloading data:  48%|█████████▉           | 534k/1.12M [00:00<00:00, 1.67MB/s]\u001b[A\n",
            "Downloading data: 100%|████████████████████| 1.12M/1.12M [00:00<00:00, 2.17MB/s]\u001b[A\n",
            "\n",
            "Downloading data:   0%|                             | 0.00/1.13M [00:00<?, ?B/s]\u001b[A\n",
            "Downloading data:   2%|▍                    | 25.6k/1.13M [00:00<00:04, 249kB/s]\u001b[A\n",
            "Downloading data:   9%|█▊                   | 98.3k/1.13M [00:00<00:01, 519kB/s]\u001b[A\n",
            "Downloading data:  22%|████▊                 | 246k/1.13M [00:00<00:00, 934kB/s]\u001b[A\n",
            "Downloading data:  47%|█████████▊           | 529k/1.13M [00:00<00:00, 1.65MB/s]\u001b[A\n",
            "Downloading data: 100%|████████████████████| 1.13M/1.13M [00:00<00:00, 2.19MB/s]\u001b[A\n",
            "Downloading data files: 100%|█████████████████████| 1/1 [00:04<00:00,  4.85s/it]\n",
            "Extracting data files: 100%|█████████████████████| 1/1 [00:00<00:00, 355.21it/s]\n",
            "Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/winglian___json/winglian--evals-f3d8ab7303b30dba/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4. Subsequent calls will reuse this data.\n",
            "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 496.07it/s]\n",
            "Downloading and preparing dataset json/winglian--evals to /root/.cache/huggingface/datasets/winglian___json/winglian--evals-c89bb0dad6bf8005/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4...\n",
            "Downloading data files:   0%|                             | 0/1 [00:00<?, ?it/s]\n",
            "Downloading data:   0%|                             | 0.00/2.23M [00:00<?, ?B/s]\u001b[A\n",
            "Downloading data:   1%|▏                    | 25.6k/2.23M [00:00<00:08, 251kB/s]\u001b[A\n",
            "Downloading data:   5%|█                     | 104k/2.23M [00:00<00:03, 554kB/s]\u001b[A\n",
            "Downloading data:  11%|██▍                   | 243k/2.23M [00:00<00:02, 913kB/s]\u001b[A\n",
            "Downloading data:  23%|████▉                | 523k/2.23M [00:00<00:01, 1.62MB/s]\u001b[A\n",
            "Downloading data: 100%|████████████████████| 2.23M/2.23M [00:00<00:00, 4.19MB/s]\u001b[A\n",
            "Downloading data files: 100%|█████████████████████| 1/1 [00:01<00:00,  1.14s/it]\n",
            "Extracting data files: 100%|████████████████████| 1/1 [00:00<00:00, 1797.82it/s]\n",
            "Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/winglian___json/winglian--evals-c89bb0dad6bf8005/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4. Subsequent calls will reuse this data.\n",
            "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 817.44it/s]\n",
            "Downloading and preparing dataset json/winglian--evals to /root/.cache/huggingface/datasets/winglian___json/winglian--evals-99f605981858093b/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4...\n",
            "Downloading data files:   0%|                             | 0/1 [00:00<?, ?it/s]\n",
            "Downloading data:   0%|                             | 0.00/73.1M [00:00<?, ?B/s]\u001b[A\n",
            "Downloading data:   0%|                     | 25.6k/73.1M [00:00<04:52, 250kB/s]\u001b[A\n",
            "Downloading data:   0%|                     | 91.1k/73.1M [00:00<02:33, 477kB/s]\u001b[A\n",
            "Downloading data:   0%|                      | 239k/73.1M [00:00<01:20, 909kB/s]\u001b[A\n",
            "Downloading data:   1%|▏                    | 534k/73.1M [00:00<00:43, 1.67MB/s]\u001b[A\n",
            "Downloading data:   1%|▎                   | 1.09M/73.1M [00:00<00:24, 3.00MB/s]\u001b[A\n",
            "Downloading data:   3%|▌                   | 2.24M/73.1M [00:00<00:12, 5.75MB/s]\u001b[A\n",
            "Downloading data:   6%|█▏                  | 4.51M/73.1M [00:00<00:06, 11.0MB/s]\u001b[A\n",
            "Downloading data:  10%|█▉                  | 7.16M/73.1M [00:00<00:05, 11.6MB/s]\u001b[A\n",
            "Downloading data:  16%|███▏                | 11.9M/73.1M [00:01<00:03, 19.7MB/s]\u001b[A\n",
            "Downloading data:  23%|████▋               | 17.0M/73.1M [00:01<00:02, 27.7MB/s]\u001b[A\n",
            "Downloading data:  30%|█████▉              | 21.9M/73.1M [00:01<00:01, 33.4MB/s]\u001b[A\n",
            "Downloading data:  37%|███████▎            | 27.0M/73.1M [00:01<00:01, 37.9MB/s]\u001b[A\n",
            "Downloading data:  44%|████████▊           | 32.2M/73.1M [00:01<00:00, 41.4MB/s]\u001b[A\n",
            "Downloading data:  51%|██████████▏         | 37.4M/73.1M [00:01<00:00, 43.9MB/s]\u001b[A\n",
            "Downloading data:  58%|███████████▌        | 42.5M/73.1M [00:01<00:00, 45.5MB/s]\u001b[A\n",
            "Downloading data:  65%|█████████████       | 47.6M/73.1M [00:01<00:00, 46.7MB/s]\u001b[A\n",
            "Downloading data:  72%|██████████████▍     | 52.8M/73.1M [00:01<00:00, 47.5MB/s]\u001b[A\n",
            "Downloading data:  79%|███████████████▊    | 57.7M/73.1M [00:01<00:00, 47.5MB/s]\u001b[A\n",
            "Downloading data:  86%|█████████████████▏  | 62.8M/73.1M [00:02<00:00, 47.9MB/s]\u001b[A\n",
            "Downloading data:  93%|██████████████████▌ | 67.9M/73.1M [00:02<00:00, 48.5MB/s]\u001b[A\n",
            "Downloading data: 100%|████████████████████| 73.1M/73.1M [00:02<00:00, 31.9MB/s]\u001b[A\n",
            "Downloading data files: 100%|█████████████████████| 1/1 [00:07<00:00,  7.69s/it]\n",
            "Extracting data files: 100%|████████████████████| 1/1 [00:00<00:00, 1895.30it/s]\n",
            "Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/winglian___json/winglian--evals-99f605981858093b/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4. Subsequent calls will reuse this data.\n",
            "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 412.34it/s]\n",
            "Downloading readme: 100%|██████████████████| 1.23k/1.23k [00:00<00:00, 10.2MB/s]\n",
            "Downloading and preparing dataset None/None to /root/.cache/huggingface/datasets/metaeval___parquet/metaeval--ScienceQA_text_only-00e2b9b849dc5307/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec...\n",
            "Downloading data files:   0%|                             | 0/3 [00:00<?, ?it/s]\n",
            "Downloading data: 100%|████████████████████| 1.73M/1.73M [00:00<00:00, 35.0MB/s]\u001b[A\n",
            "Downloading data files:  33%|███████              | 1/3 [00:00<00:01,  1.06it/s]\n",
            "Downloading data: 100%|██████████████████████| 576k/576k [00:00<00:00, 14.0MB/s]\u001b[A\n",
            "Downloading data files:  67%|██████████████       | 2/3 [00:01<00:00,  1.25it/s]\n",
            "Downloading data: 100%|██████████████████████| 619k/619k [00:00<00:00, 18.5MB/s]\u001b[A\n",
            "Downloading data files: 100%|█████████████████████| 3/3 [00:02<00:00,  1.16it/s]\n",
            "Extracting data files: 100%|████████████████████| 3/3 [00:00<00:00, 1891.31it/s]\n",
            "Dataset parquet downloaded and prepared to /root/.cache/huggingface/datasets/metaeval___parquet/metaeval--ScienceQA_text_only-00e2b9b849dc5307/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec. Subsequent calls will reuse this data.\n",
            "100%|████████████████████████████████████████████| 3/3 [00:00<00:00, 606.41it/s]\n",
            "Downloading readme: 100%|██████████████████████| 501/501 [00:00<00:00, 2.30MB/s]\n",
            "Downloading and preparing dataset json/teknium--GPT4-LLM-Cleaned to /root/.cache/huggingface/datasets/teknium___json/teknium--GPT4-LLM-Cleaned-a71aa8ae1ac3982d/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4...\n",
            "Downloading data files:   0%|                             | 0/1 [00:00<?, ?it/s]\n",
            "Downloading data:   0%|                             | 0.00/36.0M [00:00<?, ?B/s]\u001b[A\n",
            "Downloading data:  18%|███▌                | 6.41M/36.0M [00:00<00:00, 64.1MB/s]\u001b[A\n",
            "Downloading data:  44%|████████▊           | 15.9M/36.0M [00:00<00:00, 82.4MB/s]\u001b[A\n",
            "Downloading data:  71%|██████████████▎     | 25.7M/36.0M [00:00<00:00, 89.5MB/s]\u001b[A\n",
            "Downloading data: 100%|████████████████████| 36.0M/36.0M [00:00<00:00, 88.9MB/s]\u001b[A\n",
            "\n",
            "Downloading data:   0%|                             | 0.00/4.91M [00:00<?, ?B/s]\u001b[A\n",
            "Downloading data:   1%|                     | 25.6k/4.91M [00:00<00:19, 250kB/s]\u001b[A\n",
            "Downloading data:   2%|▍                     | 105k/4.91M [00:00<00:08, 560kB/s]\u001b[A\n",
            "Downloading data:   5%|█                     | 240k/4.91M [00:00<00:05, 897kB/s]\u001b[A\n",
            "Downloading data:  11%|██▎                  | 532k/4.91M [00:00<00:02, 1.66MB/s]\u001b[A\n",
            "Downloading data:  22%|████▍               | 1.10M/4.91M [00:00<00:01, 3.05MB/s]\u001b[A\n",
            "Downloading data:  46%|█████████           | 2.24M/4.91M [00:00<00:00, 5.73MB/s]\u001b[A\n",
            "Downloading data: 100%|████████████████████| 4.91M/4.91M [00:00<00:00, 6.75MB/s]\u001b[A\n",
            "Downloading data files: 100%|█████████████████████| 1/1 [00:02<00:00,  2.66s/it]\n",
            "Extracting data files: 100%|████████████████████| 1/1 [00:00<00:00, 1154.82it/s]\n",
            "Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/teknium___json/teknium--GPT4-LLM-Cleaned-a71aa8ae1ac3982d/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4. Subsequent calls will reuse this data.\n",
            "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 542.60it/s]\n",
            "Downloading readme: 100%|██████████████████████| 458/458 [00:00<00:00, 2.78MB/s]\n",
            "Downloading and preparing dataset json/teknium--GPTeacher-General-Instruct to /root/.cache/huggingface/datasets/teknium___json/teknium--GPTeacher-General-Instruct-ff38d362dfbec0b7/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4...\n",
            "Downloading data files:   0%|                             | 0/1 [00:00<?, ?it/s]\n",
            "Downloading data:   0%|                             | 0.00/12.1M [00:00<?, ?B/s]\u001b[A\n",
            "Downloading data: 100%|████████████████████| 12.1M/12.1M [00:00<00:00, 75.8MB/s]\u001b[A\n",
            "Downloading data files: 100%|█████████████████████| 1/1 [00:01<00:00,  1.07s/it]\n",
            "Extracting data files: 100%|████████████████████| 1/1 [00:00<00:00, 1875.81it/s]\n",
            "Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/teknium___json/teknium--GPTeacher-General-Instruct-ff38d362dfbec0b7/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4. Subsequent calls will reuse this data.\n",
            "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 779.18it/s]\n",
            "Downloading readme: 100%|██████████████████| 8.26k/8.26k [00:00<00:00, 11.7MB/s]\n",
            "Downloading and preparing dataset json/QingyiSi--Alpaca-CoT to /root/.cache/huggingface/datasets/QingyiSi___json/QingyiSi--Alpaca-CoT-72053b9662210036/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4...\n",
            "Downloading data files:   0%|                             | 0/1 [00:00<?, ?it/s]\n",
            "Downloading data:   0%|                             | 0.00/1.20M [00:00<?, ?B/s]\u001b[A\n",
            "Downloading data: 100%|████████████████████| 1.20M/1.20M [00:00<00:00, 9.10MB/s]\u001b[A\n",
            "\n",
            "Downloading data:   0%|                             | 0.00/2.28M [00:00<?, ?B/s]\u001b[A\n",
            "Downloading data:  24%|████▉                | 540k/2.28M [00:00<00:00, 5.01MB/s]\u001b[A\n",
            "Downloading data: 100%|████████████████████| 2.28M/2.28M [00:00<00:00, 7.81MB/s]\u001b[A\n",
            "\n",
            "Downloading data: 100%|████████████████████| 2.81M/2.81M [00:00<00:00, 30.0MB/s]\u001b[A\n",
            "\n",
            "Downloading data:   0%|                             | 0.00/15.0M [00:00<?, ?B/s]\u001b[A\n",
            "Downloading data: 100%|████████████████████| 15.0M/15.0M [00:00<00:00, 79.1MB/s]\u001b[A\n",
            "\n",
            "Downloading data: 100%|██████████████████████| 548k/548k [00:00<00:00, 17.4MB/s]\u001b[A\n",
            "\n",
            "Downloading data:   0%|                             | 0.00/5.12M [00:00<?, ?B/s]\u001b[A\n",
            "Downloading data:  30%|█████▉              | 1.52M/5.12M [00:00<00:00, 15.2MB/s]\u001b[A\n",
            "Downloading data: 100%|████████████████████| 5.12M/5.12M [00:00<00:00, 21.6MB/s]\u001b[A\n",
            "\n",
            "Downloading data: 100%|████████████████████| 2.25M/2.25M [00:00<00:00, 23.9MB/s]\u001b[A\n",
            "\n",
            "Downloading data: 100%|██████████████████████| 719k/719k [00:00<00:00, 12.2MB/s]\u001b[A\n",
            "\n",
            "Downloading data:   0%|                             | 0.00/2.58M [00:00<?, ?B/s]\u001b[A\n",
            "Downloading data: 100%|████████████████████| 2.58M/2.58M [00:00<00:00, 17.2MB/s]\u001b[A\n",
            "Downloading data files: 100%|█████████████████████| 1/1 [00:07<00:00,  7.80s/it]\n",
            "Extracting data files: 100%|█████████████████████| 1/1 [00:00<00:00, 362.89it/s]\n",
            "Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/QingyiSi___json/QingyiSi--Alpaca-CoT-72053b9662210036/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4. Subsequent calls will reuse this data.\n",
            "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 472.86it/s]\n",
            "Downloading readme: 100%|██████████████████████| 387/387 [00:00<00:00, 1.78MB/s]\n",
            "Downloading and preparing dataset json/ehartford--WizardLM_alpaca_evol_instruct_70k_unfiltered to /root/.cache/huggingface/datasets/ehartford___json/ehartford--WizardLM_alpaca_evol_instruct_70k_unfiltered-d64f16a81bd92db8/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4...\n",
            "Downloading data files:   0%|                             | 0/1 [00:00<?, ?it/s]\n",
            "Downloading data:   0%|                             | 0.00/99.6M [00:00<?, ?B/s]\u001b[A\n",
            "Downloading data:   5%|▉                   | 4.84M/99.6M [00:00<00:01, 48.4MB/s]\u001b[A\n",
            "Downloading data:  12%|██▎                 | 11.6M/99.6M [00:00<00:01, 59.9MB/s]\u001b[A\n",
            "Downloading data:  21%|████▏               | 20.7M/99.6M [00:00<00:01, 73.9MB/s]\u001b[A\n",
            "Downloading data:  30%|██████              | 30.1M/99.6M [00:00<00:00, 81.9MB/s]\u001b[A\n",
            "Downloading data:  39%|███████▉            | 39.3M/99.6M [00:00<00:00, 85.5MB/s]\u001b[A\n",
            "Downloading data:  49%|█████████▊          | 48.6M/99.6M [00:00<00:00, 88.2MB/s]\u001b[A\n",
            "Downloading data:  58%|███████████▋        | 58.1M/99.6M [00:00<00:00, 90.4MB/s]\u001b[A\n",
            "Downloading data:  68%|█████████████▌      | 67.6M/99.6M [00:00<00:00, 91.8MB/s]\u001b[A\n",
            "Downloading data:  78%|███████████████▌    | 77.2M/99.6M [00:00<00:00, 93.1MB/s]\u001b[A\n",
            "Downloading data:  87%|█████████████████▍  | 86.9M/99.6M [00:01<00:00, 94.3MB/s]\u001b[A\n",
            "Downloading data: 100%|████████████████████| 99.6M/99.6M [00:01<00:00, 87.9MB/s]\u001b[A\n",
            "Downloading data files: 100%|█████████████████████| 1/1 [00:02<00:00,  2.01s/it]\n",
            "Extracting data files: 100%|████████████████████| 1/1 [00:00<00:00, 1869.95it/s]\n",
            "Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/ehartford___json/ehartford--WizardLM_alpaca_evol_instruct_70k_unfiltered-d64f16a81bd92db8/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4. Subsequent calls will reuse this data.\n",
            "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 477.87it/s]\n",
            "Downloading readme: 100%|██████████████████████| 348/348 [00:00<00:00, 1.68MB/s]\n",
            "Downloading and preparing dataset json/ehartford--wizard_vicuna_70k_unfiltered to /root/.cache/huggingface/datasets/ehartford___json/ehartford--wizard_vicuna_70k_unfiltered-71f549fba4cffce0/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4...\n",
            "Downloading data files:   0%|                             | 0/1 [00:00<?, ?it/s]\n",
            "Downloading data:   0%|                              | 0.00/152M [00:00<?, ?B/s]\u001b[A\n",
            "Downloading data:   4%|▋                    | 5.35M/152M [00:00<00:02, 53.5MB/s]\u001b[A\n",
            "Downloading data:  10%|██                   | 14.6M/152M [00:00<00:01, 76.4MB/s]\u001b[A\n",
            "Downloading data:  16%|███▎                 | 24.2M/152M [00:00<00:01, 85.2MB/s]\u001b[A\n",
            "Downloading data:  22%|████▋                | 33.8M/152M [00:00<00:01, 89.6MB/s]\u001b[A\n",
            "Downloading data:  29%|█████▉               | 43.2M/152M [00:00<00:01, 91.2MB/s]\u001b[A\n",
            "Downloading data:  35%|███████▎             | 52.8M/152M [00:00<00:01, 92.8MB/s]\u001b[A\n",
            "Downloading data:  41%|████████▋            | 62.3M/152M [00:00<00:00, 93.6MB/s]\u001b[A\n",
            "Downloading data:  48%|█████████▉           | 72.0M/152M [00:00<00:00, 94.6MB/s]\u001b[A\n",
            "Downloading data:  54%|███████████▎         | 81.7M/152M [00:00<00:00, 95.4MB/s]\u001b[A\n",
            "Downloading data:  60%|████████████▋        | 91.4M/152M [00:01<00:00, 95.9MB/s]\u001b[A\n",
            "Downloading data:  67%|██████████████▋       | 101M/152M [00:01<00:00, 95.9MB/s]\u001b[A\n",
            "Downloading data:  73%|████████████████      | 111M/152M [00:01<00:00, 94.5MB/s]\u001b[A\n",
            "Downloading data:  79%|█████████████████▍    | 120M/152M [00:01<00:00, 90.0MB/s]\u001b[A\n",
            "Downloading data:  86%|██████████████████▊   | 130M/152M [00:01<00:00, 91.5MB/s]\u001b[A\n",
            "Downloading data:  92%|████████████████████▏ | 139M/152M [00:01<00:00, 92.7MB/s]\u001b[A\n",
            "Downloading data: 100%|██████████████████████| 152M/152M [00:01<00:00, 91.8MB/s]\u001b[A\n",
            "Downloading data files: 100%|█████████████████████| 1/1 [00:02<00:00,  2.32s/it]\n",
            "Extracting data files: 100%|████████████████████| 1/1 [00:00<00:00, 1842.03it/s]\n",
            "Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/ehartford___json/ehartford--wizard_vicuna_70k_unfiltered-71f549fba4cffce0/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4. Subsequent calls will reuse this data.\n",
            "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 507.97it/s]\n",
            "INFO:root:tokenizing, merging, and shuffling master dataset\n",
            "WARNING:root:role with empty message: ASSISTANT\n",
            "Traceback (most recent call last):\n",
            "  File \"/workspace/axolotl/scripts/finetune.py\", line 321, in <module>\n",
            "    fire.Fire(train)\n",
            "  File \"/root/miniconda3/envs/py3.9/lib/python3.9/site-packages/fire/core.py\", line 141, in Fire\n",
            "    component_trace = _Fire(component, args, parsed_flag_args, context, name)\n",
            "  File \"/root/miniconda3/envs/py3.9/lib/python3.9/site-packages/fire/core.py\", line 475, in _Fire\n",
            "    component, remaining_args = _CallAndUpdateTrace(\n",
            "  File \"/root/miniconda3/envs/py3.9/lib/python3.9/site-packages/fire/core.py\", line 691, in _CallAndUpdateTrace\n",
            "    component = fn(*varargs, **kwargs)\n",
            "  File \"/workspace/axolotl/scripts/finetune.py\", line 211, in train\n",
            "    train_dataset, eval_dataset = load_prepare_datasets(\n",
            "  File \"/workspace/axolotl/src/axolotl/utils/data.py\", line 384, in load_prepare_datasets\n",
            "    dataset = load_tokenized_prepared_datasets(\n",
            "  File \"/workspace/axolotl/src/axolotl/utils/data.py\", line 255, in load_tokenized_prepared_datasets\n",
            "    samples = samples + list(d)\n",
            "  File \"/workspace/axolotl/src/axolotl/datasets.py\", line 45, in __iter__\n",
            "    raise RuntimeError(\"Expected at least one datapoint in dataset.\")\n",
            "RuntimeError: Expected at least one datapoint in dataset.\n"
          ]
        }
      ],
      "source": [
        "!python scripts/finetune.py examples/falcon/config-40b-qlora.yml -prepare_ds_only"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3E1gNNve8sra"
      },
      "source": [
        "# Chores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmp8Th0D8sra"
      },
      "source": [
        "## Clean up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BfQXJ3CpXJ_d"
      },
      "outputs": [],
      "source": [
        "!rm -rf /content/axolotl/last_run_prepared"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RyO-KRuB8srb"
      },
      "source": [
        "## `sharegpt_jokes` Patch\n",
        "\n",
        "https://github.com/OpenAccess-AI-Collective/axolotl/pull/192"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_jJLqlr-XXHM",
        "outputId": "294d36dc-4670-4312-c388-2cb7c4c1cdb9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/workspace\n"
          ]
        }
      ],
      "source": [
        "%cd /workspace/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7GR9EKon8srb"
      },
      "outputs": [],
      "source": [
        "!rm -rf axolotl-patch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L5OY6kWv8src",
        "outputId": "a78b6dbf-296b-4fc0-dc88-23ac4e7e3c5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'axolotl-patch'...\n",
            "remote: Enumerating objects: 2985, done.\u001b[K\n",
            "remote: Counting objects: 100% (1179/1179), done.\u001b[K\n",
            "remote: Compressing objects: 100% (294/294), done.\u001b[K\n",
            "remote: Total 2985 (delta 976), reused 978 (delta 849), pack-reused 1806\u001b[K\n",
            "Receiving objects: 100% (2985/2985), 1.39 MiB | 1.96 MiB/s, done.\n",
            "Resolving deltas: 100% (1866/1866), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/OpenAccess-AI-Collective/axolotl axolotl-patch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IXssp8b98src",
        "outputId": "0c71a37d-ae16-48ba-b89d-8c497085b5de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/workspace/axolotl-patch\n"
          ]
        }
      ],
      "source": [
        "%cd axolotl-patch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YaosxjA88src",
        "outputId": "603ed259-6612-4509-c5ef-ab3e95ab9c78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Branch 'sharegpt-custom-prompt' set up to track remote branch 'sharegpt-custom-prompt' from 'origin'.\n",
            "Switched to a new branch 'sharegpt-custom-prompt'\n"
          ]
        }
      ],
      "source": [
        "!git checkout sharegpt-custom-prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T_VlO2_L8src",
        "outputId": "8cfe4131-d8e6-4c74-dc95-2f98b5f397d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "On branch sharegpt-custom-prompt\n",
            "Your branch is up to date with 'origin/sharegpt-custom-prompt'.\n",
            "\n",
            "nothing to commit, working tree clean\n"
          ]
        }
      ],
      "source": [
        "!git status"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VPGSaf6u8srd",
        "outputId": "2e617590-f9ff-4ec0-d2bd-0042755a2d8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/workspace\n"
          ]
        }
      ],
      "source": [
        "%cd /workspace/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fCJwdeQF8srd"
      },
      "outputs": [],
      "source": [
        "!cp -r axolotl-patch/* axolotl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TOQKrk2t8srd",
        "outputId": "5e3a80be-1d15-40e1-d872-f3349c5ac3bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/workspace/axolotl\n"
          ]
        }
      ],
      "source": [
        "%cd axolotl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NnEYqKF18srd",
        "outputId": "d8fa4e09-bd61-4f86-9fa2-40ee0b2659e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "On branch main\n",
            "Your branch is up to date with 'origin/main'.\n",
            "\n",
            "Changes not staged for commit:\n",
            "  (use \"git add <file>...\" to update what will be committed)\n",
            "  (use \"git restore <file>...\" to discard changes in working directory)\n",
            "\t\u001b[31mmodified:   FAQS.md\u001b[m\n",
            "\t\u001b[31mmodified:   README.md\u001b[m\n",
            "\t\u001b[31mmodified:   docker/Dockerfile\u001b[m\n",
            "\t\u001b[31mmodified:   docker/Dockerfile-base\u001b[m\n",
            "\t\u001b[31mmodified:   examples/gptq-lora-7b/config.yml\u001b[m\n",
            "\t\u001b[31mmodified:   examples/mpt-7b/config.yml\u001b[m\n",
            "\t\u001b[31mmodified:   requirements.txt\u001b[m\n",
            "\t\u001b[31mmodified:   scripts/finetune.py\u001b[m\n",
            "\t\u001b[31mmodified:   scripts/runpod-entrypoint.sh\u001b[m\n",
            "\t\u001b[31mmodified:   src/axolotl/datasets.py\u001b[m\n",
            "\t\u001b[31mmodified:   src/axolotl/flash_attn.py\u001b[m\n",
            "\t\u001b[31mmodified:   src/axolotl/prompt_strategies/alpaca_chat.py\u001b[m\n",
            "\t\u001b[31mmodified:   src/axolotl/prompters.py\u001b[m\n",
            "\t\u001b[31mmodified:   src/axolotl/utils/data.py\u001b[m\n",
            "\t\u001b[31mmodified:   src/axolotl/utils/models.py\u001b[m\n",
            "\t\u001b[31mmodified:   src/axolotl/utils/trainer.py\u001b[m\n",
            "\t\u001b[31mmodified:   src/axolotl/utils/validation.py\u001b[m\n",
            "\t\u001b[31mmodified:   src/axolotl/utils/wandb.py\u001b[m\n",
            "\t\u001b[31mmodified:   tests/test_prompt_tokenizers.py\u001b[m\n",
            "\t\u001b[31mmodified:   tests/test_validation.py\u001b[m\n",
            "\n",
            "Untracked files:\n",
            "  (use \"git add <file>...\" to include in what will be committed)\n",
            "\t\u001b[31mdocker-compose.yaml\u001b[m\n",
            "\t\u001b[31mexamples/cerebras/\u001b[m\n",
            "\t\u001b[31mexamples/falcon/config-7b-qlora.yml\u001b[m\n",
            "\t\u001b[31mexamples/falcon/ft.yml\u001b[m\n",
            "\t\u001b[31mexamples/falcon/lora.yml\u001b[m\n",
            "\t\u001b[31mexamples/falcon/qlora.yml\u001b[m\n",
            "\t\u001b[31mexamples/gptj/\u001b[m\n",
            "\t\u001b[31mexamples/huggyllama/\u001b[m\n",
            "\t\u001b[31mexamples/jeopardy-bot/\u001b[m\n",
            "\t\u001b[31mexamples/openllama-3b/\u001b[m\n",
            "\t\u001b[31mexamples/openllama/\u001b[m\n",
            "\t\u001b[31mexamples/pythia/\u001b[m\n",
            "\t\u001b[31mimage/axolotl-badge-web.png\u001b[m\n",
            "\t\u001b[31msrc/axolotl/monkeypatch/\u001b[m\n",
            "\t\u001b[31msrc/axolotl/prompt_strategies/context_qa.py\u001b[m\n",
            "\t\u001b[31msrc/axolotl/prompt_strategies/sharegpt_jokes.py\u001b[m\n",
            "\t\u001b[31msrc/axolotl/prompt_strategies/sharegpt_simple.py\u001b[m\n",
            "\t\u001b[31mtests/fixtures/alpaca/\u001b[m\n",
            "\t\u001b[31mtests/test_packed_dataset.py\u001b[m\n",
            "\n",
            "no changes added to commit (use \"git add\" and/or \"git commit -a\")\n"
          ]
        }
      ],
      "source": [
        "!git status"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Q7JUhPl8srd"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "064dc7a36e3141a7bda70adb723791f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "PasswordModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_16b9ed34f3494401b5bbd8103b67097a",
            "placeholder": "​",
            "style": "IPY_MODEL_5c68d498914448cda16a6a1d37be1780",
            "value": ""
          }
        },
        "07e43ba6fbe44f2b94fab16e970d3a02": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0dd2b6777bec401b867867a5cdbedd23": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c62beb828d2f4c1ca13e50736d817232",
            "placeholder": "​",
            "style": "IPY_MODEL_cd9a2b859a05461f9ddee1ad98d77bf5",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "13def2c1464a4eada87d139eaaf8773e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "16b9ed34f3494401b5bbd8103b67097a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1cb197ba0137492fb8e953b05d73d0d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89273b45582947faa13889eed2a04ff6",
            "placeholder": "​",
            "style": "IPY_MODEL_ba4c7ffae5e8419ba99e126666148b49",
            "value": "Login successful"
          }
        },
        "29a22c57ce28449cbb062b493124c68c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3440a93ed74749358bae76d2bd8861ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "34b6dd2b7e264c2394bb1d79a05bc065": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d420532df0e438da7d94ab32e6ebb22": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6f7e6381b6fd4301a3ddf02d351caa50",
              "IPY_MODEL_99aab7f417784805a2b7c94e7a9d549f",
              "IPY_MODEL_6effd08048af4f1091973d4b5dc74694",
              "IPY_MODEL_1cb197ba0137492fb8e953b05d73d0d7"
            ],
            "layout": "IPY_MODEL_54ac694cc9a34de2afcc4077b6611936"
          }
        },
        "54ac694cc9a34de2afcc4077b6611936": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "5654a4fc9e1a4cf9b48d233329fe3c75": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57bf0e73135643b09821981f1bcbd971": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5654a4fc9e1a4cf9b48d233329fe3c75",
            "placeholder": "​",
            "style": "IPY_MODEL_3440a93ed74749358bae76d2bd8861ab",
            "value": "Connecting..."
          }
        },
        "5c68d498914448cda16a6a1d37be1780": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "608f3bf410e942b887c138de6429c2a1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ad4144260cb4733933947fd26bfbc25": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "6effd08048af4f1091973d4b5dc74694": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_34b6dd2b7e264c2394bb1d79a05bc065",
            "placeholder": "​",
            "style": "IPY_MODEL_29a22c57ce28449cbb062b493124c68c",
            "value": "Your token has been saved to /root/.cache/huggingface/token"
          }
        },
        "6f7e6381b6fd4301a3ddf02d351caa50": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_febd7a732c4e408cbde580a1c8db57f0",
            "placeholder": "​",
            "style": "IPY_MODEL_c30292fd334143c3803cfbb69cf9a67f",
            "value": "Token is valid (permission: write)."
          }
        },
        "79bb8e0094ff4b6d85460391781309b4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89273b45582947faa13889eed2a04ff6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c56af0ee49c4992a2644ad1ff3c0404": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_f8d0567cf49b498092a965abbe041133",
            "style": "IPY_MODEL_6ad4144260cb4733933947fd26bfbc25",
            "tooltip": ""
          }
        },
        "8ea6ca6af7a04e7cba7b93eda06ae420": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99aab7f417784805a2b7c94e7a9d549f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_608f3bf410e942b887c138de6429c2a1",
            "placeholder": "​",
            "style": "IPY_MODEL_07e43ba6fbe44f2b94fab16e970d3a02",
            "value": "Your token has been saved in your configured git credential helpers (store)."
          }
        },
        "ba4c7ffae5e8419ba99e126666148b49": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c1f0fd41f0b54a59be62e086db7459c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c30292fd334143c3803cfbb69cf9a67f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c62beb828d2f4c1ca13e50736d817232": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd9a2b859a05461f9ddee1ad98d77bf5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d3e29b6ef6ab49e987c284dec6a9aedb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "CheckboxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_79bb8e0094ff4b6d85460391781309b4",
            "style": "IPY_MODEL_c1f0fd41f0b54a59be62e086db7459c3",
            "value": true
          }
        },
        "e470289f17114e4cb76f7d3e2b755ad7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ea6ca6af7a04e7cba7b93eda06ae420",
            "placeholder": "​",
            "style": "IPY_MODEL_13def2c1464a4eada87d139eaaf8773e",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "f8d0567cf49b498092a965abbe041133": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "febd7a732c4e408cbde580a1c8db57f0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}