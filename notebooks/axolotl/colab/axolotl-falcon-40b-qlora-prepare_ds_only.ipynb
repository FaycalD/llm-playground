{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/utensil/llm-playground/blob/main/notebooks/axolotl/colab/axolotl-falcon-40b-qlora-prepare_ds_only.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97yoSiRvDY7G"
      },
      "source": [
        "# Prepare dataset (on Colab) for Finetuning falcon-40b\n",
        "\n",
        "- Axolotl+QLoRA\n",
        "- minotaur datasets\n",
        "- deepspeed ZeRO 3 8xGPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCpbQuaxDY7H"
      },
      "source": [
        "<!-- https://jupyterlab.readthedocs.io/en/stable/user/commands.html#commands-list -->\n",
        "<button data-commandLinker-command=\"apputils:change-theme\" data-commandlinker-args='{\"theme\": \"JupyterLab Dark\"}' href=\"#\">Dark theme</button>\n",
        "<button data-commandLinker-command=\"filebrowser:go-to-path\" data-commandlinker-args='{\"path\": \"/workspace/llm-playground/\"}' href=\"#\">llm-playground</button>\n",
        "<button data-commandLinker-command=\"filebrowser:go-to-path\" data-commandlinker-args='{\"path\": \"/workspace/axolotl/\"}' href=\"#\">axolotl</button>\n",
        "<button data-commandLinker-command=\"filebrowser:go-to-path\" data-commandlinker-args='{\"path\": \"/workspace/llm-playground/notebooks/axolotl/runpod\"}' href=\"#\">Runpod notebooks</button>\n",
        "<button data-commandLinker-command=\"filebrowser:go-to-path\" data-commandlinker-args='{\"path\": \"/workspace/axolotl/examples\"}' href=\"#\">axolotl configs</button>\n",
        "<button data-commandLinker-command=\"filebrowser:go-to-path\" data-commandlinker-args='{\"path\": \"/workspace/llm-playground/storage\"}' href=\"#\">Storage</button>\n",
        "<button data-commandLinker-command=\"filebrowser:go-to-path\" data-commandlinker-args='{\"path\": \"/workspace/llm-playground/axolotl-trained\"}' href=\"#\">axolotl-trained</button>\n",
        "<button data-commandLinker-command=\"docmanager:open\" data-commandlinker-args='{\"path\": \"/workspace/axolotl/examples/falcon/config-40b-qlora.yml\"}' href=\"#\">Edit config</button>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICK_4OyeQdfn",
        "outputId": "d366b1af-f189-47af-9675-97f00587dc9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'axolotl'...\n",
            "remote: Enumerating objects: 2985, done.\u001b[K\n",
            "remote: Counting objects: 100% (1179/1179), done.\u001b[K\n",
            "remote: Compressing objects: 100% (294/294), done.\u001b[K\n",
            "remote: Total 2985 (delta 976), reused 978 (delta 849), pack-reused 1806\n",
            "Receiving objects: 100% (2985/2985), 1.39 MiB | 7.16 MiB/s, done.\n",
            "Resolving deltas: 100% (1866/1866), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/OpenAccess-AI-Collective/axolotl.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_P9uKMPoOFh6",
        "outputId": "1f1714ef-5bdd-4fbb-e65f-33c61883c642"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/workspace/axolotl\n"
          ]
        }
      ],
      "source": [
        "%cd /workspace/axolotl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hb4i9d9gQydE",
        "outputId": "700a2abf-5bf4-47b6-840c-780528e73ba3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Obtaining file:///workspace/axolotl\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting transformers@ git+https://github.com/huggingface/transformers.git (from axolotl==0.1)\n",
            "  Cloning https://github.com/huggingface/transformers.git to /tmp/pip-install-6qt0ze0g/transformers_622ada43523a4cc595d97ee326b89ec2\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git /tmp/pip-install-6qt0ze0g/transformers_622ada43523a4cc595d97ee326b89ec2\n",
            "  Resolved https://github.com/huggingface/transformers.git to commit dadc9fb4275f4b7c2984d16d6d9a7880ec76d872\n",
            "  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: bitsandbytes>=0.39.0 in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages/bitsandbytes-0.39.0-py3.9.egg (from axolotl==0.1) (0.39.0)\n",
            "Requirement already satisfied: accelerate in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from axolotl==0.1) (0.21.0.dev0)\n",
            "Requirement already satisfied: addict in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from axolotl==0.1) (2.4.0)\n",
            "Requirement already satisfied: fire in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from axolotl==0.1) (0.5.0)\n",
            "Requirement already satisfied: PyYAML==6.0 in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from axolotl==0.1) (6.0)\n",
            "Requirement already satisfied: datasets in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from axolotl==0.1) (2.12.0)\n",
            "Requirement already satisfied: sentencepiece in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from axolotl==0.1) (0.1.99)\n",
            "Requirement already satisfied: wandb in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from axolotl==0.1) (0.15.3)\n",
            "Requirement already satisfied: einops in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from axolotl==0.1) (0.6.1)\n",
            "Requirement already satisfied: xformers in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from axolotl==0.1) (0.0.20)\n",
            "Requirement already satisfied: bert-score==0.3.13 in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from axolotl==0.1) (0.3.13)\n",
            "Requirement already satisfied: evaluate==0.4.0 in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from axolotl==0.1) (0.4.0)\n",
            "Requirement already satisfied: rouge-score==0.1.2 in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from axolotl==0.1) (0.1.2)\n",
            "Requirement already satisfied: scipy in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from axolotl==0.1) (1.10.1)\n",
            "Requirement already satisfied: scikit-learn==1.2.2 in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from axolotl==0.1) (1.2.2)\n",
            "Requirement already satisfied: torch>=1.0.0 in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from bert-score==0.3.13->axolotl==0.1) (2.0.1)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from bert-score==0.3.13->axolotl==0.1) (2.0.2)\n",
            "Requirement already satisfied: numpy in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from bert-score==0.3.13->axolotl==0.1) (1.24.3)\n",
            "Requirement already satisfied: requests in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from bert-score==0.3.13->axolotl==0.1) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.31.1 in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from bert-score==0.3.13->axolotl==0.1) (4.65.0)\n",
            "Requirement already satisfied: matplotlib in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from bert-score==0.3.13->axolotl==0.1) (3.7.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from bert-score==0.3.13->axolotl==0.1) (23.1)\n",
            "Requirement already satisfied: dill in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from evaluate==0.4.0->axolotl==0.1) (0.3.6)\n",
            "Requirement already satisfied: xxhash in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from evaluate==0.4.0->axolotl==0.1) (3.2.0)\n",
            "Requirement already satisfied: multiprocess in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from evaluate==0.4.0->axolotl==0.1) (0.70.14)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from evaluate==0.4.0->axolotl==0.1) (2023.5.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from evaluate==0.4.0->axolotl==0.1) (0.14.1)\n",
            "Requirement already satisfied: responses<0.19 in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from evaluate==0.4.0->axolotl==0.1) (0.18.0)\n",
            "Requirement already satisfied: absl-py in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from rouge-score==0.1.2->axolotl==0.1) (1.4.0)\n",
            "Requirement already satisfied: nltk in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from rouge-score==0.1.2->axolotl==0.1) (3.8.1)\n",
            "Requirement already satisfied: six>=1.14.0 in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from rouge-score==0.1.2->axolotl==0.1) (1.16.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from scikit-learn==1.2.2->axolotl==0.1) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from scikit-learn==1.2.2->axolotl==0.1) (3.1.0)\n",
            "Requirement already satisfied: psutil in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from accelerate->axolotl==0.1) (5.9.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from datasets->axolotl==0.1) (12.0.0)\n",
            "Requirement already satisfied: aiohttp in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from datasets->axolotl==0.1) (3.8.4)\n",
            "Requirement already satisfied: filelock in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from transformers@ git+https://github.com/huggingface/transformers.git->axolotl==0.1) (3.12.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from transformers@ git+https://github.com/huggingface/transformers.git->axolotl==0.1) (2023.5.5)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from transformers@ git+https://github.com/huggingface/transformers.git->axolotl==0.1) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from transformers@ git+https://github.com/huggingface/transformers.git->axolotl==0.1) (0.3.1)\n",
            "Requirement already satisfied: termcolor in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from fire->axolotl==0.1) (2.3.0)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from wandb->axolotl==0.1) (8.1.3)\n",
            "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from wandb->axolotl==0.1) (3.1.31)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from wandb->axolotl==0.1) (1.24.0)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from wandb->axolotl==0.1) (0.4.0)\n",
            "Requirement already satisfied: pathtools in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from wandb->axolotl==0.1) (0.1.2)\n",
            "Requirement already satisfied: setproctitle in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from wandb->axolotl==0.1) (1.3.2)\n",
            "Requirement already satisfied: setuptools in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from wandb->axolotl==0.1) (67.8.0)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from wandb->axolotl==0.1) (1.4.4)\n",
            "Requirement already satisfied: typing-extensions in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from wandb->axolotl==0.1) (4.6.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.15.0 in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from wandb->axolotl==0.1) (4.23.2)\n",
            "Requirement already satisfied: pyre-extensions==0.0.29 in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from xformers->axolotl==0.1) (0.0.29)\n",
            "Requirement already satisfied: typing-inspect in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from pyre-extensions==0.0.29->xformers->axolotl==0.1) (0.9.0)\n",
            "Requirement already satisfied: sympy in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from torch>=1.0.0->bert-score==0.3.13->axolotl==0.1) (1.12)\n",
            "Requirement already satisfied: networkx in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from torch>=1.0.0->bert-score==0.3.13->axolotl==0.1) (3.1)\n",
            "Requirement already satisfied: jinja2 in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from torch>=1.0.0->bert-score==0.3.13->axolotl==0.1) (3.1.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from torch>=1.0.0->bert-score==0.3.13->axolotl==0.1) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from torch>=1.0.0->bert-score==0.3.13->axolotl==0.1) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from torch>=1.0.0->bert-score==0.3.13->axolotl==0.1) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from torch>=1.0.0->bert-score==0.3.13->axolotl==0.1) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from torch>=1.0.0->bert-score==0.3.13->axolotl==0.1) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from torch>=1.0.0->bert-score==0.3.13->axolotl==0.1) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from torch>=1.0.0->bert-score==0.3.13->axolotl==0.1) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from torch>=1.0.0->bert-score==0.3.13->axolotl==0.1) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from torch>=1.0.0->bert-score==0.3.13->axolotl==0.1) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from torch>=1.0.0->bert-score==0.3.13->axolotl==0.1) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from torch>=1.0.0->bert-score==0.3.13->axolotl==0.1) (11.7.91)\n",
            "Requirement already satisfied: triton==2.0.0 in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from torch>=1.0.0->bert-score==0.3.13->axolotl==0.1) (2.0.0)\n",
            "Requirement already satisfied: wheel in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.0.0->bert-score==0.3.13->axolotl==0.1) (0.40.0)\n",
            "Requirement already satisfied: cmake in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from triton==2.0.0->torch>=1.0.0->bert-score==0.3.13->axolotl==0.1) (3.26.3)\n",
            "Requirement already satisfied: lit in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from triton==2.0.0->torch>=1.0.0->bert-score==0.3.13->axolotl==0.1) (16.0.5)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from aiohttp->datasets->axolotl==0.1) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from aiohttp->datasets->axolotl==0.1) (3.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from aiohttp->datasets->axolotl==0.1) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from aiohttp->datasets->axolotl==0.1) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from aiohttp->datasets->axolotl==0.1) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from aiohttp->datasets->axolotl==0.1) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from aiohttp->datasets->axolotl==0.1) (1.3.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb->axolotl==0.1) (4.0.10)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from pandas>=1.0.1->bert-score==0.3.13->axolotl==0.1) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from pandas>=1.0.1->bert-score==0.3.13->axolotl==0.1) (2023.3)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from pandas>=1.0.1->bert-score==0.3.13->axolotl==0.1) (2023.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from requests->bert-score==0.3.13->axolotl==0.1) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from requests->bert-score==0.3.13->axolotl==0.1) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from requests->bert-score==0.3.13->axolotl==0.1) (2023.5.7)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from matplotlib->bert-score==0.3.13->axolotl==0.1) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from matplotlib->bert-score==0.3.13->axolotl==0.1) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from matplotlib->bert-score==0.3.13->axolotl==0.1) (4.39.4)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from matplotlib->bert-score==0.3.13->axolotl==0.1) (1.4.4)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from matplotlib->bert-score==0.3.13->axolotl==0.1) (9.5.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from matplotlib->bert-score==0.3.13->axolotl==0.1) (3.0.9)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from matplotlib->bert-score==0.3.13->axolotl==0.1) (5.12.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb->axolotl==0.1) (5.0.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib->bert-score==0.3.13->axolotl==0.1) (3.15.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from jinja2->torch>=1.0.0->bert-score==0.3.13->axolotl==0.1) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from sympy->torch>=1.0.0->bert-score==0.3.13->axolotl==0.1) (1.3.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from typing-inspect->pyre-extensions==0.0.29->xformers->axolotl==0.1) (1.0.0)\n",
            "Installing collected packages: axolotl\n",
            "  Attempting uninstall: axolotl\n",
            "    Found existing installation: axolotl 0.1\n",
            "    Uninstalling axolotl-0.1:\n",
            "      Successfully uninstalled axolotl-0.1\n",
            "  Running setup.py develop for axolotl\n",
            "Successfully installed axolotl-0.1\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting git+https://github.com/huggingface/peft.git\n",
            "  Cloning https://github.com/huggingface/peft.git to /tmp/pip-req-build-nykue8ep\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/peft.git /tmp/pip-req-build-nykue8ep\n",
            "  Resolved https://github.com/huggingface/peft.git to commit 189a6b8e357ecda05ccde13999e4c35759596a67\n",
            "  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from peft==0.4.0.dev0) (1.24.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from peft==0.4.0.dev0) (23.1)\n",
            "Requirement already satisfied: psutil in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from peft==0.4.0.dev0) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from peft==0.4.0.dev0) (6.0)\n",
            "Requirement already satisfied: torch>=1.13.0 in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from peft==0.4.0.dev0) (2.0.1)\n",
            "Requirement already satisfied: transformers in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from peft==0.4.0.dev0) (4.31.0.dev0)\n",
            "Requirement already satisfied: accelerate in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from peft==0.4.0.dev0) (0.21.0.dev0)\n",
            "Requirement already satisfied: safetensors in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from peft==0.4.0.dev0) (0.3.1)\n",
            "Requirement already satisfied: filelock in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from torch>=1.13.0->peft==0.4.0.dev0) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from torch>=1.13.0->peft==0.4.0.dev0) (4.6.2)\n",
            "Requirement already satisfied: sympy in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from torch>=1.13.0->peft==0.4.0.dev0) (1.12)\n",
            "Requirement already satisfied: networkx in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from torch>=1.13.0->peft==0.4.0.dev0) (3.1)\n",
            "Requirement already satisfied: jinja2 in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from torch>=1.13.0->peft==0.4.0.dev0) (3.1.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from torch>=1.13.0->peft==0.4.0.dev0) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from torch>=1.13.0->peft==0.4.0.dev0) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from torch>=1.13.0->peft==0.4.0.dev0) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from torch>=1.13.0->peft==0.4.0.dev0) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from torch>=1.13.0->peft==0.4.0.dev0) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from torch>=1.13.0->peft==0.4.0.dev0) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from torch>=1.13.0->peft==0.4.0.dev0) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from torch>=1.13.0->peft==0.4.0.dev0) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from torch>=1.13.0->peft==0.4.0.dev0) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from torch>=1.13.0->peft==0.4.0.dev0) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from torch>=1.13.0->peft==0.4.0.dev0) (11.7.91)\n",
            "Requirement already satisfied: triton==2.0.0 in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from torch>=1.13.0->peft==0.4.0.dev0) (2.0.0)\n",
            "Requirement already satisfied: setuptools in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.13.0->peft==0.4.0.dev0) (67.8.0)\n",
            "Requirement already satisfied: wheel in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.13.0->peft==0.4.0.dev0) (0.40.0)\n",
            "Requirement already satisfied: cmake in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from triton==2.0.0->torch>=1.13.0->peft==0.4.0.dev0) (3.26.3)\n",
            "Requirement already satisfied: lit in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from triton==2.0.0->torch>=1.13.0->peft==0.4.0.dev0) (16.0.5)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from transformers->peft==0.4.0.dev0) (0.14.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from transformers->peft==0.4.0.dev0) (2023.5.5)\n",
            "Requirement already satisfied: requests in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from transformers->peft==0.4.0.dev0) (2.31.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from transformers->peft==0.4.0.dev0) (0.13.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from transformers->peft==0.4.0.dev0) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers->peft==0.4.0.dev0) (2023.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from jinja2->torch>=1.13.0->peft==0.4.0.dev0) (2.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from requests->transformers->peft==0.4.0.dev0) (3.1.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from requests->transformers->peft==0.4.0.dev0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from requests->transformers->peft==0.4.0.dev0) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from requests->transformers->peft==0.4.0.dev0) (2023.5.7)\n",
            "Requirement already satisfied: mpmath>=0.19 in /root/miniconda3/envs/py3.9/lib/python3.9/site-packages (from sympy->torch>=1.13.0->peft==0.4.0.dev0) (1.3.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -e .\n",
        "!pip install -U git+https://github.com/huggingface/peft.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "3d420532df0e438da7d94ab32e6ebb22",
            "0dd2b6777bec401b867867a5cdbedd23",
            "064dc7a36e3141a7bda70adb723791f4",
            "d3e29b6ef6ab49e987c284dec6a9aedb",
            "8c56af0ee49c4992a2644ad1ff3c0404",
            "e470289f17114e4cb76f7d3e2b755ad7",
            "54ac694cc9a34de2afcc4077b6611936",
            "c62beb828d2f4c1ca13e50736d817232",
            "cd9a2b859a05461f9ddee1ad98d77bf5",
            "16b9ed34f3494401b5bbd8103b67097a",
            "5c68d498914448cda16a6a1d37be1780",
            "79bb8e0094ff4b6d85460391781309b4",
            "c1f0fd41f0b54a59be62e086db7459c3",
            "f8d0567cf49b498092a965abbe041133",
            "6ad4144260cb4733933947fd26bfbc25",
            "8ea6ca6af7a04e7cba7b93eda06ae420",
            "13def2c1464a4eada87d139eaaf8773e",
            "57bf0e73135643b09821981f1bcbd971",
            "5654a4fc9e1a4cf9b48d233329fe3c75",
            "3440a93ed74749358bae76d2bd8861ab",
            "6f7e6381b6fd4301a3ddf02d351caa50",
            "99aab7f417784805a2b7c94e7a9d549f",
            "6effd08048af4f1091973d4b5dc74694",
            "1cb197ba0137492fb8e953b05d73d0d7",
            "febd7a732c4e408cbde580a1c8db57f0",
            "c30292fd334143c3803cfbb69cf9a67f",
            "608f3bf410e942b887c138de6429c2a1",
            "07e43ba6fbe44f2b94fab16e970d3a02",
            "34b6dd2b7e264c2394bb1d79a05bc065",
            "29a22c57ce28449cbb062b493124c68c",
            "89273b45582947faa13889eed2a04ff6",
            "ba4c7ffae5e8419ba99e126666148b49",
            "db970e6ef6154bef98116a5bf180c7f0",
            "eb654d390d58424da55c565b356ae435"
          ]
        },
        "id": "APgdb2JHO8FV",
        "outputId": "f6385a91-95cd-45a5-9a45-6ec85c0bfe58"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "eb654d390d58424da55c565b356ae435",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wWw91DLOC_l"
      },
      "source": [
        "# gsm8k"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMV1BTs_OJYu",
        "outputId": "fd4609c0-e0fb-472f-cc58-8556b025629c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting examples/falcon/config-40b-qlora.yml\n"
          ]
        }
      ],
      "source": [
        "%%writefile examples/falcon/config-40b-qlora.yml\n",
        "# 1b: tiiuae/falcon-rw-1b\n",
        "# 7b: tiiuae/falcon-7b\n",
        "# 40b: tiiuae/falcon-40b\n",
        "base_model: tiiuae/falcon-40b\n",
        "base_model_config: tiiuae/falcon-40b\n",
        "# required by falcon custom model code: https://huggingface.co/tiiuae/falcon-7b/tree/main\n",
        "trust_remote_code: true\n",
        "model_type: AutoModelForCausalLM\n",
        "tokenizer_type: AutoTokenizer\n",
        "load_in_8bit: false\n",
        "# enable 4bit for QLoRA\n",
        "load_in_4bit: true\n",
        "gptq: false\n",
        "strict: false\n",
        "\n",
        "push_dataset_to_hub: utensil\n",
        "hf_use_auth_token: true\n",
        "\n",
        "datasets:\n",
        "  - path: QingyiSi/Alpaca-CoT\n",
        "    data_files:\n",
        "      - Chain-of-Thought/formatted_cot_data/gsm8k_train.json\n",
        "    type: \"alpaca:chat\"\n",
        "\n",
        "dataset_prepared_path: last_run_prepared\n",
        "val_set_size: 0.01\n",
        "# enable QLoRA\n",
        "adapter: qlora\n",
        "lora_model_dir:\n",
        "sequence_len: 2048\n",
        "max_packed_sequence_len:\n",
        "\n",
        "# hyperparameters from QLoRA paper Appendix B.2\n",
        "# \"We find hyperparameters to be largely robust across datasets\"\n",
        "lora_r: 64\n",
        "lora_alpha: 16\n",
        "# 0.1 for models up to 13B\n",
        "# 0.05 for 33B and 65B models\n",
        "lora_dropout: 0.05\n",
        "# add LoRA modules on all linear layers of the base model\n",
        "lora_target_modules:\n",
        "lora_target_linear: true\n",
        "lora_fan_in_fan_out:\n",
        "\n",
        "wandb_project: falcon-qlora\n",
        "wandb_watch:\n",
        "wandb_run_id:\n",
        "wandb_log_model:\n",
        "output_dir: /workspace/llm-playground/axolotl-trained/falcon-qlora-40b-gsm8k/\n",
        "\n",
        "# QLoRA paper Table 9\n",
        "# - 16 for 7b & 13b\n",
        "# - 32 for 33b, 64 for 64b\n",
        "# Max size tested on A6000\n",
        "# - 7b: 40\n",
        "# - 40b: 4\n",
        "# decrease if OOM, increase for max VRAM utilization\n",
        "micro_batch_size: 1\n",
        "gradient_accumulation_steps: 2\n",
        "num_epochs: 3\n",
        "# Optimizer for QLoRA\n",
        "optimizer: paged_adamw_32bit\n",
        "torchdistx_path:\n",
        "lr_scheduler: cosine\n",
        "# QLoRA paper Table 9\n",
        "# - 2e-4 for 7b & 13b\n",
        "# - 1e-4 for 33b & 64b\n",
        "learning_rate: 0.0002\n",
        "train_on_inputs: false\n",
        "group_by_length: false\n",
        "bf16: true\n",
        "fp16: false\n",
        "tf32: true\n",
        "gradient_checkpointing: true\n",
        "# stop training after this many evaluation losses have increased in a row\n",
        "# https://huggingface.co/transformers/v4.2.2/_modules/transformers/trainer_callback.html#EarlyStoppingCallback\n",
        "early_stopping_patience: 3\n",
        "resume_from_checkpoint:\n",
        "auto_resume_from_checkpoints: true\n",
        "local_rank:\n",
        "logging_steps: 1\n",
        "xformers_attention: true\n",
        "flash_attention:\n",
        "gptq_groupsize:\n",
        "gptq_model_v1:\n",
        "warmup_steps: 10\n",
        "eval_steps: 5\n",
        "save_steps: 10\n",
        "debug:\n",
        "deepspeed:\n",
        "weight_decay: 0.01\n",
        "fsdp:\n",
        "fsdp_config:\n",
        "special_tokens:\n",
        "  pad_token: \"<|endoftext|>\"\n",
        "  bos_token: \">>ABSTRACT<<\"\n",
        "  eos_token: \"<|endoftext|>\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aY3eLpM2OMzM",
        "outputId": "182d6c73-0162-4ca6-e5ab-204816a7bdfc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "===================================BUG REPORT===================================\n",
            "Welcome to bitsandbytes. For bug reports, please run\n",
            "\n",
            "python -m bitsandbytes\n",
            "\n",
            " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
            "================================================================================\n",
            "bin /usr/local/lib/python3.10/dist-packages/bitsandbytes/libbitsandbytes_cuda118.so\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: /usr/lib64-nvidia did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/sys/fs/cgroup/memory.events /var/colab/cgroup/jupyter-children/memory.events')}\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('http'), PosixPath('//172.28.0.1'), PosixPath('8013')}\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('--logtostderr --listen_host=172.28.0.12 --target_host=172.28.0.12 --tunnel_background_save_url=https'), PosixPath('//colab.research.google.com/tun/m/cc48301118ce562b961b3c22d803539adc1e0c19/gpu-t4-s-3qu49qpehlmmz --tunnel_background_save_delay=10s --tunnel_periodic_background_save_frequency=30m0s --enable_output_coalescing=true --output_coalescing_required=true')}\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/env/python')}\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('//ipykernel.pylab.backend_inline'), PosixPath('module')}\n",
            "  warn(msg)\n",
            "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching in backup paths...\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: Found duplicate ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] files: {PosixPath('/usr/local/cuda/lib64/libcudart.so.11.0'), PosixPath('/usr/local/cuda/lib64/libcudart.so')}.. We'll flip a coin and try one of these, in order to fail forward.\n",
            "Either way, this might cause trouble in the future:\n",
            "If you get `CUDA error: invalid device function` errors, the above might be the cause and the solution is to make sure only one ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] in the paths that we search based on your env.\n",
            "  warn(msg)\n",
            "CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so.11.0\n",
            "CUDA SETUP: Highest compute capability among GPUs detected: 7.5\n",
            "CUDA SETUP: Detected CUDA version 118\n",
            "CUDA SETUP: Loading binary /usr/local/lib/python3.10/dist-packages/bitsandbytes/libbitsandbytes_cuda118.so...\n",
            "2023-06-12 06:45:03.959717: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "WARNING:root:`trust_remote_code` is set to true. Please make sure that you reviewed the remote code/model.\n",
            "INFO:root:loading tokenizer... tiiuae/falcon-40b\n",
            "Using bos_token, but it is not set yet.\n",
            "Using pad_token, but it is not set yet.\n",
            "Using unk_token, but it is not set yet.\n",
            "INFO:root:Unable to find prepared dataset in last_run_prepared/31a4e867d804a957707db033c9abcd13\n",
            "INFO:root:Loading raw datasets...\n",
            "INFO:root:No seed provided, using default seed of 42\n",
            "WARNING:datasets.builder:Found cached dataset json (/root/.cache/huggingface/datasets/QingyiSi___json/QingyiSi--Alpaca-CoT-2953efcfeb19f105/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\n",
            "100% 1/1 [00:00<00:00, 748.85it/s]\n",
            "INFO:root:tokenizing, merging, and shuffling master dataset\n",
            "INFO:root:Saving merged prepared dataset to disk... last_run_prepared/31a4e867d804a957707db033c9abcd13\n",
            "INFO:root:Saving merged prepared dataset with push_to_hub... utensil/31a4e867d804a957707db033c9abcd13\n",
            "Pushing dataset shards to the dataset hub:   0% 0/1 [00:00<?, ?it/s]\n",
            "Creating parquet from Arrow format:   0% 0/8 [00:00<?, ?ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  38% 3/8 [00:00<00:00, 21.31ba/s]\u001b[A\n",
            "Creating parquet from Arrow format: 100% 8/8 [00:00<00:00, 22.66ba/s]\n",
            "\n",
            "Upload 1 LFS files:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Upload 1 LFS files: 100% 1/1 [00:00<00:00,  1.87it/s]\n",
            "Pushing dataset shards to the dataset hub: 100% 1/1 [00:01<00:00,  1.25s/it]\n",
            "INFO:root:Finished preparing dataset. Exiting...\n"
          ]
        }
      ],
      "source": [
        "!python scripts/finetune.py examples/falcon/config-40b-qlora.yml -prepare_ds_only"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XjMcoRRWSci-"
      },
      "outputs": [],
      "source": [
        "!rm -rf /content/axolotl/last_run_prepared"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2ko6jJPfTFD"
      },
      "source": [
        "# minotaur (deprecated)\n",
        "\n",
        "Datasets from https://huggingface.co/openaccess-ai-collective/minotaur-13b/blob/main/configs/minotaur.yml\n",
        "\n",
        "Plus [this fix](https://discord.com/channels/1104757954588196865/1116465236715786310/1117778180372185149)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2yxeT32XJ_c",
        "outputId": "a6f296b2-31de-4ee7-b0ae-81e6702adeb6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing examples/falcon/config-40b-qlora.yml\n"
          ]
        }
      ],
      "source": [
        "%%writefile examples/falcon/config-40b-qlora.yml\n",
        "# 1b: tiiuae/falcon-rw-1b\n",
        "# 7b: tiiuae/falcon-7b\n",
        "# 40b: tiiuae/falcon-40b\n",
        "base_model: tiiuae/falcon-40b\n",
        "base_model_config: tiiuae/falcon-40b\n",
        "# required by falcon custom model code: https://huggingface.co/tiiuae/falcon-7b/tree/main\n",
        "trust_remote_code: true\n",
        "model_type: AutoModelForCausalLM\n",
        "tokenizer_type: AutoTokenizer\n",
        "load_in_8bit: false\n",
        "# enable 4bit for QLoRA\n",
        "load_in_4bit: true\n",
        "gptq: false\n",
        "strict: false\n",
        "\n",
        "push_dataset_to_hub: utensil\n",
        "hf_use_auth_token: true\n",
        "\n",
        "datasets:\n",
        "  - path: winglian/evals\n",
        "    data_files:\n",
        "      - hf/ARC-Challenge.jsonl\n",
        "      - hf/ARC-Easy.jsonl\n",
        "      - hf/riddle_sense.jsonl\n",
        "    type: explainchoice:chat\n",
        "  - path: winglian/evals\n",
        "    data_files:\n",
        "      - hf/gsm8k.jsonl\n",
        "      - hf/winogrande.jsonl\n",
        "    type: alpaca_chat.load_qa\n",
        "  - path: winglian/evals\n",
        "    data_files:\n",
        "      - custom/n_task.jsonl\n",
        "      - custom/misconceptions.jsonl\n",
        "      - custom/context_insensitivity.jsonl\n",
        "    type: alpaca_chat\n",
        "  - path: camel-ai/math\n",
        "    type: alpaca_chat.load_camel_ai\n",
        "  - path: camel-ai/biology\n",
        "    type: alpaca_chat.load_camel_ai\n",
        "  - path: camel-ai/physics\n",
        "    type: alpaca_chat.load_camel_ai\n",
        "  - path: camel-ai/chemistry\n",
        "    type: alpaca_chat.load_camel_ai\n",
        "  - path: winglian/evals\n",
        "    data_files:\n",
        "      - custom/in_context_qa.jsonl\n",
        "    type: context_qa\n",
        "  - path: winglian/evals\n",
        "    data_files:\n",
        "      - custom/in_context_qa.jsonl\n",
        "    type: context_qa.load_404\n",
        "  - path: winglian/evals\n",
        "    data_files:\n",
        "      - custom/jokes_explained_500up.jsonl\n",
        "    type: sharegpt_jokes\n",
        "  - path: winglian/evals\n",
        "    data_files:\n",
        "      - custom/classify-self-chat.sharegpt.jsonl\n",
        "      - custom/coding-self-chat.sharegpt.jsonl\n",
        "      - custom/prose-gpt4.sharegpt.jsonl\n",
        "      - custom/prose-rewrite-gpt4.sharegpt.jsonl\n",
        "    type: sharegpt_simple.load_role\n",
        "  - path: winglian/evals\n",
        "    data_files:\n",
        "      - openai/tldr.jsonl\n",
        "    type: summarizetldr:chat\n",
        "  - path: winglian/evals\n",
        "    data_files:\n",
        "      - hellaswag/hellaswag.jsonl\n",
        "    type: explainchoice:chat\n",
        "  - path: metaeval/ScienceQA_text_only\n",
        "    type: concisechoice:chat\n",
        "  - path: teknium/GPT4-LLM-Cleaned\n",
        "    type: alpaca_chat\n",
        "  - path: teknium/GPTeacher-General-Instruct\n",
        "    data_files: gpt4-instruct-similarity-0.6-dataset.json\n",
        "    type: gpteacher:chat\n",
        "  - path: QingyiSi/Alpaca-CoT\n",
        "    data_files:\n",
        "      - Chain-of-Thought/formatted_cot_data/aqua_train.json\n",
        "      - Chain-of-Thought/formatted_cot_data/creak_train.json\n",
        "      - Chain-of-Thought/formatted_cot_data/ecqa_train.json\n",
        "      - Chain-of-Thought/formatted_cot_data/esnli_train.json\n",
        "      - Chain-of-Thought/formatted_cot_data/qasc_train.json\n",
        "      - Chain-of-Thought/formatted_cot_data/qed_train.json\n",
        "      - Chain-of-Thought/formatted_cot_data/sensemaking_train.json\n",
        "      - Chain-of-Thought/formatted_cot_data/strategyqa_train.json\n",
        "      - GPTeacher/Roleplay/formatted_roleplay-similarity_0.6-instruct-dataset.json\n",
        "    type: alpaca_chat\n",
        "  - path: ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered\n",
        "    type: alpaca_chat\n",
        "  - path: ehartford/wizard_vicuna_70k_unfiltered\n",
        "    type: sharegpt:chat\n",
        "\n",
        "dataset_prepared_path: last_run_prepared\n",
        "val_set_size: 0.01\n",
        "# enable QLoRA\n",
        "adapter: qlora\n",
        "lora_model_dir:\n",
        "sequence_len: 2048\n",
        "max_packed_sequence_len:\n",
        "\n",
        "# hyperparameters from QLoRA paper Appendix B.2\n",
        "# \"We find hyperparameters to be largely robust across datasets\"\n",
        "lora_r: 64\n",
        "lora_alpha: 16\n",
        "# 0.1 for models up to 13B\n",
        "# 0.05 for 33B and 65B models\n",
        "lora_dropout: 0.05\n",
        "# add LoRA modules on all linear layers of the base model\n",
        "lora_target_modules:\n",
        "lora_target_linear: true\n",
        "lora_fan_in_fan_out:\n",
        "\n",
        "wandb_project: falcon-qlora\n",
        "wandb_watch:\n",
        "wandb_run_id:\n",
        "wandb_log_model:\n",
        "output_dir: /workspace/llm-playground/axolotl-trained/falcon-qlora-40b-gsm8k/\n",
        "\n",
        "# QLoRA paper Table 9\n",
        "# - 16 for 7b & 13b\n",
        "# - 32 for 33b, 64 for 64b\n",
        "# Max size tested on A6000\n",
        "# - 7b: 40\n",
        "# - 40b: 4\n",
        "# decrease if OOM, increase for max VRAM utilization\n",
        "micro_batch_size: 1\n",
        "gradient_accumulation_steps: 2\n",
        "num_epochs: 3\n",
        "# Optimizer for QLoRA\n",
        "optimizer: paged_adamw_32bit\n",
        "torchdistx_path:\n",
        "lr_scheduler: cosine\n",
        "# QLoRA paper Table 9\n",
        "# - 2e-4 for 7b & 13b\n",
        "# - 1e-4 for 33b & 64b\n",
        "learning_rate: 0.0002\n",
        "train_on_inputs: false\n",
        "group_by_length: false\n",
        "bf16: true\n",
        "fp16: false\n",
        "tf32: true\n",
        "gradient_checkpointing: true\n",
        "# stop training after this many evaluation losses have increased in a row\n",
        "# https://huggingface.co/transformers/v4.2.2/_modules/transformers/trainer_callback.html#EarlyStoppingCallback\n",
        "early_stopping_patience: 3\n",
        "resume_from_checkpoint:\n",
        "auto_resume_from_checkpoints: true\n",
        "local_rank:\n",
        "logging_steps: 1\n",
        "xformers_attention: true\n",
        "flash_attention:\n",
        "gptq_groupsize:\n",
        "gptq_model_v1:\n",
        "warmup_steps: 10\n",
        "eval_steps: 5\n",
        "save_steps: 10\n",
        "debug:\n",
        "deepspeed:\n",
        "weight_decay: 0.01\n",
        "fsdp:\n",
        "fsdp_config:\n",
        "special_tokens:\n",
        "  pad_token: \"<|endoftext|>\"\n",
        "  bos_token: \">>ABSTRACT<<\"\n",
        "  eos_token: \"<|endoftext|>\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KvSjgxUrXJ_d",
        "outputId": "38a091d5-8a03-41e3-cb47-ff7c8cc0912b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "===================================BUG REPORT===================================\n",
            "Welcome to bitsandbytes. For bug reports, please run\n",
            "\n",
            "python -m bitsandbytes\n",
            "\n",
            " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
            "================================================================================\n",
            "bin /root/miniconda3/envs/py3.9/lib/python3.9/site-packages/bitsandbytes-0.39.0-py3.9.egg/bitsandbytes/libbitsandbytes_cuda118.so\n",
            "/root/miniconda3/envs/py3.9/lib/python3.9/site-packages/bitsandbytes-0.39.0-py3.9.egg/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/usr/local/nvidia/lib'), PosixPath('/usr/local/nvidia/lib64')}\n",
            "  warn(msg)\n",
            "/root/miniconda3/envs/py3.9/lib/python3.9/site-packages/bitsandbytes-0.39.0-py3.9.egg/bitsandbytes/cuda_setup/main.py:149: UserWarning: /usr/local/nvidia/lib:/usr/local/nvidia/lib64 did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...\n",
            "  warn(msg)\n",
            "/root/miniconda3/envs/py3.9/lib/python3.9/site-packages/bitsandbytes-0.39.0-py3.9.egg/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('//matplotlib_inline.backend_inline'), PosixPath('module')}\n",
            "  warn(msg)\n",
            "/root/miniconda3/envs/py3.9/lib/python3.9/site-packages/bitsandbytes-0.39.0-py3.9.egg/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQDvnE4umHheXhWsDJbbukYvvyc47/mC4z8syS93btA72T90WDrQagOy5O+DrhdXOvr5i/JwsTlAImy57eLRrtRFOrQq73jyi7Dzo0tvrAiNLVgX2q2dFLoplRyXDXiVYLPmPieMWQOeUCLeSb8FC5zzllcocZwjMXpxScDerZqnlAR0ccpSkGyKIod4ZMkn/29A/C5kHEb/wT8cOAq+MWJ/2okZZgbiR0AMV4DynAkrtcx9JnJnTs9chiMyH+dyCS42Ai24sHWJBkQo6TfxXkyKo9GOpu3Y2WLgrHyaot9Lk5mA1mujyIWdlReD2nvjeCQKjl3KW3xZ73m4nD97MydWSWoJfEWlr+VZvk8EWsZk3CYLZCIBLdod6xXJJ0DD0pvTIq11c8VB7XkgVjapuU/sC8M6HFzHW/NBeE+xX/txPkZkIGqrnxeQ0AtBXdN9ukyNGhGzTkPYJNliiYpY0dCvVuz/BJ2FawFTQGnD1EHOenUCRajREFGCbKoYZqi40j8= utensil@Utensils-MacBook-Pro.local')}\n",
            "  warn(msg)\n",
            "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching in backup paths...\n",
            "/root/miniconda3/envs/py3.9/lib/python3.9/site-packages/bitsandbytes-0.39.0-py3.9.egg/bitsandbytes/cuda_setup/main.py:149: UserWarning: Found duplicate ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] files: {PosixPath('/usr/local/cuda/lib64/libcudart.so'), PosixPath('/usr/local/cuda/lib64/libcudart.so.11.0')}.. We'll flip a coin and try one of these, in order to fail forward.\n",
            "Either way, this might cause trouble in the future:\n",
            "If you get `CUDA error: invalid device function` errors, the above might be the cause and the solution is to make sure only one ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] in the paths that we search based on your env.\n",
            "  warn(msg)\n",
            "CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so\n",
            "CUDA SETUP: Highest compute capability among GPUs detected: 8.6\n",
            "CUDA SETUP: Detected CUDA version 118\n",
            "CUDA SETUP: Loading binary /root/miniconda3/envs/py3.9/lib/python3.9/site-packages/bitsandbytes-0.39.0-py3.9.egg/bitsandbytes/libbitsandbytes_cuda118.so...\n",
            "Setting ds_accelerator to cuda (auto detect)\n",
            "WARNING:root:`trust_remote_code` is set to true. Please make sure that you reviewed the remote code/model.\n",
            "INFO:root:loading tokenizer... tiiuae/falcon-40b\n",
            "Downloading (…)okenizer_config.json: 100%|█████| 175/175 [00:00<00:00, 53.7kB/s]\n",
            "Downloading (…)/main/tokenizer.json: 100%|█| 2.73M/2.73M [00:00<00:00, 20.5MB/s]\n",
            "Downloading (…)cial_tokens_map.json: 100%|██████| 281/281 [00:00<00:00, 218kB/s]\n",
            "Using bos_token, but it is not set yet.\n",
            "Using pad_token, but it is not set yet.\n",
            "Using unk_token, but it is not set yet.\n",
            "INFO:root:Unable to find prepared dataset in last_run_prepared/9a63aa2c07ace8350a0e8b32ab913f2a\n",
            "INFO:root:Loading raw datasets...\n",
            "INFO:root:No seed provided, using default seed of 42\n",
            "Downloading readme: 100%|██████████████████████| 259/259 [00:00<00:00, 2.28MB/s]\n",
            "Downloading and preparing dataset json/winglian--evals to /root/.cache/huggingface/datasets/winglian___json/winglian--evals-967fbffa8fbc6a56/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4...\n",
            "Downloading data files:   0%|                             | 0/1 [00:00<?, ?it/s]\n",
            "Downloading data:   0%|                             | 0.00/2.05M [00:00<?, ?B/s]\u001b[A\n",
            "Downloading data:   4%|▊                    | 75.8k/2.05M [00:00<00:02, 732kB/s]\u001b[A\n",
            "Downloading data:   7%|█▌                    | 150k/2.05M [00:00<00:02, 700kB/s]\u001b[A\n",
            "Downloading data:  26%|█████▍               | 526k/2.05M [00:00<00:00, 1.70MB/s]\u001b[A\n",
            "Downloading data: 100%|████████████████████| 2.05M/2.05M [00:00<00:00, 4.20MB/s]\u001b[A\n",
            "\n",
            "Downloading data:   0%|                             | 0.00/3.22M [00:00<?, ?B/s]\u001b[A\n",
            "Downloading data:  27%|█████▋               | 882k/3.22M [00:00<00:00, 7.59MB/s]\u001b[A\n",
            "Downloading data: 100%|████████████████████| 3.22M/3.22M [00:00<00:00, 14.2MB/s]\u001b[A\n",
            "\n",
            "Downloading data:   0%|                             | 0.00/3.94M [00:00<?, ?B/s]\u001b[A\n",
            "Downloading data:   2%|▍                    | 89.1k/3.94M [00:00<00:07, 495kB/s]\u001b[A\n",
            "Downloading data:   8%|█▋                   | 307k/3.94M [00:00<00:03, 1.18MB/s]\u001b[A\n",
            "Downloading data:  28%|█████▌              | 1.10M/3.94M [00:00<00:00, 3.03MB/s]\u001b[A\n",
            "Downloading data: 100%|████████████████████| 3.94M/3.94M [00:00<00:00, 6.60MB/s]\u001b[A\n",
            "Downloading data files: 100%|█████████████████████| 1/1 [00:02<00:00,  2.90s/it]\n",
            "Extracting data files: 100%|█████████████████████| 1/1 [00:00<00:00, 451.15it/s]\n",
            "Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/winglian___json/winglian--evals-967fbffa8fbc6a56/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4. Subsequent calls will reuse this data.\n",
            "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 372.86it/s]\n",
            "Downloading and preparing dataset json/winglian--evals to /root/.cache/huggingface/datasets/winglian___json/winglian--evals-2d9807bf90eb06df/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4...\n",
            "Downloading data files:   0%|                             | 0/1 [00:00<?, ?it/s]\n",
            "Downloading data:   0%|                             | 0.00/7.79M [00:00<?, ?B/s]\u001b[A\n",
            "Downloading data:   1%|▏                    | 75.8k/7.79M [00:00<00:10, 729kB/s]\u001b[A\n",
            "Downloading data:   3%|▋                     | 239k/7.79M [00:00<00:08, 900kB/s]\u001b[A\n",
            "Downloading data:  12%|██▌                  | 943k/7.79M [00:00<00:02, 3.15MB/s]\u001b[A\n",
            "Downloading data:  28%|█████▋              | 2.19M/7.79M [00:00<00:00, 6.37MB/s]\u001b[A\n",
            "Downloading data:  39%|███████▉            | 3.07M/7.79M [00:00<00:00, 7.16MB/s]\u001b[A\n",
            "Downloading data: 100%|████████████████████| 7.79M/7.79M [00:00<00:00, 10.5MB/s]\u001b[A\n",
            "\n",
            "Downloading data:   0%|                             | 0.00/5.89M [00:00<?, ?B/s]\u001b[A\n",
            "Downloading data:   4%|▊                    | 216k/5.89M [00:00<00:02, 2.00MB/s]\u001b[A\n",
            "Downloading data:  28%|█████▌              | 1.65M/5.89M [00:00<00:00, 6.56MB/s]\u001b[A\n",
            "Downloading data: 100%|████████████████████| 5.89M/5.89M [00:00<00:00, 12.6MB/s]\u001b[A\n",
            "Downloading data files: 100%|█████████████████████| 1/1 [00:04<00:00,  4.27s/it]\n",
            "Extracting data files: 100%|█████████████████████| 1/1 [00:00<00:00, 645.28it/s]\n",
            "Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/winglian___json/winglian--evals-2d9807bf90eb06df/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4. Subsequent calls will reuse this data.\n",
            "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 471.27it/s]\n",
            "Downloading and preparing dataset json/winglian--evals to /root/.cache/huggingface/datasets/winglian___json/winglian--evals-5354680ac81acd67/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4...\n",
            "Downloading data files:   0%|                             | 0/1 [00:00<?, ?it/s]\n",
            "Downloading data: 100%|██████████████████████| 172k/172k [00:00<00:00, 4.32MB/s]\u001b[A\n",
            "\n",
            "Downloading data:   0%|                              | 0.00/395k [00:00<?, ?B/s]\u001b[A\n",
            "Downloading data:   6%|█▎                    | 24.6k/395k [00:00<00:01, 227kB/s]\u001b[A\n",
            "Downloading data: 100%|██████████████████████| 395k/395k [00:00<00:00, 1.35MB/s]\u001b[A\n",
            "\n",
            "Downloading data: 100%|████████████████████| 79.9k/79.9k [00:00<00:00, 5.18MB/s]\u001b[A\n",
            "Downloading data files: 100%|█████████████████████| 1/1 [00:01<00:00,  1.80s/it]\n",
            "Extracting data files: 100%|█████████████████████| 1/1 [00:00<00:00, 708.38it/s]\n",
            "Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/winglian___json/winglian--evals-5354680ac81acd67/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4. Subsequent calls will reuse this data.\n",
            "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 827.44it/s]\n",
            "Downloading readme: 100%|██████████████████| 2.19k/2.19k [00:00<00:00, 9.19MB/s]\n",
            "Downloading and preparing dataset json/camel-ai--math to /root/.cache/huggingface/datasets/camel-ai___json/camel-ai--math-e65613a5e6088d3f/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4...\n",
            "Downloading data files:   0%|                             | 0/1 [00:00<?, ?it/s]\n",
            "Downloading data:   0%|                             | 0.00/39.8M [00:00<?, ?B/s]\u001b[A\n",
            "Downloading data:   3%|▌                   | 1.13M/39.8M [00:00<00:03, 11.3MB/s]\u001b[A\n",
            "Downloading data:  13%|██▌                 | 4.99M/39.8M [00:00<00:01, 27.2MB/s]\u001b[A\n",
            "Downloading data:  27%|█████▍              | 10.7M/39.8M [00:00<00:00, 38.0MB/s]\u001b[A\n",
            "Downloading data:  36%|███████▎            | 14.4M/39.8M [00:00<00:00, 33.5MB/s]\u001b[A\n",
            "Downloading data:  49%|█████████▋          | 19.4M/39.8M [00:00<00:00, 38.6MB/s]\u001b[A\n",
            "Downloading data:  63%|████████████▌       | 24.9M/39.8M [00:00<00:00, 42.5MB/s]\u001b[A\n",
            "Downloading data:  79%|███████████████▊    | 31.3M/39.8M [00:00<00:00, 49.2MB/s]\u001b[A\n",
            "Downloading data: 100%|████████████████████| 39.8M/39.8M [00:00<00:00, 40.2MB/s]\u001b[A\n",
            "Downloading data files: 100%|█████████████████████| 1/1 [00:01<00:00,  1.50s/it]\n",
            "Extracting data files: 100%|██████████████████████| 1/1 [00:06<00:00,  6.37s/it]\n",
            "Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/camel-ai___json/camel-ai--math-e65613a5e6088d3f/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4. Subsequent calls will reuse this data.\n",
            "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.61it/s]\n",
            "Downloading readme: 100%|██████████████████| 2.12k/2.12k [00:00<00:00, 9.70MB/s]\n",
            "Downloading and preparing dataset json/camel-ai--biology to /root/.cache/huggingface/datasets/camel-ai___json/camel-ai--biology-a0dba0b3efd07bc4/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4...\n",
            "Downloading data files:   0%|                             | 0/1 [00:00<?, ?it/s]\n",
            "Downloading data:   0%|                             | 0.00/27.4M [00:00<?, ?B/s]\u001b[A\n",
            "Downloading data:   8%|█▌                  | 2.14M/27.4M [00:00<00:01, 21.3MB/s]\u001b[A\n",
            "Downloading data:  31%|██████▏             | 8.46M/27.4M [00:00<00:00, 45.9MB/s]\u001b[A\n",
            "Downloading data:  64%|████████████▊       | 17.6M/27.4M [00:00<00:00, 66.7MB/s]\u001b[A\n",
            "Downloading data: 100%|████████████████████| 27.4M/27.4M [00:00<00:00, 67.3MB/s]\u001b[A\n",
            "Downloading data files: 100%|█████████████████████| 1/1 [00:00<00:00,  1.00it/s]\n",
            "Extracting data files: 100%|██████████████████████| 1/1 [00:02<00:00,  2.48s/it]\n",
            "Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/camel-ai___json/camel-ai--biology-a0dba0b3efd07bc4/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4. Subsequent calls will reuse this data.\n",
            "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.02it/s]\n",
            "Downloading readme: 100%|██████████████████| 2.12k/2.12k [00:00<00:00, 19.3MB/s]\n",
            "Downloading and preparing dataset json/camel-ai--physics to /root/.cache/huggingface/datasets/camel-ai___json/camel-ai--physics-c2d5e46897f076a2/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4...\n",
            "Downloading data files:   0%|                             | 0/1 [00:00<?, ?it/s]\n",
            "Downloading data:   0%|                             | 0.00/23.5M [00:00<?, ?B/s]\u001b[A\n",
            "Downloading data:   7%|█▍                  | 1.77M/23.5M [00:00<00:01, 17.7MB/s]\u001b[A\n",
            "Downloading data:  36%|███████             | 8.37M/23.5M [00:00<00:00, 44.7MB/s]\u001b[A\n",
            "Downloading data: 100%|████████████████████| 23.5M/23.5M [00:00<00:00, 60.4MB/s]\u001b[A\n",
            "Downloading data files: 100%|█████████████████████| 1/1 [00:01<00:00,  1.03s/it]\n",
            "Extracting data files: 100%|██████████████████████| 1/1 [00:02<00:00,  2.52s/it]\n",
            "Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/camel-ai___json/camel-ai--physics-c2d5e46897f076a2/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4. Subsequent calls will reuse this data.\n",
            "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.11it/s]\n",
            "Downloading readme: 100%|██████████████████| 2.14k/2.14k [00:00<00:00, 8.95MB/s]\n",
            "Downloading and preparing dataset json/camel-ai--chemistry to /root/.cache/huggingface/datasets/camel-ai___json/camel-ai--chemistry-8a34ec93529b52ff/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4...\n",
            "Downloading data files:   0%|                             | 0/1 [00:00<?, ?it/s]\n",
            "Downloading data:   0%|                             | 0.00/21.8M [00:00<?, ?B/s]\u001b[A\n",
            "Downloading data:   9%|█▊                  | 2.00M/21.8M [00:00<00:01, 19.5MB/s]\u001b[A\n",
            "Downloading data:  41%|████████▏           | 8.96M/21.8M [00:00<00:00, 48.7MB/s]\u001b[A\n",
            "Downloading data: 100%|████████████████████| 21.8M/21.8M [00:00<00:00, 60.6MB/s]\u001b[A\n",
            "Downloading data files: 100%|█████████████████████| 1/1 [00:00<00:00,  1.17it/s]\n",
            "Extracting data files: 100%|██████████████████████| 1/1 [00:02<00:00,  2.48s/it]\n",
            "Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/camel-ai___json/camel-ai--chemistry-8a34ec93529b52ff/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4. Subsequent calls will reuse this data.\n",
            "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.20it/s]\n",
            "Downloading and preparing dataset json/winglian--evals to /root/.cache/huggingface/datasets/winglian___json/winglian--evals-81bfad14acee858f/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4...\n",
            "Downloading data files:   0%|                             | 0/1 [00:00<?, ?it/s]\n",
            "Downloading data:   0%|                             | 0.00/1.84M [00:00<?, ?B/s]\u001b[A\n",
            "Downloading data:   1%|▎                    | 25.6k/1.84M [00:00<00:07, 251kB/s]\u001b[A\n",
            "Downloading data:   5%|█                    | 98.3k/1.84M [00:00<00:03, 520kB/s]\u001b[A\n",
            "Downloading data:  13%|██▉                   | 245k/1.84M [00:00<00:01, 933kB/s]\u001b[A\n",
            "Downloading data:  29%|█████▉               | 525k/1.84M [00:00<00:00, 1.64MB/s]\u001b[A\n",
            "Downloading data: 100%|████████████████████| 1.84M/1.84M [00:00<00:00, 3.46MB/s]\u001b[A\n",
            "Downloading data files: 100%|█████████████████████| 1/1 [00:01<00:00,  1.65s/it]\n",
            "Extracting data files: 100%|████████████████████| 1/1 [00:00<00:00, 1064.27it/s]\n",
            "Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/winglian___json/winglian--evals-81bfad14acee858f/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4. Subsequent calls will reuse this data.\n",
            "100%|███████████████████████████████████████████| 1/1 [00:00<00:00, 1077.67it/s]\n",
            "WARNING:datasets.builder:Found cached dataset json (/root/.cache/huggingface/datasets/winglian___json/winglian--evals-81bfad14acee858f/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\n",
            "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 627.61it/s]\n",
            "Downloading and preparing dataset json/winglian--evals to /root/.cache/huggingface/datasets/winglian___json/winglian--evals-c3b1db8d176877c7/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4...\n",
            "Downloading data files:   0%|                             | 0/1 [00:00<?, ?it/s]\n",
            "Downloading data:   0%|                             | 0.00/1.58M [00:00<?, ?B/s]\u001b[A\n",
            "Downloading data:   2%|▎                    | 26.6k/1.58M [00:00<00:05, 261kB/s]\u001b[A\n",
            "Downloading data:   7%|█▍                    | 105k/1.58M [00:00<00:02, 558kB/s]\u001b[A\n",
            "Downloading data:  15%|███▎                  | 236k/1.58M [00:00<00:01, 881kB/s]\u001b[A\n",
            "Downloading data:  33%|██████▉              | 527k/1.58M [00:00<00:00, 1.64MB/s]\u001b[A\n",
            "Downloading data: 100%|████████████████████| 1.58M/1.58M [00:00<00:00, 3.00MB/s]\u001b[A\n",
            "Downloading data files: 100%|█████████████████████| 1/1 [00:01<00:00,  1.13s/it]\n",
            "Extracting data files: 100%|████████████████████| 1/1 [00:00<00:00, 1009.95it/s]\n",
            "Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/winglian___json/winglian--evals-c3b1db8d176877c7/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4. Subsequent calls will reuse this data.\n",
            "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 474.84it/s]\n",
            "Downloading and preparing dataset json/winglian--evals to /root/.cache/huggingface/datasets/winglian___json/winglian--evals-f3d8ab7303b30dba/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4...\n",
            "Downloading data files:   0%|                             | 0/1 [00:00<?, ?it/s]\n",
            "Downloading data:   0%|                              | 0.00/626k [00:00<?, ?B/s]\u001b[A\n",
            "Downloading data:   4%|▉                     | 26.6k/626k [00:00<00:02, 261kB/s]\u001b[A\n",
            "Downloading data:  17%|███▉                   | 105k/626k [00:00<00:00, 558kB/s]\u001b[A\n",
            "Downloading data:  39%|████████▉              | 242k/626k [00:00<00:00, 895kB/s]\u001b[A\n",
            "Downloading data: 100%|██████████████████████| 626k/626k [00:00<00:00, 1.49MB/s]\u001b[A\n",
            "\n",
            "Downloading data:   0%|                             | 0.00/7.87M [00:00<?, ?B/s]\u001b[A\n",
            "Downloading data:   0%|                     | 32.8k/7.87M [00:00<00:24, 319kB/s]\u001b[A\n",
            "Downloading data:   1%|▎                    | 98.3k/7.87M [00:00<00:15, 504kB/s]\u001b[A\n",
            "Downloading data:   3%|▋                     | 246k/7.87M [00:00<00:08, 924kB/s]\u001b[A\n",
            "Downloading data:   7%|█▍                   | 524k/7.87M [00:00<00:04, 1.62MB/s]\u001b[A\n",
            "Downloading data:  14%|██▊                 | 1.10M/7.87M [00:00<00:02, 3.03MB/s]\u001b[A\n",
            "Downloading data:  28%|█████▋              | 2.23M/7.87M [00:00<00:00, 5.70MB/s]\u001b[A\n",
            "Downloading data: 100%|████████████████████| 7.87M/7.87M [00:00<00:00, 10.2MB/s]\u001b[A\n",
            "\n",
            "Downloading data:   0%|                             | 0.00/1.12M [00:00<?, ?B/s]\u001b[A\n",
            "Downloading data:   2%|▍                    | 25.6k/1.12M [00:00<00:04, 250kB/s]\u001b[A\n",
            "Downloading data:   9%|██                    | 105k/1.12M [00:00<00:01, 562kB/s]\u001b[A\n",
            "Downloading data:  21%|████▋                 | 239k/1.12M [00:00<00:00, 894kB/s]\u001b[A\n",
            "Downloading data:  48%|█████████▉           | 534k/1.12M [00:00<00:00, 1.67MB/s]\u001b[A\n",
            "Downloading data: 100%|████████████████████| 1.12M/1.12M [00:00<00:00, 2.17MB/s]\u001b[A\n",
            "\n",
            "Downloading data:   0%|                             | 0.00/1.13M [00:00<?, ?B/s]\u001b[A\n",
            "Downloading data:   3%|▋                    | 33.8k/1.13M [00:00<00:03, 329kB/s]\u001b[A\n",
            "Downloading data:   8%|█▋                   | 89.1k/1.13M [00:00<00:02, 450kB/s]\u001b[A\n",
            "Downloading data:  21%|████▌                 | 233k/1.13M [00:00<00:01, 883kB/s]\u001b[A\n",
            "Downloading data:  46%|█████████▋           | 520k/1.13M [00:00<00:00, 1.63MB/s]\u001b[A\n",
            "Downloading data: 100%|████████████████████| 1.13M/1.13M [00:00<00:00, 2.18MB/s]\u001b[A\n",
            "Downloading data files: 100%|█████████████████████| 1/1 [00:05<00:00,  5.83s/it]\n",
            "Extracting data files: 100%|█████████████████████| 1/1 [00:00<00:00, 385.68it/s]\n",
            "Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/winglian___json/winglian--evals-f3d8ab7303b30dba/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4. Subsequent calls will reuse this data.\n",
            "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 710.18it/s]\n",
            "Downloading and preparing dataset json/winglian--evals to /root/.cache/huggingface/datasets/winglian___json/winglian--evals-c89bb0dad6bf8005/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4...\n",
            "Downloading data files:   0%|                             | 0/1 [00:00<?, ?it/s]\n",
            "Downloading data:   0%|                             | 0.00/2.23M [00:00<?, ?B/s]\u001b[A\n",
            "Downloading data:   1%|▎                    | 26.6k/2.23M [00:00<00:08, 260kB/s]\u001b[A\n",
            "Downloading data:   5%|█                     | 105k/2.23M [00:00<00:03, 557kB/s]\u001b[A\n",
            "Downloading data:  11%|██▍                   | 247k/2.23M [00:00<00:02, 930kB/s]\u001b[A\n",
            "Downloading data:  23%|████▉                | 524k/2.23M [00:00<00:01, 1.62MB/s]\u001b[A\n",
            "Downloading data: 100%|████████████████████| 2.23M/2.23M [00:00<00:00, 4.14MB/s]\u001b[A\n",
            "Downloading data files: 100%|█████████████████████| 1/1 [00:01<00:00,  1.59s/it]\n",
            "Extracting data files: 100%|█████████████████████| 1/1 [00:00<00:00, 983.65it/s]\n",
            "Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/winglian___json/winglian--evals-c89bb0dad6bf8005/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4. Subsequent calls will reuse this data.\n",
            "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 547.27it/s]\n",
            "Downloading and preparing dataset json/winglian--evals to /root/.cache/huggingface/datasets/winglian___json/winglian--evals-99f605981858093b/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4...\n",
            "Downloading data files:   0%|                             | 0/1 [00:00<?, ?it/s]\n",
            "Downloading data:   0%|                             | 0.00/73.1M [00:00<?, ?B/s]\u001b[A\n",
            "Downloading data:   0%|                     | 25.6k/73.1M [00:00<04:53, 249kB/s]\u001b[A\n",
            "Downloading data:   0%|                      | 105k/73.1M [00:00<02:10, 560kB/s]\u001b[A\n",
            "Downloading data:   0%|                      | 239k/73.1M [00:00<01:21, 892kB/s]\u001b[A\n",
            "Downloading data:   1%|▏                    | 530k/73.1M [00:00<00:43, 1.65MB/s]\u001b[A\n",
            "Downloading data:   2%|▎                   | 1.10M/73.1M [00:00<00:23, 3.06MB/s]\u001b[A\n",
            "Downloading data:   3%|▌                   | 2.23M/73.1M [00:00<00:12, 5.74MB/s]\u001b[A\n",
            "Downloading data:   6%|█▏                  | 4.48M/73.1M [00:00<00:06, 10.9MB/s]\u001b[A\n",
            "Downloading data:  12%|██▍                 | 9.00M/73.1M [00:00<00:03, 21.3MB/s]\u001b[A\n",
            "Downloading data:  19%|███▉                | 14.2M/73.1M [00:00<00:01, 30.4MB/s]\u001b[A\n",
            "Downloading data:  26%|█████▏              | 18.8M/73.1M [00:01<00:01, 33.1MB/s]\u001b[A\n",
            "Downloading data:  33%|██████▌             | 24.2M/73.1M [00:01<00:01, 39.1MB/s]\u001b[A\n",
            "Downloading data:  40%|████████            | 29.3M/73.1M [00:01<00:01, 42.5MB/s]\u001b[A\n",
            "Downloading data:  47%|█████████▍          | 34.3M/73.1M [00:01<00:00, 44.8MB/s]\u001b[A\n",
            "Downloading data:  54%|██████████▋         | 39.2M/73.1M [00:01<00:00, 46.2MB/s]\u001b[A\n",
            "Downloading data:  61%|████████████        | 44.3M/73.1M [00:01<00:00, 47.2MB/s]\u001b[A\n",
            "Downloading data:  68%|█████████████▌      | 49.4M/73.1M [00:01<00:00, 47.9MB/s]\u001b[A\n",
            "Downloading data:  75%|██████████████▉     | 54.5M/73.1M [00:01<00:00, 48.5MB/s]\u001b[A\n",
            "Downloading data:  82%|████████████████▎   | 59.6M/73.1M [00:01<00:00, 48.7MB/s]\u001b[A\n",
            "Downloading data:  88%|█████████████████▋  | 64.5M/73.1M [00:01<00:00, 46.9MB/s]\u001b[A\n",
            "Downloading data: 100%|████████████████████| 73.1M/73.1M [00:02<00:00, 34.5MB/s]\u001b[A\n",
            "Downloading data files: 100%|█████████████████████| 1/1 [00:05<00:00,  5.55s/it]\n",
            "Extracting data files: 100%|████████████████████| 1/1 [00:00<00:00, 1658.48it/s]\n",
            "Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/winglian___json/winglian--evals-99f605981858093b/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4. Subsequent calls will reuse this data.\n",
            "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 437.45it/s]\n",
            "Downloading readme: 100%|██████████████████| 1.23k/1.23k [00:00<00:00, 4.81MB/s]\n",
            "Downloading and preparing dataset None/None to /root/.cache/huggingface/datasets/metaeval___parquet/metaeval--ScienceQA_text_only-00e2b9b849dc5307/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec...\n",
            "Downloading data files:   0%|                             | 0/3 [00:00<?, ?it/s]\n",
            "Downloading data: 100%|████████████████████| 1.73M/1.73M [00:00<00:00, 30.4MB/s]\u001b[A\n",
            "Downloading data files:  33%|███████              | 1/3 [00:00<00:01,  1.27it/s]\n",
            "Downloading data: 100%|██████████████████████| 576k/576k [00:00<00:00, 17.0MB/s]\u001b[A\n",
            "Downloading data files:  67%|██████████████       | 2/3 [00:01<00:00,  1.38it/s]\n",
            "Downloading data: 100%|██████████████████████| 619k/619k [00:00<00:00, 18.4MB/s]\u001b[A\n",
            "Downloading data files: 100%|█████████████████████| 3/3 [00:02<00:00,  1.23it/s]\n",
            "Extracting data files: 100%|████████████████████| 3/3 [00:00<00:00, 2335.36it/s]\n",
            "Dataset parquet downloaded and prepared to /root/.cache/huggingface/datasets/metaeval___parquet/metaeval--ScienceQA_text_only-00e2b9b849dc5307/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec. Subsequent calls will reuse this data.\n",
            "100%|████████████████████████████████████████████| 3/3 [00:00<00:00, 429.79it/s]\n",
            "Downloading readme: 100%|██████████████████████| 501/501 [00:00<00:00, 2.13MB/s]\n",
            "Downloading and preparing dataset json/teknium--GPT4-LLM-Cleaned to /root/.cache/huggingface/datasets/teknium___json/teknium--GPT4-LLM-Cleaned-a71aa8ae1ac3982d/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4...\n",
            "Downloading data files:   0%|                             | 0/1 [00:00<?, ?it/s]\n",
            "Downloading data:   0%|                             | 0.00/36.0M [00:00<?, ?B/s]\u001b[A\n",
            "Downloading data:  12%|██▎                 | 4.21M/36.0M [00:00<00:00, 42.1MB/s]\u001b[A\n",
            "Downloading data:  23%|████▋               | 8.42M/36.0M [00:00<00:00, 32.4MB/s]\u001b[A\n",
            "Downloading data:  33%|██████▌             | 11.8M/36.0M [00:00<00:00, 31.0MB/s]\u001b[A\n",
            "Downloading data:  42%|████████▎           | 15.0M/36.0M [00:00<00:00, 30.2MB/s]\u001b[A\n",
            "Downloading data:  58%|███████████▌        | 20.8M/36.0M [00:00<00:00, 39.4MB/s]\u001b[A\n",
            "Downloading data:  72%|██████████████▍     | 26.1M/36.0M [00:00<00:00, 43.5MB/s]\u001b[A\n",
            "Downloading data:  85%|████████████████▉   | 30.5M/36.0M [00:00<00:00, 35.5MB/s]\u001b[A\n",
            "Downloading data: 100%|████████████████████| 36.0M/36.0M [00:00<00:00, 36.8MB/s]\u001b[A\n",
            "\n",
            "Downloading data:   0%|                             | 0.00/4.91M [00:00<?, ?B/s]\u001b[A\n",
            "Downloading data:   1%|                     | 26.6k/4.91M [00:00<00:18, 259kB/s]\u001b[A\n",
            "Downloading data:   2%|▍                    | 92.2k/4.91M [00:00<00:10, 479kB/s]\u001b[A\n",
            "Downloading data:   5%|█                     | 233k/4.91M [00:00<00:05, 889kB/s]\u001b[A\n",
            "Downloading data:  11%|██▎                  | 528k/4.91M [00:00<00:02, 1.67MB/s]\u001b[A\n",
            "Downloading data:  22%|████▍               | 1.10M/4.91M [00:00<00:01, 3.06MB/s]\u001b[A\n",
            "Downloading data:  45%|█████████           | 2.23M/4.91M [00:00<00:00, 5.73MB/s]\u001b[A\n",
            "Downloading data: 100%|████████████████████| 4.91M/4.91M [00:00<00:00, 6.74MB/s]\u001b[A\n",
            "Downloading data files: 100%|█████████████████████| 1/1 [00:03<00:00,  3.21s/it]\n",
            "Extracting data files: 100%|█████████████████████| 1/1 [00:00<00:00, 901.03it/s]\n",
            "Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/teknium___json/teknium--GPT4-LLM-Cleaned-a71aa8ae1ac3982d/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4. Subsequent calls will reuse this data.\n",
            "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 519.29it/s]\n",
            "Downloading readme: 100%|██████████████████████| 458/458 [00:00<00:00, 2.44MB/s]\n",
            "Downloading and preparing dataset json/teknium--GPTeacher-General-Instruct to /root/.cache/huggingface/datasets/teknium___json/teknium--GPTeacher-General-Instruct-ff38d362dfbec0b7/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4...\n",
            "Downloading data files:   0%|                             | 0/1 [00:00<?, ?it/s]\n",
            "Downloading data:   0%|                             | 0.00/12.1M [00:00<?, ?B/s]\u001b[A\n",
            "Downloading data:  21%|████▏               | 2.55M/12.1M [00:00<00:00, 25.3MB/s]\u001b[A\n",
            "Downloading data:  42%|████████▍           | 5.09M/12.1M [00:00<00:00, 25.0MB/s]\u001b[A\n",
            "Downloading data:  63%|████████████▋       | 7.64M/12.1M [00:00<00:00, 25.3MB/s]\u001b[A\n",
            "Downloading data: 100%|████████████████████| 12.1M/12.1M [00:00<00:00, 25.9MB/s]\u001b[A\n",
            "Downloading data files: 100%|█████████████████████| 1/1 [00:01<00:00,  1.18s/it]\n",
            "Extracting data files: 100%|████████████████████| 1/1 [00:00<00:00, 1500.11it/s]\n",
            "Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/teknium___json/teknium--GPTeacher-General-Instruct-ff38d362dfbec0b7/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4. Subsequent calls will reuse this data.\n",
            "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 783.10it/s]\n",
            "Downloading readme: 100%|██████████████████| 8.26k/8.26k [00:00<00:00, 34.5MB/s]\n",
            "Downloading and preparing dataset json/QingyiSi--Alpaca-CoT to /root/.cache/huggingface/datasets/QingyiSi___json/QingyiSi--Alpaca-CoT-72053b9662210036/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4...\n",
            "Downloading data files:   0%|                             | 0/1 [00:00<?, ?it/s]\n",
            "Downloading data: 100%|████████████████████| 1.20M/1.20M [00:00<00:00, 25.2MB/s]\u001b[A\n",
            "\n",
            "Downloading data: 100%|████████████████████| 2.28M/2.28M [00:00<00:00, 32.4MB/s]\u001b[A\n",
            "\n",
            "Downloading data: 100%|████████████████████| 2.81M/2.81M [00:00<00:00, 35.6MB/s]\u001b[A\n",
            "\n",
            "Downloading data:   0%|                             | 0.00/15.0M [00:00<?, ?B/s]\u001b[A\n",
            "Downloading data:  23%|████▌               | 3.41M/15.0M [00:00<00:00, 33.9MB/s]\u001b[A\n",
            "Downloading data: 100%|████████████████████| 15.0M/15.0M [00:00<00:00, 47.2MB/s]\u001b[A\n",
            "\n",
            "Downloading data: 100%|██████████████████████| 548k/548k [00:00<00:00, 16.9MB/s]\u001b[A\n",
            "\n",
            "Downloading data:   0%|                             | 0.00/5.12M [00:00<?, ?B/s]\u001b[A\n",
            "Downloading data: 100%|████████████████████| 5.12M/5.12M [00:00<00:00, 42.1MB/s]\u001b[A\n",
            "\n",
            "Downloading data: 100%|████████████████████| 2.25M/2.25M [00:00<00:00, 29.6MB/s]\u001b[A\n",
            "\n",
            "Downloading data: 100%|██████████████████████| 719k/719k [00:00<00:00, 18.7MB/s]\u001b[A\n",
            "\n",
            "Downloading data:   0%|                             | 0.00/2.58M [00:00<?, ?B/s]\u001b[A\n",
            "Downloading data: 100%|████████████████████| 2.58M/2.58M [00:00<00:00, 25.1MB/s]\u001b[A\n",
            "Downloading data files: 100%|█████████████████████| 1/1 [00:07<00:00,  7.12s/it]\n",
            "Extracting data files: 100%|█████████████████████| 1/1 [00:00<00:00, 175.38it/s]\n",
            "Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/QingyiSi___json/QingyiSi--Alpaca-CoT-72053b9662210036/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4. Subsequent calls will reuse this data.\n",
            "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 472.23it/s]\n",
            "Downloading readme: 100%|██████████████████████| 387/387 [00:00<00:00, 2.34MB/s]\n",
            "Downloading and preparing dataset json/ehartford--WizardLM_alpaca_evol_instruct_70k_unfiltered to /root/.cache/huggingface/datasets/ehartford___json/ehartford--WizardLM_alpaca_evol_instruct_70k_unfiltered-d64f16a81bd92db8/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4...\n",
            "Downloading data files:   0%|                             | 0/1 [00:00<?, ?it/s]\n",
            "Downloading data:   0%|                             | 0.00/99.6M [00:00<?, ?B/s]\u001b[A\n",
            "Downloading data:   5%|█                   | 4.99M/99.6M [00:00<00:01, 49.9MB/s]\u001b[A\n",
            "Downloading data:  12%|██▎                 | 11.8M/99.6M [00:00<00:01, 60.5MB/s]\u001b[A\n",
            "Downloading data:  18%|███▌                | 17.8M/99.6M [00:00<00:01, 45.6MB/s]\u001b[A\n",
            "Downloading data:  23%|████▌               | 22.7M/99.6M [00:00<00:01, 42.8MB/s]\u001b[A\n",
            "Downloading data:  30%|██████              | 29.9M/99.6M [00:00<00:01, 51.6MB/s]\u001b[A\n",
            "Downloading data:  36%|███████             | 35.4M/99.6M [00:00<00:01, 51.9MB/s]\u001b[A\n",
            "Downloading data:  41%|████████▏           | 40.8M/99.6M [00:00<00:01, 52.4MB/s]\u001b[A\n",
            "Downloading data:  46%|█████████▎          | 46.2M/99.6M [00:00<00:01, 48.0MB/s]\u001b[A\n",
            "Downloading data:  52%|██████████▍         | 52.0M/99.6M [00:01<00:00, 50.8MB/s]\u001b[A\n",
            "Downloading data:  57%|███████████▍        | 57.2M/99.6M [00:01<00:00, 50.8MB/s]\u001b[A\n",
            "Downloading data:  63%|████████████▌       | 62.4M/99.6M [00:01<00:00, 45.7MB/s]\u001b[A\n",
            "Downloading data:  68%|█████████████▌      | 67.6M/99.6M [00:01<00:00, 47.6MB/s]\u001b[A\n",
            "Downloading data:  73%|██████████████▌     | 72.5M/99.6M [00:01<00:00, 46.2MB/s]\u001b[A\n",
            "Downloading data:  78%|███████████████▌    | 77.2M/99.6M [00:01<00:00, 44.1MB/s]\u001b[A\n",
            "Downloading data:  84%|████████████████▊   | 83.9M/99.6M [00:01<00:00, 50.2MB/s]\u001b[A\n",
            "Downloading data:  90%|█████████████████▉  | 89.4M/99.6M [00:01<00:00, 51.5MB/s]\u001b[A\n",
            "Downloading data: 100%|████████████████████| 99.6M/99.6M [00:02<00:00, 49.4MB/s]\u001b[A\n",
            "Downloading data files: 100%|█████████████████████| 1/1 [00:02<00:00,  2.91s/it]\n",
            "Extracting data files: 100%|████████████████████| 1/1 [00:00<00:00, 1485.24it/s]\n",
            "Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/ehartford___json/ehartford--WizardLM_alpaca_evol_instruct_70k_unfiltered-d64f16a81bd92db8/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4. Subsequent calls will reuse this data.\n",
            "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 455.36it/s]\n",
            "Downloading readme: 100%|██████████████████████| 348/348 [00:00<00:00, 2.38MB/s]\n",
            "Downloading and preparing dataset json/ehartford--wizard_vicuna_70k_unfiltered to /root/.cache/huggingface/datasets/ehartford___json/ehartford--wizard_vicuna_70k_unfiltered-71f549fba4cffce0/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4...\n",
            "Downloading data files:   0%|                             | 0/1 [00:00<?, ?it/s]\n",
            "Downloading data:   0%|                              | 0.00/152M [00:00<?, ?B/s]\u001b[A\n",
            "Downloading data:   3%|▌                    | 4.21M/152M [00:00<00:03, 42.1MB/s]\u001b[A\n",
            "Downloading data:   6%|█▏                   | 8.43M/152M [00:00<00:03, 36.0MB/s]\u001b[A\n",
            "Downloading data:  10%|██                   | 14.5M/152M [00:00<00:02, 46.1MB/s]\u001b[A\n",
            "Downloading data:  13%|██▋                  | 19.6M/152M [00:00<00:02, 47.9MB/s]\u001b[A\n",
            "Downloading data:  16%|███▍                 | 24.4M/152M [00:00<00:03, 40.7MB/s]\u001b[A\n",
            "Downloading data:  20%|████                 | 29.6M/152M [00:00<00:02, 43.8MB/s]\u001b[A\n",
            "Downloading data:  23%|████▊                | 34.4M/152M [00:00<00:02, 45.0MB/s]\u001b[A\n",
            "Downloading data:  26%|█████▍               | 39.0M/152M [00:00<00:02, 43.2MB/s]\u001b[A\n",
            "Downloading data:  29%|██████               | 43.4M/152M [00:01<00:02, 36.8MB/s]\u001b[A\n",
            "Downloading data:  32%|██████▋              | 47.8M/152M [00:01<00:02, 38.6MB/s]\u001b[A\n",
            "Downloading data:  34%|███████▏             | 51.9M/152M [00:01<00:02, 36.5MB/s]\u001b[A\n",
            "Downloading data:  38%|████████             | 58.3M/152M [00:01<00:02, 43.8MB/s]\u001b[A\n",
            "Downloading data:  41%|████████▋            | 62.9M/152M [00:01<00:02, 42.3MB/s]\u001b[A\n",
            "Downloading data:  44%|█████████▎           | 67.2M/152M [00:01<00:02, 40.7MB/s]\u001b[A\n",
            "Downloading data:  47%|█████████▉           | 71.4M/152M [00:01<00:01, 40.1MB/s]\u001b[A\n",
            "Downloading data:  51%|██████████▊          | 77.7M/152M [00:01<00:01, 46.5MB/s]\u001b[A\n",
            "Downloading data:  55%|███████████▌         | 83.3M/152M [00:01<00:01, 49.1MB/s]\u001b[A\n",
            "Downloading data:  59%|████████████▎        | 89.0M/152M [00:02<00:01, 51.4MB/s]\u001b[A\n",
            "Downloading data:  62%|█████████████        | 94.3M/152M [00:02<00:01, 50.5MB/s]\u001b[A\n",
            "Downloading data:  66%|█████████████▊       | 99.4M/152M [00:02<00:01, 49.7MB/s]\u001b[A\n",
            "Downloading data:  70%|███████████████▎      | 106M/152M [00:02<00:00, 54.0MB/s]\u001b[A\n",
            "Downloading data:  75%|████████████████▍     | 113M/152M [00:02<00:00, 59.3MB/s]\u001b[A\n",
            "Downloading data:  79%|█████████████████▎    | 119M/152M [00:02<00:00, 57.8MB/s]\u001b[A\n",
            "Downloading data:  82%|██████████████████    | 125M/152M [00:02<00:00, 54.1MB/s]\u001b[A\n",
            "Downloading data:  86%|██████████████████▉   | 130M/152M [00:02<00:00, 52.0MB/s]\u001b[A\n",
            "Downloading data:  89%|███████████████████▋  | 136M/152M [00:02<00:00, 48.2MB/s]\u001b[A\n",
            "Downloading data:  93%|████████████████████▍ | 140M/152M [00:03<00:00, 42.7MB/s]\u001b[A\n",
            "Downloading data: 100%|██████████████████████| 152M/152M [00:03<00:00, 46.1MB/s]\u001b[A\n",
            "Downloading data files: 100%|█████████████████████| 1/1 [00:03<00:00,  3.95s/it]\n",
            "Extracting data files: 100%|████████████████████| 1/1 [00:00<00:00, 1921.35it/s]\n",
            "Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/ehartford___json/ehartford--wizard_vicuna_70k_unfiltered-71f549fba4cffce0/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4. Subsequent calls will reuse this data.\n",
            "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 437.54it/s]\n",
            "INFO:root:tokenizing, merging, and shuffling master dataset\n",
            "WARNING:root:role with empty message: ASSISTANT\n",
            "WARNING:root:role with empty message: USER\n",
            "WARNING:root:role with empty message: USER\n",
            "WARNING:root:role with empty message: ASSISTANT\n",
            "WARNING:root:role with empty message: ASSISTANT\n",
            "INFO:root:Saving merged prepared dataset to disk... last_run_prepared/9a63aa2c07ace8350a0e8b32ab913f2a\n",
            "INFO:root:Saving merged prepared dataset with push_to_hub... utensil/9a63aa2c07ace8350a0e8b32ab913f2a\n",
            "Pushing dataset shards to the dataset hub:   0%|          | 0/5 [00:00<?, ?it/s]\n",
            "Creating parquet from Arrow format:   0%|                | 0/85 [00:00<?, ?ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:   2%|▏       | 2/85 [00:00<00:06, 12.59ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:   5%|▍       | 4/85 [00:00<00:06, 13.14ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:   7%|▌       | 6/85 [00:00<00:05, 13.34ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:   9%|▊       | 8/85 [00:00<00:05, 13.59ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  12%|▊      | 10/85 [00:00<00:05, 13.60ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  14%|▉      | 12/85 [00:00<00:05, 13.75ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  16%|█▏     | 14/85 [00:01<00:05, 12.91ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  19%|█▎     | 16/85 [00:01<00:05, 13.20ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  21%|█▍     | 18/85 [00:01<00:05, 13.28ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  24%|█▋     | 20/85 [00:01<00:04, 13.06ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  26%|█▊     | 22/85 [00:01<00:04, 13.28ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  28%|█▉     | 24/85 [00:01<00:04, 13.44ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  31%|██▏    | 26/85 [00:01<00:04, 13.69ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  33%|██▎    | 28/85 [00:02<00:04, 13.84ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  35%|██▍    | 30/85 [00:02<00:03, 14.00ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  38%|██▋    | 32/85 [00:02<00:03, 14.06ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  40%|██▊    | 34/85 [00:02<00:03, 14.16ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  42%|██▉    | 36/85 [00:02<00:03, 14.33ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  45%|███▏   | 38/85 [00:02<00:03, 14.40ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  47%|███▎   | 40/85 [00:02<00:03, 14.44ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  49%|███▍   | 42/85 [00:03<00:02, 14.37ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  52%|███▌   | 44/85 [00:03<00:02, 14.43ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  54%|███▊   | 46/85 [00:03<00:02, 14.11ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  56%|███▉   | 48/85 [00:03<00:02, 13.87ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  59%|████   | 50/85 [00:03<00:02, 13.43ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  61%|████▎  | 52/85 [00:03<00:02, 13.70ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  64%|████▍  | 54/85 [00:03<00:02, 13.96ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  66%|████▌  | 56/85 [00:04<00:02, 14.12ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  68%|████▊  | 58/85 [00:04<00:01, 14.25ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  71%|████▉  | 60/85 [00:04<00:01, 14.32ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  73%|█████  | 62/85 [00:04<00:01, 14.31ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  75%|█████▎ | 64/85 [00:04<00:01, 14.30ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  78%|█████▍ | 66/85 [00:04<00:01, 14.38ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  80%|█████▌ | 68/85 [00:04<00:01, 14.43ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  82%|█████▊ | 70/85 [00:05<00:01, 14.43ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  85%|█████▉ | 72/85 [00:05<00:00, 14.45ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  87%|██████ | 74/85 [00:05<00:00, 14.33ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  89%|██████▎| 76/85 [00:05<00:00, 14.30ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  92%|██████▍| 78/85 [00:05<00:00, 14.37ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  94%|██████▌| 80/85 [00:05<00:00, 14.33ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  96%|██████▊| 82/85 [00:05<00:00, 14.33ba/s]\u001b[A\n",
            "Creating parquet from Arrow format: 100%|███████| 85/85 [00:06<00:00, 14.11ba/s]\u001b[A\n",
            "\n",
            "Upload 1 LFS files:   0%|                                 | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Upload 1 LFS files: 100%|█████████████████████████| 1/1 [00:10<00:00, 10.18s/it]\u001b[A\n",
            "Pushing dataset shards to the dataset hub:  20%|▍ | 1/5 [00:17<01:08, 17.22s/it]\n",
            "Creating parquet from Arrow format:   0%|                | 0/85 [00:00<?, ?ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:   2%|▏       | 2/85 [00:00<00:05, 14.70ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:   5%|▍       | 4/85 [00:00<00:05, 14.54ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:   7%|▌       | 6/85 [00:00<00:05, 14.41ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:   9%|▊       | 8/85 [00:00<00:05, 14.48ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  12%|▊      | 10/85 [00:00<00:05, 14.39ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  14%|▉      | 12/85 [00:00<00:05, 14.39ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  16%|█▏     | 14/85 [00:00<00:04, 14.47ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  19%|█▎     | 16/85 [00:01<00:04, 14.51ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  21%|█▍     | 18/85 [00:01<00:04, 14.52ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  24%|█▋     | 20/85 [00:01<00:04, 14.27ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  26%|█▊     | 22/85 [00:01<00:04, 14.04ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  28%|█▉     | 24/85 [00:01<00:04, 14.29ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  31%|██▏    | 26/85 [00:01<00:04, 14.37ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  33%|██▎    | 28/85 [00:01<00:03, 14.46ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  35%|██▍    | 30/85 [00:02<00:03, 14.48ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  38%|██▋    | 32/85 [00:02<00:03, 14.53ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  40%|██▊    | 34/85 [00:02<00:03, 14.57ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  42%|██▉    | 36/85 [00:02<00:03, 14.54ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  45%|███▏   | 38/85 [00:02<00:03, 14.60ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  47%|███▎   | 40/85 [00:02<00:03, 14.58ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  49%|███▍   | 42/85 [00:02<00:02, 14.52ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  52%|███▌   | 44/85 [00:03<00:02, 14.49ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  54%|███▊   | 46/85 [00:03<00:02, 14.54ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  56%|███▉   | 48/85 [00:03<00:02, 14.58ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  59%|████   | 50/85 [00:03<00:02, 14.54ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  61%|████▎  | 52/85 [00:03<00:02, 14.44ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  64%|████▍  | 54/85 [00:03<00:02, 14.51ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  66%|████▌  | 56/85 [00:03<00:01, 14.58ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  68%|████▊  | 58/85 [00:04<00:01, 14.66ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  71%|████▉  | 60/85 [00:04<00:01, 14.64ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  73%|█████  | 62/85 [00:04<00:01, 14.63ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  75%|█████▎ | 64/85 [00:04<00:01, 14.66ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  78%|█████▍ | 66/85 [00:04<00:01, 14.69ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  80%|█████▌ | 68/85 [00:04<00:01, 14.60ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  82%|█████▊ | 70/85 [00:04<00:01, 14.63ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  85%|█████▉ | 72/85 [00:04<00:00, 14.60ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  87%|██████ | 74/85 [00:05<00:00, 14.65ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  89%|██████▎| 76/85 [00:05<00:00, 14.59ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  92%|██████▍| 78/85 [00:05<00:00, 14.59ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  94%|██████▌| 80/85 [00:05<00:00, 14.70ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  96%|██████▊| 82/85 [00:05<00:00, 14.11ba/s]\u001b[A\n",
            "Creating parquet from Arrow format: 100%|███████| 85/85 [00:05<00:00, 14.50ba/s]\u001b[A\n",
            "\n",
            "Upload 1 LFS files:   0%|                                 | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Upload 1 LFS files: 100%|█████████████████████████| 1/1 [00:08<00:00,  8.21s/it]\u001b[A\n",
            "Pushing dataset shards to the dataset hub:  40%|▊ | 2/5 [00:31<00:47, 15.74s/it]\n",
            "Creating parquet from Arrow format:   0%|                | 0/85 [00:00<?, ?ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:   2%|▏       | 2/85 [00:00<00:06, 13.70ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:   5%|▍       | 4/85 [00:00<00:05, 13.92ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:   7%|▌       | 6/85 [00:00<00:05, 13.98ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:   9%|▊       | 8/85 [00:00<00:05, 13.83ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  12%|▊      | 10/85 [00:00<00:05, 13.83ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  14%|▉      | 12/85 [00:00<00:05, 13.96ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  16%|█▏     | 14/85 [00:00<00:05, 14.16ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  19%|█▎     | 16/85 [00:01<00:04, 14.18ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  21%|█▍     | 18/85 [00:01<00:04, 14.07ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  24%|█▋     | 20/85 [00:01<00:04, 13.84ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  26%|█▊     | 22/85 [00:01<00:04, 14.06ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  28%|█▉     | 24/85 [00:01<00:04, 14.22ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  31%|██▏    | 26/85 [00:01<00:04, 14.30ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  33%|██▎    | 28/85 [00:01<00:03, 14.39ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  35%|██▍    | 30/85 [00:02<00:03, 14.49ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  38%|██▋    | 32/85 [00:02<00:03, 14.44ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  40%|██▊    | 34/85 [00:02<00:03, 14.46ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  42%|██▉    | 36/85 [00:02<00:03, 14.38ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  45%|███▏   | 38/85 [00:02<00:03, 14.43ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  47%|███▎   | 40/85 [00:02<00:03, 14.34ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  49%|███▍   | 42/85 [00:02<00:03, 14.29ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  52%|███▌   | 44/85 [00:03<00:02, 14.34ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  54%|███▊   | 46/85 [00:03<00:02, 14.43ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  56%|███▉   | 48/85 [00:03<00:02, 14.40ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  59%|████   | 50/85 [00:03<00:02, 14.40ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  61%|████▎  | 52/85 [00:03<00:02, 14.40ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  64%|████▍  | 54/85 [00:03<00:02, 14.36ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  66%|████▌  | 56/85 [00:03<00:02, 14.44ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  68%|████▊  | 58/85 [00:04<00:01, 14.61ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  71%|████▉  | 60/85 [00:04<00:01, 14.67ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  73%|█████  | 62/85 [00:04<00:01, 14.62ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  75%|█████▎ | 64/85 [00:04<00:01, 14.45ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  78%|█████▍ | 66/85 [00:04<00:01, 14.48ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  80%|█████▌ | 68/85 [00:04<00:01, 14.54ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  82%|█████▊ | 70/85 [00:04<00:01, 14.54ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  85%|█████▉ | 72/85 [00:05<00:00, 14.61ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  87%|██████ | 74/85 [00:05<00:00, 14.53ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  89%|██████▎| 76/85 [00:05<00:00, 14.58ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  92%|██████▍| 78/85 [00:05<00:00, 14.48ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  94%|██████▌| 80/85 [00:05<00:00, 14.40ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  96%|██████▊| 82/85 [00:05<00:00, 14.40ba/s]\u001b[A\n",
            "Creating parquet from Arrow format: 100%|███████| 85/85 [00:05<00:00, 14.47ba/s]\u001b[A\n",
            "\n",
            "Upload 1 LFS files:   0%|                                 | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Upload 1 LFS files: 100%|█████████████████████████| 1/1 [00:06<00:00,  7.00s/it]\u001b[A\n",
            "Pushing dataset shards to the dataset hub:  60%|█▏| 3/5 [00:45<00:29, 14.74s/it]\n",
            "Creating parquet from Arrow format:   0%|                | 0/85 [00:00<?, ?ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:   2%|▏       | 2/85 [00:00<00:06, 12.27ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:   5%|▍       | 4/85 [00:00<00:05, 13.56ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:   7%|▌       | 6/85 [00:00<00:05, 13.81ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:   9%|▊       | 8/85 [00:00<00:05, 13.88ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  12%|▊      | 10/85 [00:00<00:05, 13.69ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  14%|▉      | 12/85 [00:00<00:05, 13.94ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  16%|█▏     | 14/85 [00:01<00:05, 14.18ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  19%|█▎     | 16/85 [00:01<00:04, 14.16ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  21%|█▍     | 18/85 [00:01<00:04, 14.11ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  24%|█▋     | 20/85 [00:01<00:04, 13.89ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  26%|█▊     | 22/85 [00:01<00:04, 13.64ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  28%|█▉     | 24/85 [00:01<00:04, 13.88ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  31%|██▏    | 26/85 [00:01<00:04, 14.07ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  33%|██▎    | 28/85 [00:02<00:04, 14.22ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  35%|██▍    | 30/85 [00:02<00:03, 14.27ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  38%|██▋    | 32/85 [00:02<00:03, 14.27ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  40%|██▊    | 34/85 [00:02<00:03, 14.36ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  42%|██▉    | 36/85 [00:02<00:03, 14.32ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  45%|███▏   | 38/85 [00:02<00:03, 14.37ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  47%|███▎   | 40/85 [00:02<00:03, 14.44ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  49%|███▍   | 42/85 [00:02<00:02, 14.58ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  52%|███▌   | 44/85 [00:03<00:02, 14.61ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  54%|███▊   | 46/85 [00:03<00:02, 14.25ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  56%|███▉   | 48/85 [00:03<00:02, 14.24ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  59%|████   | 50/85 [00:03<00:02, 14.25ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  61%|████▎  | 52/85 [00:03<00:02, 14.27ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  64%|████▍  | 54/85 [00:03<00:02, 14.20ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  66%|████▌  | 56/85 [00:03<00:02, 14.23ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  68%|████▊  | 58/85 [00:04<00:01, 14.36ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  71%|████▉  | 60/85 [00:04<00:01, 14.48ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  73%|█████  | 62/85 [00:04<00:01, 14.47ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  75%|█████▎ | 64/85 [00:04<00:01, 14.45ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  78%|█████▍ | 66/85 [00:04<00:01, 14.46ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  80%|█████▌ | 68/85 [00:04<00:01, 14.36ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  82%|█████▊ | 70/85 [00:04<00:01, 14.40ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  85%|█████▉ | 72/85 [00:05<00:00, 14.46ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  87%|██████ | 74/85 [00:05<00:00, 14.54ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  89%|██████▎| 76/85 [00:05<00:00, 14.60ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  92%|██████▍| 78/85 [00:05<00:00, 14.55ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  94%|██████▌| 80/85 [00:05<00:00, 14.45ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  96%|██████▊| 82/85 [00:05<00:00, 14.43ba/s]\u001b[A\n",
            "Creating parquet from Arrow format: 100%|███████| 85/85 [00:05<00:00, 14.37ba/s]\u001b[A\n",
            "\n",
            "Upload 1 LFS files:   0%|                                 | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Upload 1 LFS files: 100%|█████████████████████████| 1/1 [00:11<00:00, 11.10s/it]\u001b[A\n",
            "Pushing dataset shards to the dataset hub:  80%|█▌| 4/5 [01:03<00:15, 15.90s/it]\n",
            "Creating parquet from Arrow format:   0%|                | 0/85 [00:00<?, ?ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:   2%|▏       | 2/85 [00:00<00:06, 12.39ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:   5%|▍       | 4/85 [00:00<00:05, 13.60ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:   7%|▌       | 6/85 [00:00<00:05, 13.99ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:   9%|▊       | 8/85 [00:00<00:05, 14.07ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  12%|▊      | 10/85 [00:00<00:05, 14.21ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  14%|▉      | 12/85 [00:00<00:05, 14.13ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  16%|█▏     | 14/85 [00:00<00:04, 14.20ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  19%|█▎     | 16/85 [00:01<00:04, 14.38ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  21%|█▍     | 18/85 [00:01<00:04, 14.46ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  24%|█▋     | 20/85 [00:01<00:04, 14.16ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  26%|█▊     | 22/85 [00:01<00:04, 14.16ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  28%|█▉     | 24/85 [00:01<00:04, 14.21ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  31%|██▏    | 26/85 [00:01<00:04, 14.28ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  33%|██▎    | 28/85 [00:01<00:04, 13.99ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  35%|██▍    | 30/85 [00:02<00:03, 14.04ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  38%|██▋    | 32/85 [00:02<00:03, 14.12ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  40%|██▊    | 34/85 [00:02<00:03, 14.20ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  42%|██▉    | 36/85 [00:02<00:03, 14.16ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  45%|███▏   | 38/85 [00:02<00:03, 14.30ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  47%|███▎   | 40/85 [00:02<00:03, 14.33ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  49%|███▍   | 42/85 [00:02<00:02, 14.39ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  52%|███▌   | 44/85 [00:03<00:02, 14.34ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  54%|███▊   | 46/85 [00:03<00:02, 14.39ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  56%|███▉   | 48/85 [00:03<00:02, 14.42ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  59%|████   | 50/85 [00:03<00:02, 14.42ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  61%|████▎  | 52/85 [00:03<00:02, 14.47ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  64%|████▍  | 54/85 [00:03<00:02, 14.48ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  66%|████▌  | 56/85 [00:03<00:02, 14.48ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  68%|████▊  | 58/85 [00:04<00:01, 14.49ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  71%|████▉  | 60/85 [00:04<00:01, 14.41ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  73%|█████  | 62/85 [00:04<00:01, 14.47ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  75%|█████▎ | 64/85 [00:04<00:01, 14.48ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  78%|█████▍ | 66/85 [00:04<00:01, 14.48ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  80%|█████▌ | 68/85 [00:04<00:01, 14.55ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  82%|█████▊ | 70/85 [00:04<00:01, 14.57ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  85%|█████▉ | 72/85 [00:05<00:00, 14.46ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  87%|██████ | 74/85 [00:05<00:00, 14.21ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  89%|██████▎| 76/85 [00:05<00:00, 14.13ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  92%|██████▍| 78/85 [00:05<00:00, 14.22ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  94%|██████▌| 80/85 [00:05<00:00, 14.32ba/s]\u001b[A\n",
            "Creating parquet from Arrow format:  96%|██████▊| 82/85 [00:05<00:00, 14.38ba/s]\u001b[A\n",
            "Creating parquet from Arrow format: 100%|███████| 85/85 [00:05<00:00, 14.41ba/s]\u001b[A\n",
            "\n",
            "Upload 1 LFS files:   0%|                                 | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Upload 1 LFS files: 100%|█████████████████████████| 1/1 [00:07<00:00,  7.22s/it]\u001b[A\n",
            "Pushing dataset shards to the dataset hub: 100%|██| 5/5 [01:17<00:00, 15.40s/it]\n",
            "INFO:root:Finished preparing dataset. Exiting...\n"
          ]
        }
      ],
      "source": [
        "!python scripts/finetune.py examples/falcon/config-40b-qlora.yml --prepare_ds_only"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# minotaur (fixed)\n",
        "\n",
        "Datasets from https://huggingface.co/openaccess-ai-collective/minotaur-13b-fixed/blob/main/configs/minotaur-13b.yml\n",
        "\n",
        "Configs from https://github.com/utensil/llm-playground/blob/32b79773441a3fef5c6a74f0a035077c7d4a1af1/notebooks/axolotl/runpod/axolotl-falcon-40b-qlora-deepspeed.ipynb"
      ],
      "metadata": {
        "id": "2Q3pemkLWlYY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile examples/falcon/config-40b-qlora.yml\n",
        "# 1b: tiiuae/falcon-rw-1b\n",
        "# 7b: tiiuae/falcon-7b\n",
        "# 40b: tiiuae/falcon-40b\n",
        "base_model: /content/llm-playground/models/tiiuae_falcon-40b\n",
        "base_model_config: /content/llm-playground/models/tiiuae_falcon-40b\n",
        "# required by falcon custom model code: https://huggingface.co/tiiuae/falcon-7b/tree/main\n",
        "trust_remote_code: true\n",
        "model_type: AutoModelForCausalLM\n",
        "tokenizer_type: AutoTokenizer\n",
        "load_in_8bit: false\n",
        "# enable 4bit for QLoRA\n",
        "load_in_4bit: true\n",
        "gptq: false\n",
        "strict: false\n",
        "\n",
        "push_dataset_to_hub: utensil\n",
        "hf_use_auth_token: true\n",
        "\n",
        "datasets:\n",
        "  - path: winglian/evals\n",
        "    data_files:\n",
        "      - hf/ARC-Challenge.jsonl\n",
        "      - hf/ARC-Easy.jsonl\n",
        "      - hf/riddle_sense.jsonl\n",
        "      - hf/piqa.jsonl\n",
        "    type: explainchoice:chat\n",
        "  - path: winglian/evals\n",
        "    data_files:\n",
        "      - hf/gsm8k.jsonl\n",
        "      - hf/winogrande.jsonl\n",
        "    type: alpaca_chat.load_qa\n",
        "  - path: winglian/evals\n",
        "    data_files:\n",
        "      - custom/n_task.jsonl\n",
        "      - custom/misconceptions.jsonl\n",
        "      - custom/context_insensitivity.jsonl\n",
        "    type: alpaca_chat\n",
        "  - path: camel-ai/math\n",
        "    type: alpaca_chat.load_camel_ai\n",
        "  - path: camel-ai/biology\n",
        "    type: alpaca_chat.load_camel_ai\n",
        "  - path: camel-ai/physics\n",
        "    type: alpaca_chat.load_camel_ai\n",
        "  - path: camel-ai/chemistry\n",
        "    type: alpaca_chat.load_camel_ai\n",
        "  - path: winglian/evals\n",
        "    data_files:\n",
        "      - custom/in_context_qa.jsonl\n",
        "    type: context_qa\n",
        "  - path: winglian/evals\n",
        "    data_files:\n",
        "      - custom/in_context_qa.jsonl\n",
        "    type: context_qa.load_404\n",
        "  - path: winglian/evals\n",
        "    data_files:\n",
        "      - custom/jokes_explained_500up.jsonl\n",
        "    type: sharegpt_jokes\n",
        "  - path: winglian/evals\n",
        "    data_files:\n",
        "      - custom/classify-self-chat.sharegpt.jsonl\n",
        "      - custom/coding-self-chat.sharegpt.jsonl\n",
        "      - custom/prose-gpt4.sharegpt.jsonl\n",
        "      - custom/prose-rewrite-gpt4.sharegpt.jsonl\n",
        "    type: sharegpt_simple.load_role\n",
        "  - path: winglian/evals\n",
        "    data_files:\n",
        "      - openai/tldr.jsonl\n",
        "    type: summarizetldr:chat\n",
        "  - path: winglian/evals\n",
        "    data_files:\n",
        "      - hellaswag/hellaswag.jsonl\n",
        "    type: explainchoice:chat\n",
        "  - path: metaeval/ScienceQA_text_only\n",
        "    type: concisechoice:chat\n",
        "  - path: teknium/GPT4-LLM-Cleaned\n",
        "    type: alpaca_chat\n",
        "  - path: teknium/GPTeacher-General-Instruct\n",
        "    data_files: gpt4-instruct-similarity-0.6-dataset.json\n",
        "    type: gpteacher:chat\n",
        "  - path: QingyiSi/Alpaca-CoT\n",
        "    data_files:\n",
        "      - Chain-of-Thought/formatted_cot_data/aqua_train.json\n",
        "      - Chain-of-Thought/formatted_cot_data/creak_train.json\n",
        "      - Chain-of-Thought/formatted_cot_data/ecqa_train.json\n",
        "      - Chain-of-Thought/formatted_cot_data/esnli_train.json\n",
        "      - Chain-of-Thought/formatted_cot_data/qasc_train.json\n",
        "      - Chain-of-Thought/formatted_cot_data/qed_train.json\n",
        "      - Chain-of-Thought/formatted_cot_data/sensemaking_train.json\n",
        "      - Chain-of-Thought/formatted_cot_data/strategyqa_train.json\n",
        "      - GPTeacher/Roleplay/formatted_roleplay-similarity_0.6-instruct-dataset.json\n",
        "    type: alpaca_chat\n",
        "  - path: ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered\n",
        "    type: alpaca_chat\n",
        "  - path: ehartford/wizard_vicuna_70k_unfiltered\n",
        "    type: sharegpt:chat\n",
        "\n",
        "dataset_prepared_path: last_run_prepared\n",
        "val_set_size: 0.01\n",
        "# enable QLoRA\n",
        "adapter: qlora\n",
        "lora_model_dir:\n",
        "sequence_len: 2048\n",
        "max_packed_sequence_len:\n",
        "\n",
        "# hyperparameters from QLoRA paper Appendix B.2\n",
        "# \"We find hyperparameters to be largely robust across datasets\"\n",
        "lora_r: 64\n",
        "lora_alpha: 16\n",
        "# 0.1 for models up to 13B\n",
        "# 0.05 for 33B and 65B models\n",
        "lora_dropout: 0.05\n",
        "# add LoRA modules on all linear layers of the base model\n",
        "lora_target_modules:\n",
        "lora_target_linear: true\n",
        "lora_fan_in_fan_out:\n",
        "\n",
        "wandb_project: falcon-qlora\n",
        "wandb_watch:\n",
        "wandb_run_id:\n",
        "wandb_log_model:\n",
        "output_dir: /content/axolotl-trained/falcon-qlora-40b-gsm8k/\n",
        "\n",
        "# QLoRA paper Table 9\n",
        "# - 16 for 7b & 13b\n",
        "# - 32 for 33b, 64 for 64b\n",
        "# Max size tested on A6000\n",
        "# - 7b: 40\n",
        "# - 40b: 4\n",
        "# decrease if OOM, increase for max VRAM utilization\n",
        "micro_batch_size: 4\n",
        "gradient_accumulation_steps: 1\n",
        "num_epochs: 3\n",
        "# Optimizer for QLoRA\n",
        "optimizer: paged_adamw_32bit\n",
        "torchdistx_path:\n",
        "lr_scheduler: cosine\n",
        "# QLoRA paper Table 9\n",
        "# - 2e-4 for 7b & 13b\n",
        "# - 1e-4 for 33b & 64b\n",
        "learning_rate: 0.0002\n",
        "train_on_inputs: false\n",
        "group_by_length: false\n",
        "bf16: true\n",
        "fp16: false\n",
        "tf32: true\n",
        "gradient_checkpointing: true\n",
        "# stop training after this many evaluation losses have increased in a row\n",
        "# https://huggingface.co/transformers/v4.2.2/_modules/transformers/trainer_callback.html#EarlyStoppingCallback\n",
        "# early_stopping_patience: 3\n",
        "resume_from_checkpoint:\n",
        "auto_resume_from_checkpoints: true\n",
        "local_rank:\n",
        "logging_steps: 1\n",
        "xformers_attention: true\n",
        "flash_attention:\n",
        "gptq_groupsize:\n",
        "gptq_model_v1:\n",
        "warmup_steps: 10\n",
        "eval_steps: 5\n",
        "save_steps: 10\n",
        "debug:\n",
        "deepspeed:\n",
        "weight_decay: 0.01\n",
        "adam_beta1:\n",
        "adam_beta2: 0.999\n",
        "adam_epsilon:\n",
        "# Gradient clipping max norm\n",
        "max_grad_norm: 0.3\n",
        "\n",
        "fsdp:\n",
        "fsdp_config:\n",
        "special_tokens:\n",
        "  pad_token: \"<|endoftext|>\"\n",
        "  bos_token: \">>ABSTRACT<<\"\n",
        "  eos_token: \"<|endoftext|>\""
      ],
      "metadata": {
        "id": "6bR8BwTJXDkU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python scripts/finetune.py examples/falcon/config-40b-qlora.yml -prepare_ds_only"
      ],
      "metadata": {
        "id": "vTOYjexcXblC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3E1gNNve8sra"
      },
      "source": [
        "# Chores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmp8Th0D8sra"
      },
      "source": [
        "## Clean up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BfQXJ3CpXJ_d"
      },
      "outputs": [],
      "source": [
        "!rm -rf /content/axolotl/last_run_prepared"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RyO-KRuB8srb"
      },
      "source": [
        "## `sharegpt_jokes` Patch\n",
        "\n",
        "https://github.com/OpenAccess-AI-Collective/axolotl/pull/192"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_jJLqlr-XXHM",
        "outputId": "294d36dc-4670-4312-c388-2cb7c4c1cdb9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/workspace\n"
          ]
        }
      ],
      "source": [
        "%cd /workspace/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7GR9EKon8srb"
      },
      "outputs": [],
      "source": [
        "!rm -rf axolotl-patch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L5OY6kWv8src",
        "outputId": "a78b6dbf-296b-4fc0-dc88-23ac4e7e3c5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'axolotl-patch'...\n",
            "remote: Enumerating objects: 3119, done.\u001b[K\n",
            "remote: Counting objects: 100% (1332/1332), done.\u001b[K\n",
            "remote: Compressing objects: 100% (349/349), done.\u001b[K\n",
            "remote: Total 3119 (delta 1085), reused 1092 (delta 933), pack-reused 1787\u001b[K\n",
            "Receiving objects: 100% (3119/3119), 1.42 MiB | 16.97 MiB/s, done.\n",
            "Resolving deltas: 100% (1953/1953), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/OpenAccess-AI-Collective/axolotl axolotl-patch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IXssp8b98src",
        "outputId": "0c71a37d-ae16-48ba-b89d-8c497085b5de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/workspace/axolotl-patch\n"
          ]
        }
      ],
      "source": [
        "%cd axolotl-patch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YaosxjA88src",
        "outputId": "603ed259-6612-4509-c5ef-ab3e95ab9c78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Branch 'sharegpt-custom-prompt' set up to track remote branch 'sharegpt-custom-prompt' from 'origin'.\n",
            "Switched to a new branch 'sharegpt-custom-prompt'\n"
          ]
        }
      ],
      "source": [
        "!git checkout sharegpt-custom-prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T_VlO2_L8src",
        "outputId": "8cfe4131-d8e6-4c74-dc95-2f98b5f397d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "On branch sharegpt-custom-prompt\n",
            "Your branch is up to date with 'origin/sharegpt-custom-prompt'.\n",
            "\n",
            "nothing to commit, working tree clean\n"
          ]
        }
      ],
      "source": [
        "!git status"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VPGSaf6u8srd",
        "outputId": "2e617590-f9ff-4ec0-d2bd-0042755a2d8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/workspace\n"
          ]
        }
      ],
      "source": [
        "%cd /workspace/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fCJwdeQF8srd"
      },
      "outputs": [],
      "source": [
        "!cp -r axolotl-patch/* axolotl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TOQKrk2t8srd",
        "outputId": "5e3a80be-1d15-40e1-d872-f3349c5ac3bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/workspace/axolotl\n"
          ]
        }
      ],
      "source": [
        "%cd axolotl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NnEYqKF18srd",
        "outputId": "d8fa4e09-bd61-4f86-9fa2-40ee0b2659e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "On branch main\n",
            "Your branch is up to date with 'origin/main'.\n",
            "\n",
            "Changes not staged for commit:\n",
            "  (use \"git add <file>...\" to update what will be committed)\n",
            "  (use \"git restore <file>...\" to discard changes in working directory)\n",
            "\t\u001b[31mmodified:   FAQS.md\u001b[m\n",
            "\t\u001b[31mmodified:   README.md\u001b[m\n",
            "\t\u001b[31mmodified:   docker/Dockerfile\u001b[m\n",
            "\t\u001b[31mmodified:   docker/Dockerfile-base\u001b[m\n",
            "\t\u001b[31mmodified:   examples/gptq-lora-7b/config.yml\u001b[m\n",
            "\t\u001b[31mmodified:   examples/mpt-7b/config.yml\u001b[m\n",
            "\t\u001b[31mmodified:   requirements.txt\u001b[m\n",
            "\t\u001b[31mmodified:   scripts/finetune.py\u001b[m\n",
            "\t\u001b[31mmodified:   scripts/runpod-entrypoint.sh\u001b[m\n",
            "\t\u001b[31mmodified:   src/axolotl/datasets.py\u001b[m\n",
            "\t\u001b[31mmodified:   src/axolotl/flash_attn.py\u001b[m\n",
            "\t\u001b[31mmodified:   src/axolotl/prompt_strategies/alpaca_chat.py\u001b[m\n",
            "\t\u001b[31mmodified:   src/axolotl/prompters.py\u001b[m\n",
            "\t\u001b[31mmodified:   src/axolotl/utils/data.py\u001b[m\n",
            "\t\u001b[31mmodified:   src/axolotl/utils/models.py\u001b[m\n",
            "\t\u001b[31mmodified:   src/axolotl/utils/trainer.py\u001b[m\n",
            "\t\u001b[31mmodified:   src/axolotl/utils/validation.py\u001b[m\n",
            "\t\u001b[31mmodified:   src/axolotl/utils/wandb.py\u001b[m\n",
            "\t\u001b[31mmodified:   tests/test_prompt_tokenizers.py\u001b[m\n",
            "\t\u001b[31mmodified:   tests/test_validation.py\u001b[m\n",
            "\n",
            "Untracked files:\n",
            "  (use \"git add <file>...\" to include in what will be committed)\n",
            "\t\u001b[31mdocker-compose.yaml\u001b[m\n",
            "\t\u001b[31mexamples/cerebras/\u001b[m\n",
            "\t\u001b[31mexamples/falcon/config-7b-qlora.yml\u001b[m\n",
            "\t\u001b[31mexamples/falcon/ft.yml\u001b[m\n",
            "\t\u001b[31mexamples/falcon/lora.yml\u001b[m\n",
            "\t\u001b[31mexamples/falcon/qlora.yml\u001b[m\n",
            "\t\u001b[31mexamples/gptj/\u001b[m\n",
            "\t\u001b[31mexamples/huggyllama/\u001b[m\n",
            "\t\u001b[31mexamples/jeopardy-bot/\u001b[m\n",
            "\t\u001b[31mexamples/openllama-3b/\u001b[m\n",
            "\t\u001b[31mexamples/openllama/\u001b[m\n",
            "\t\u001b[31mexamples/pythia/\u001b[m\n",
            "\t\u001b[31mimage/axolotl-badge-web.png\u001b[m\n",
            "\t\u001b[31msrc/axolotl/monkeypatch/\u001b[m\n",
            "\t\u001b[31msrc/axolotl/prompt_strategies/context_qa.py\u001b[m\n",
            "\t\u001b[31msrc/axolotl/prompt_strategies/sharegpt_jokes.py\u001b[m\n",
            "\t\u001b[31msrc/axolotl/prompt_strategies/sharegpt_simple.py\u001b[m\n",
            "\t\u001b[31mtests/fixtures/alpaca/\u001b[m\n",
            "\t\u001b[31mtests/test_packed_dataset.py\u001b[m\n",
            "\n",
            "no changes added to commit (use \"git add\" and/or \"git commit -a\")\n"
          ]
        }
      ],
      "source": [
        "!git status"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Q7JUhPl8srd"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "064dc7a36e3141a7bda70adb723791f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "PasswordModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_16b9ed34f3494401b5bbd8103b67097a",
            "placeholder": "​",
            "style": "IPY_MODEL_5c68d498914448cda16a6a1d37be1780",
            "value": ""
          }
        },
        "07e43ba6fbe44f2b94fab16e970d3a02": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0dd2b6777bec401b867867a5cdbedd23": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c62beb828d2f4c1ca13e50736d817232",
            "placeholder": "​",
            "style": "IPY_MODEL_cd9a2b859a05461f9ddee1ad98d77bf5",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "13def2c1464a4eada87d139eaaf8773e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "16b9ed34f3494401b5bbd8103b67097a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1cb197ba0137492fb8e953b05d73d0d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89273b45582947faa13889eed2a04ff6",
            "placeholder": "​",
            "style": "IPY_MODEL_ba4c7ffae5e8419ba99e126666148b49",
            "value": "Login successful"
          }
        },
        "29a22c57ce28449cbb062b493124c68c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3440a93ed74749358bae76d2bd8861ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "34b6dd2b7e264c2394bb1d79a05bc065": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d420532df0e438da7d94ab32e6ebb22": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6f7e6381b6fd4301a3ddf02d351caa50",
              "IPY_MODEL_99aab7f417784805a2b7c94e7a9d549f",
              "IPY_MODEL_6effd08048af4f1091973d4b5dc74694",
              "IPY_MODEL_1cb197ba0137492fb8e953b05d73d0d7"
            ],
            "layout": "IPY_MODEL_54ac694cc9a34de2afcc4077b6611936"
          }
        },
        "54ac694cc9a34de2afcc4077b6611936": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "5654a4fc9e1a4cf9b48d233329fe3c75": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57bf0e73135643b09821981f1bcbd971": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5654a4fc9e1a4cf9b48d233329fe3c75",
            "placeholder": "​",
            "style": "IPY_MODEL_3440a93ed74749358bae76d2bd8861ab",
            "value": "Connecting..."
          }
        },
        "5c68d498914448cda16a6a1d37be1780": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "608f3bf410e942b887c138de6429c2a1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ad4144260cb4733933947fd26bfbc25": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "6effd08048af4f1091973d4b5dc74694": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_34b6dd2b7e264c2394bb1d79a05bc065",
            "placeholder": "​",
            "style": "IPY_MODEL_29a22c57ce28449cbb062b493124c68c",
            "value": "Your token has been saved to /root/.cache/huggingface/token"
          }
        },
        "6f7e6381b6fd4301a3ddf02d351caa50": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_febd7a732c4e408cbde580a1c8db57f0",
            "placeholder": "​",
            "style": "IPY_MODEL_c30292fd334143c3803cfbb69cf9a67f",
            "value": "Token is valid (permission: write)."
          }
        },
        "79bb8e0094ff4b6d85460391781309b4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89273b45582947faa13889eed2a04ff6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c56af0ee49c4992a2644ad1ff3c0404": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_f8d0567cf49b498092a965abbe041133",
            "style": "IPY_MODEL_6ad4144260cb4733933947fd26bfbc25",
            "tooltip": ""
          }
        },
        "8ea6ca6af7a04e7cba7b93eda06ae420": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99aab7f417784805a2b7c94e7a9d549f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_608f3bf410e942b887c138de6429c2a1",
            "placeholder": "​",
            "style": "IPY_MODEL_07e43ba6fbe44f2b94fab16e970d3a02",
            "value": "Your token has been saved in your configured git credential helpers (store)."
          }
        },
        "ba4c7ffae5e8419ba99e126666148b49": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c1f0fd41f0b54a59be62e086db7459c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c30292fd334143c3803cfbb69cf9a67f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c62beb828d2f4c1ca13e50736d817232": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd9a2b859a05461f9ddee1ad98d77bf5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d3e29b6ef6ab49e987c284dec6a9aedb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "CheckboxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_79bb8e0094ff4b6d85460391781309b4",
            "style": "IPY_MODEL_c1f0fd41f0b54a59be62e086db7459c3",
            "value": true
          }
        },
        "e470289f17114e4cb76f7d3e2b755ad7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ea6ca6af7a04e7cba7b93eda06ae420",
            "placeholder": "​",
            "style": "IPY_MODEL_13def2c1464a4eada87d139eaaf8773e",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "f8d0567cf49b498092a965abbe041133": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "febd7a732c4e408cbde580a1c8db57f0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}