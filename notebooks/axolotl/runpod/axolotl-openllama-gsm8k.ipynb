{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zJvyUmZdktu0",
    "outputId": "25275dd8-4787-4b77-f7bf-4f2bbe66f0b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/axolotl\n"
     ]
    }
   ],
   "source": [
    "%cd /workspace/axolotl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mC48y25Lkqa5",
    "outputId": "2757a3c8-3790-4fd3-be39-03be8f533b35"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting ds_accelerator to cuda (auto detect)\n",
      "accelerate configuration saved at /root/.cache/huggingface/accelerate/default_config.yaml\n"
     ]
    }
   ],
   "source": [
    "!accelerate config --config_file configs/accelerate/default_config.yaml default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Based on https://gist.github.com/fearnworks/723709806cebc67bafe1eb8138e7efbd\n",
      "base_model: openlm-research/open_llama_3b_600bt_preview\n",
      "base_model_config: openlm-research/open_llama_3b_600bt_preview\n",
      "model_type: LlamaForCausalLM\n",
      "tokenizer_type: LlamaTokenizer\n",
      "load_in_8bit: false\n",
      "load_in_4bit: true\n",
      "strict: false\n",
      "push_dataset_to_hub:\n",
      "datasets:\n",
      "  - path: QingyiSi/Alpaca-CoT\n",
      "    data_files:\n",
      "      - Chain-of-Thought/formatted_cot_data/gsm8k_train.json\n",
      "    type: \"alpaca:chat\"\n",
      "dataset_prepared_path: last_run_prepared\n",
      "val_set_size: 0.01\n",
      "adapter: qlora\n",
      "lora_model_dir:\n",
      "sequence_len: 2048\n",
      "max_packed_sequence_len:\n",
      "lora_r: 16\n",
      "lora_alpha: 32\n",
      "lora_dropout: 0.05\n",
      "lora_target_modules:\n",
      "lora_target_linear: true\n",
      "lora_fan_in_fan_out:\n",
      "wandb_project: openllama-qlora-gsm8k\n",
      "wandb_watch:\n",
      "wandb_run_id:\n",
      "wandb_log_model: checkpoint\n",
      "output_dir: ./qlora-out\n",
      "batch_size: 4\n",
      "micro_batch_size: 4\n",
      "num_epochs: 1\n",
      "optimizer: paged_adamw_32bit\n",
      "torchdistx_path:\n",
      "lr_scheduler: cosine\n",
      "learning_rate: 0.0002\n",
      "train_on_inputs: false\n",
      "group_by_length: false\n",
      "bf16: true\n",
      "fp16: false\n",
      "tf32: true\n",
      "gradient_checkpointing: true\n",
      "early_stopping_patience:\n",
      "resume_from_checkpoint:\n",
      "auto_resume_from_checkpoints: true\n",
      "local_rank:\n",
      "logging_steps: 1\n",
      "xformers_attention: true\n",
      "flash_attention:\n",
      "gptq_groupsize:\n",
      "gptq_model_v1:\n",
      "warmup_steps: 10\n",
      "eval_steps: 20\n",
      "save_steps: 100\n",
      "debug:\n",
      "deepspeed:\n",
      "weight_decay: 0.0\n",
      "fsdp:\n",
      "fsdp_config:\n",
      "special_tokens:\n",
      "  bos_token: \"<s>\"\n",
      "  eos_token: \"</s>\"\n",
      "  unk_token: \"<unk>\"\n"
     ]
    }
   ],
   "source": [
    "!cat examples/openllama/qlora.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "jICMPJuomFsx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting ds_accelerator to cuda (auto detect)\n",
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "bin /root/miniconda3/envs/py3.9/lib/python3.9/site-packages/bitsandbytes-0.39.0-py3.9.egg/bitsandbytes/libbitsandbytes_cuda118.so\n",
      "/root/miniconda3/envs/py3.9/lib/python3.9/site-packages/bitsandbytes-0.39.0-py3.9.egg/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/usr/local/nvidia/lib64'), PosixPath('/usr/local/nvidia/lib')}\n",
      "  warn(msg)\n",
      "/root/miniconda3/envs/py3.9/lib/python3.9/site-packages/bitsandbytes-0.39.0-py3.9.egg/bitsandbytes/cuda_setup/main.py:149: UserWarning: /usr/local/nvidia/lib:/usr/local/nvidia/lib64 did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...\n",
      "  warn(msg)\n",
      "/root/miniconda3/envs/py3.9/lib/python3.9/site-packages/bitsandbytes-0.39.0-py3.9.egg/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('//matplotlib_inline.backend_inline'), PosixPath('module')}\n",
      "  warn(msg)\n",
      "/root/miniconda3/envs/py3.9/lib/python3.9/site-packages/bitsandbytes-0.39.0-py3.9.egg/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIK1tFOFrWbmoa2ckCJYhzgBHKTSMeR/AeuScCCzugqlI utensilcandel@gmail.com')}\n",
      "  warn(msg)\n",
      "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching in backup paths...\n",
      "/root/miniconda3/envs/py3.9/lib/python3.9/site-packages/bitsandbytes-0.39.0-py3.9.egg/bitsandbytes/cuda_setup/main.py:149: UserWarning: Found duplicate ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] files: {PosixPath('/usr/local/cuda/lib64/libcudart.so'), PosixPath('/usr/local/cuda/lib64/libcudart.so.11.0')}.. We'll flip a coin and try one of these, in order to fail forward.\n",
      "Either way, this might cause trouble in the future:\n",
      "If you get `CUDA error: invalid device function` errors, the above might be the cause and the solution is to make sure only one ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] in the paths that we search based on your env.\n",
      "  warn(msg)\n",
      "CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 8.6\n",
      "CUDA SETUP: Detected CUDA version 118\n",
      "CUDA SETUP: Loading binary /root/miniconda3/envs/py3.9/lib/python3.9/site-packages/bitsandbytes-0.39.0-py3.9.egg/bitsandbytes/libbitsandbytes_cuda118.so...\n",
      "Setting ds_accelerator to cuda (auto detect)\n",
      "INFO:root:loading tokenizer...\n",
      "Using pad_token, but it is not set yet.\n",
      "INFO:root:Loading prepared dataset from disk at last_run_prepared/ad4057cb8b111b35ea37b1112981addc...\n",
      "INFO:root:Prepared dataset loaded from disk...\n",
      "INFO:root:loading model and peft_config...\n",
      "INFO:root:patching with xformers attention\n",
      "Replaced attention with xformers_attention\u001b[0m\n",
      "INFO:root:converting PEFT model w/ prepare_model_for_int8_training\n",
      "/root/miniconda3/envs/py3.9/lib/python3.9/site-packages/peft/utils/other.py:76: FutureWarning: prepare_model_for_int8_training is deprecated and will be removed in a future version. Use prepare_model_for_kbit_training instead.\n",
      "  warnings.warn(\n",
      "\u001b[0mINFO:root:found linear modules: ['gate_proj', 'k_proj', 'o_proj', 'v_proj', 'down_proj', 'q_proj', 'up_proj']\n",
      "\u001b[0mtrainable params: 25425920 || all params: 1841147520 || trainable%: 1.3809822256936803\u001b[0m\n",
      "INFO:root:Compiling torch model\n",
      "\u001b[0mINFO:root:Pre-saving adapter config to ./qlora-out\n",
      "INFO:root:Starting trainer...\n",
      "INFO:root:Using Auto-resume functionality to start with checkpoint at qlora-out/checkpoint-1700\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mutensil\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[0m\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.3\n",
      "\u001b[0m\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/workspace/axolotl/wandb/run-20230530_053900-6qux8m6i\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[0m\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mjolly-bee-2\u001b[0m\n",
      "\u001b[0m\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/utensil/openllama-qlora-gsm8k\u001b[0m\n",
      "\u001b[0m\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/utensil/openllama-qlora-gsm8k/runs/6qux8m6i\u001b[0m\n",
      "\u001b[0m\u001b[0m{'loss': 0.6485, 'learning_rate': 3.2185709798097096e-06, 'epoch': 0.92}\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.768, 'learning_rate': 3.1757430279430787e-06, 'epoch': 0.92}\u001b[0mm\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.7265, 'learning_rate': 3.133197335315763e-06, 'epoch': 0.92}\u001b[0mm\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.6011, 'learning_rate': 3.090934025955705e-06, 'epoch': 0.92}\u001b[0mm\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.6232, 'learning_rate': 3.0489532230676743e-06, 'epoch': 0.92}\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.5887, 'learning_rate': 3.0072550490328753e-06, 'epoch': 0.92}\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.6242, 'learning_rate': 2.9658396254086063e-06, 'epoch': 0.92}\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.4414, 'learning_rate': 2.9247070729279013e-06, 'epoch': 0.92}\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.6095, 'learning_rate': 2.8838575114991774e-06, 'epoch': 0.92}\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.5843, 'learning_rate': 2.843291060205855e-06, 'epoch': 0.92}\u001b[0mm\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.8026, 'learning_rate': 2.8030078373060818e-06, 'epoch': 0.92}\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.6676, 'learning_rate': 2.7630079602323442e-06, 'epoch': 0.93}\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.753, 'learning_rate': 2.723291545591089e-06, 'epoch': 0.93}\u001b[0m0m\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.5192, 'learning_rate': 2.683858709162468e-06, 'epoch': 0.93}\u001b[0mm\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.7247, 'learning_rate': 2.6447095658999053e-06, 'epoch': 0.93}\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.6518, 'learning_rate': 2.6058442299298435e-06, 'epoch': 0.93}\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.5277, 'learning_rate': 2.567262814551397e-06, 'epoch': 0.93}\u001b[0mm\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.6317, 'learning_rate': 2.5289654322359523e-06, 'epoch': 0.93}\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.6261, 'learning_rate': 2.4909521946269166e-06, 'epoch': 0.93}\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.5708, 'learning_rate': 2.4532232125393906e-06, 'epoch': 0.93}\u001b[0m\n",
      " 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1720/1850 [00:16<00:00, 1130.96it/s]\u001b[0m\u001b[0m\n",
      "  0%|                                                    | 0/19 [00:00<?, ?it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 11%|‚ñà‚ñà‚ñà‚ñà‚ñã                                       | 2/19 [00:00<00:01,  8.55it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 16%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                     | 3/19 [00:00<00:02,  7.30it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 21%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                  | 4/19 [00:00<00:02,  5.85it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 26%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                | 5/19 [00:00<00:02,  5.39it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                              | 6/19 [00:01<00:02,  5.01it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                           | 7/19 [00:01<00:02,  4.96it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                         | 8/19 [00:01<00:02,  4.73it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 47%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                       | 9/19 [00:01<00:02,  4.77it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                    | 10/19 [00:01<00:01,  4.88it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                  | 11/19 [00:02<00:01,  4.89it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè               | 12/19 [00:02<00:01,  4.70it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç             | 13/19 [00:02<00:01,  4.55it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã           | 14/19 [00:02<00:01,  4.46it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ         | 15/19 [00:03<00:00,  4.30it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè      | 16/19 [00:03<00:00,  4.32it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 17/19 [00:03<00:00,  4.56it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1720/1850 [00:20<00:00, 1130.96it/s]\u001b[0m\u001b[A\u001b[0m\n",
      "\u001b[0m\u001b[0m                                                                        \u001b[0m\u001b[A\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[A\u001b[0m{'eval_loss': 0.6576464772224426, 'eval_runtime': 4.0406, 'eval_samples_per_second': 18.562, 'eval_steps_per_second': 4.702, 'epoch': 0.93}\u001b[0m\n",
      " 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1720/1850 [00:20<00:00, 1130.96it/s]\u001b[0m\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 19/19 [00:03<00:00,  5.09it/s]\u001b[0m\u001b[A\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.8195, 'learning_rate': 2.4157785959597834e-06, 'epoch': 0.93}\u001b[0m[0m\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.6535, 'learning_rate': 2.3786184540455448e-06, 'epoch': 0.93}\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.5749, 'learning_rate': 2.341742895124832e-06, 'epoch': 0.93}\u001b[0mm\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.588, 'learning_rate': 2.305152026696189e-06, 'epoch': 0.93}\u001b[0m0m\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.6889, 'learning_rate': 2.268845955428267e-06, 'epoch': 0.93}\u001b[0mm\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.5893, 'learning_rate': 2.2328247871594377e-06, 'epoch': 0.93}\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.6911, 'learning_rate': 2.1970886268975586e-06, 'epoch': 0.93}\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.7405, 'learning_rate': 2.161637578819653e-06, 'epoch': 0.93}\u001b[0mm\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.754, 'learning_rate': 2.1264717462715745e-06, 'epoch': 0.93}\u001b[0mm\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.587, 'learning_rate': 2.091591231767709e-06, 'epoch': 0.94}\u001b[0m0m\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.6495, 'learning_rate': 2.056996136990741e-06, 'epoch': 0.94}\u001b[0mm\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.6435, 'learning_rate': 2.022686562791254e-06, 'epoch': 0.94}\u001b[0mm\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.7923, 'learning_rate': 1.9886626091875305e-06, 'epoch': 0.94}\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.6985, 'learning_rate': 1.9549243753651967e-06, 'epoch': 0.94}\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.7868, 'learning_rate': 1.921471959676957e-06, 'epoch': 0.94}\u001b[0mm\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.7751, 'learning_rate': 1.8883054596423256e-06, 'epoch': 0.94}\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.7849, 'learning_rate': 1.855424971947306e-06, 'epoch': 0.94}\u001b[0mm\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.7828, 'learning_rate': 1.822830592444147e-06, 'epoch': 0.94}\u001b[0mm\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.4711, 'learning_rate': 1.790522416151008e-06, 'epoch': 0.94}\u001b[0mm\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.9176, 'learning_rate': 1.7585005372517504e-06, 'epoch': 0.94}\u001b[0m\n",
      " 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1740/1850 [00:35<00:01, 55.87it/s]\u001b[0m\u001b[0m\n",
      "  0%|                                                    | 0/19 [00:00<?, ?it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 11%|‚ñà‚ñà‚ñà‚ñà‚ñã                                       | 2/19 [00:00<00:02,  8.50it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 16%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                     | 3/19 [00:00<00:02,  7.28it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 21%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                  | 4/19 [00:00<00:02,  5.87it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 26%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                | 5/19 [00:00<00:02,  5.43it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                              | 6/19 [00:01<00:02,  4.89it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                           | 7/19 [00:01<00:02,  4.89it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                         | 8/19 [00:01<00:02,  4.70it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 47%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                       | 9/19 [00:01<00:02,  4.76it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                    | 10/19 [00:01<00:01,  4.88it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                  | 11/19 [00:02<00:01,  4.90it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè               | 12/19 [00:02<00:01,  4.70it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç             | 13/19 [00:02<00:01,  4.56it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã           | 14/19 [00:02<00:01,  4.46it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ         | 15/19 [00:03<00:00,  4.40it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè      | 16/19 [00:03<00:00,  4.38it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 17/19 [00:03<00:00,  4.60it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 18/19 [00:03<00:00,  4.95it/s]\u001b[0m\u001b[A\u001b[0m\n",
      "\u001b[0m\u001b[0m                                                                        \u001b[0m\u001b[0m[0m\n",
      "\u001b[0m\u001b[A\u001b[0m{'eval_loss': 0.6570568084716797, 'eval_runtime': 4.0318, 'eval_samples_per_second': 18.602, 'eval_steps_per_second': 4.713, 'epoch': 0.94}\u001b[0m\n",
      " 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1740/1850 [00:40<00:01, 55.87it/s]\u001b[0m\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 19/19 [00:03<00:00,  5.12it/s]\u001b[0m\u001b[A\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.7643, 'learning_rate': 1.7267650490956134e-06, 'epoch': 0.94}\u001b[0m[0m\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.5953, 'learning_rate': 1.6953160441969706e-06, 'epoch': 0.94}\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.6199, 'learning_rate': 1.6641536142350423e-06, 'epoch': 0.94}\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.6336, 'learning_rate': 1.633277850053605e-06, 'epoch': 0.94}\u001b[0mm\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.7973, 'learning_rate': 1.6026888416608265e-06, 'epoch': 0.94}\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.5479, 'learning_rate': 1.5723866782288543e-06, 'epoch': 0.94}\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.6715, 'learning_rate': 1.5423714480936823e-06, 'epoch': 0.94}\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.8049, 'learning_rate': 1.5126432387548184e-06, 'epoch': 0.94}\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.7677, 'learning_rate': 1.4832021368750837e-06, 'epoch': 0.95}\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.8298, 'learning_rate': 1.4540482282803137e-06, 'epoch': 0.95}\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.7538, 'learning_rate': 1.4251815979591244e-06, 'epoch': 0.95}\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.7085, 'learning_rate': 1.3966023300626685e-06, 'epoch': 0.95}\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.8162, 'learning_rate': 1.3683105079044023e-06, 'epoch': 0.95}\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.8149, 'learning_rate': 1.3403062139598076e-06, 'epoch': 0.95}\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.6546, 'learning_rate': 1.3125895298661706e-06, 'epoch': 0.95}\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.5127, 'learning_rate': 1.2851605364223918e-06, 'epoch': 0.95}\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.5255, 'learning_rate': 1.2580193135886431e-06, 'epoch': 0.95}\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.4162, 'learning_rate': 1.231165940486234e-06, 'epoch': 0.95}\u001b[0mm\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.6497, 'learning_rate': 1.2046004953973233e-06, 'epoch': 0.95}\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.6524, 'learning_rate': 1.1783230557647074e-06, 'epoch': 0.95}\u001b[0m\n",
      " 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1760/1850 [00:56<00:04, 19.63it/s]\u001b[0m\u001b[0m\n",
      "  0%|                                                    | 0/19 [00:00<?, ?it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 11%|‚ñà‚ñà‚ñà‚ñà‚ñã                                       | 2/19 [00:00<00:01,  8.56it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 16%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                     | 3/19 [00:00<00:02,  7.29it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 21%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                  | 4/19 [00:00<00:02,  5.86it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 26%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                | 5/19 [00:00<00:02,  5.43it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                              | 6/19 [00:01<00:02,  4.97it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                           | 7/19 [00:01<00:02,  4.93it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                         | 8/19 [00:01<00:02,  4.72it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 47%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                       | 9/19 [00:01<00:02,  4.77it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                    | 10/19 [00:01<00:01,  4.87it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                  | 11/19 [00:02<00:01,  4.88it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè               | 12/19 [00:02<00:01,  4.69it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç             | 13/19 [00:02<00:01,  4.55it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã           | 14/19 [00:02<00:01,  4.43it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ         | 15/19 [00:03<00:00,  4.37it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè      | 16/19 [00:03<00:00,  4.36it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1760/1850 [01:00<00:04, 19.63it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 18/19 [00:03<00:00,  4.92it/s]\u001b[0m\u001b[A\u001b[0m\n",
      "\u001b[0m\u001b[0m                                                                        \u001b[0m\u001b[A\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[A\u001b[0m{'eval_loss': 0.6565337777137756, 'eval_runtime': 4.037, 'eval_samples_per_second': 18.578, 'eval_steps_per_second': 4.706, 'epoch': 0.95}\u001b[0m\n",
      " 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1760/1850 [01:00<00:04, 19.63it/s]\u001b[0m\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 19/19 [00:03<00:00,  5.09it/s]\u001b[0m\u001b[A\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.6893, 'learning_rate': 1.1523336981916433e-06, 'epoch': 0.95}\u001b[0m[0m\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.6545, 'learning_rate': 1.1266324984415266e-06, 'epoch': 0.95}\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.7218, 'learning_rate': 1.101219531437736e-06, 'epoch': 0.95}\u001b[0mm\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.5908, 'learning_rate': 1.076094871263411e-06, 'epoch': 0.95}\u001b[0mm\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.58, 'learning_rate': 1.0512585911612416e-06, 'epoch': 0.95}\u001b[0m0m\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.6681, 'learning_rate': 1.0267107635331897e-06, 'epoch': 0.95}\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.6666, 'learning_rate': 1.0024514599404123e-06, 'epoch': 0.96}\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.5513, 'learning_rate': 9.784807511028838e-07, 'epoch': 0.96}\u001b[0mm\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.7621, 'learning_rate': 9.54798706899318e-07, 'epoch': 0.96}\u001b[0m0m\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.6631, 'learning_rate': 9.314053963669245e-07, 'epoch': 0.96}\u001b[0mm\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.6064, 'learning_rate': 9.083008877011967e-07, 'epoch': 0.96}\u001b[0mm\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.6046, 'learning_rate': 8.854852482557241e-07, 'epoch': 0.96}\u001b[0mm\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.5207, 'learning_rate': 8.629585445419918e-07, 'epoch': 0.96}\u001b[0mm\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.4428, 'learning_rate': 8.407208422291701e-07, 'epoch': 0.96}\u001b[0mm\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.6011, 'learning_rate': 8.187722061439806e-07, 'epoch': 0.96}\u001b[0mm\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.5063, 'learning_rate': 7.971127002704304e-07, 'epoch': 0.96}\u001b[0mm\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.6823, 'learning_rate': 7.757423877496783e-07, 'epoch': 0.96}\u001b[0mm\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.6275, 'learning_rate': 7.546613308798466e-07, 'epoch': 0.96}\u001b[0mm\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.5829, 'learning_rate': 7.338695911157989e-07, 'epoch': 0.96}\u001b[0mm\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.5275, 'learning_rate': 7.133672290690063e-07, 'epoch': 0.96}\u001b[0mm\n",
      " 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1780/1850 [01:16<00:12,  5.55it/s]\u001b[0m\u001b[0m\n",
      "  0%|                                                    | 0/19 [00:00<?, ?it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 11%|‚ñà‚ñà‚ñà‚ñà‚ñã                                       | 2/19 [00:00<00:01,  8.54it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 16%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                     | 3/19 [00:00<00:02,  7.28it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 21%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                  | 4/19 [00:00<00:02,  5.85it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 26%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                | 5/19 [00:00<00:02,  5.40it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                              | 6/19 [00:01<00:02,  4.99it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                           | 7/19 [00:01<00:02,  4.94it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                         | 8/19 [00:01<00:02,  4.73it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 47%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                       | 9/19 [00:01<00:02,  4.77it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                    | 10/19 [00:01<00:01,  4.89it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                  | 11/19 [00:02<00:01,  4.89it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè               | 12/19 [00:02<00:01,  4.69it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç             | 13/19 [00:02<00:01,  4.53it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã           | 14/19 [00:02<00:01,  4.43it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ         | 15/19 [00:03<00:00,  4.36it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè      | 16/19 [00:03<00:00,  4.35it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 17/19 [00:03<00:00,  4.57it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 18/19 [00:03<00:00,  4.92it/s]\u001b[0m\u001b[A\u001b[0m\n",
      "\u001b[0m\u001b[0m                                                                        \u001b[0m\u001b[A\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[A\u001b[0m{'eval_loss': 0.6562009453773499, 'eval_runtime': 4.074, 'eval_samples_per_second': 18.41, 'eval_steps_per_second': 4.664, 'epoch': 0.96}\u001b[0m\n",
      " 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1780/1850 [01:20<00:12,  5.55it/s]\u001b[0m\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 19/19 [00:03<00:00,  5.09it/s]\u001b[0m\u001b[A\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.726, 'learning_rate': 6.931543045073708e-07, 'epoch': 0.96}\u001b[0mA\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.5627, 'learning_rate': 6.732308763550022e-07, 'epoch': 0.96}\u001b[0mm\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.924, 'learning_rate': 6.535970026921079e-07, 'epoch': 0.96}\u001b[0m0m\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.7588, 'learning_rate': 6.342527407547594e-07, 'epoch': 0.96}\u001b[0mm\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.6054, 'learning_rate': 6.151981469348033e-07, 'epoch': 0.96}\u001b[0mm\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.9341, 'learning_rate': 5.964332767796399e-07, 'epoch': 0.97}\u001b[0mm\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.5076, 'learning_rate': 5.779581849920446e-07, 'epoch': 0.97}\u001b[0mm\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.4745, 'learning_rate': 5.597729254300799e-07, 'epoch': 0.97}\u001b[0mm\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.8348, 'learning_rate': 5.418775511068841e-07, 'epoch': 0.97}\u001b[0mm\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.6965, 'learning_rate': 5.24272114190516e-07, 'epoch': 0.97}\u001b[0m0m\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.603, 'learning_rate': 5.069566660038438e-07, 'epoch': 0.97}\u001b[0m0m\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.4742, 'learning_rate': 4.899312570243453e-07, 'epoch': 0.97}\u001b[0mm\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.5997, 'learning_rate': 4.731959368839967e-07, 'epoch': 0.97}\u001b[0mm\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.7432, 'learning_rate': 4.567507543691174e-07, 'epoch': 0.97}\u001b[0mm\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.5089, 'learning_rate': 4.4059575742021466e-07, 'epoch': 0.97}\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.5229, 'learning_rate': 4.2473099313187215e-07, 'epoch': 0.97}\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.7055, 'learning_rate': 4.091565077525838e-07, 'epoch': 0.97}\u001b[0mm\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.5719, 'learning_rate': 3.938723466846206e-07, 'epoch': 0.97}\u001b[0mm\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.6084, 'learning_rate': 3.788785544839413e-07, 'epoch': 0.97}\u001b[0mm\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.5023, 'learning_rate': 3.641751748600042e-07, 'epoch': 0.97}\u001b[0mm\n",
      " 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1800/1850 [01:36<00:17,  2.79it/s]\u001b[0m\u001b[0m\n",
      "  0%|                                                    | 0/19 [00:00<?, ?it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 11%|‚ñà‚ñà‚ñà‚ñà‚ñã                                       | 2/19 [00:00<00:02,  8.50it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 16%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                     | 3/19 [00:00<00:02,  7.24it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 21%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                  | 4/19 [00:00<00:02,  5.84it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 26%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                | 5/19 [00:00<00:02,  5.41it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                              | 6/19 [00:01<00:02,  4.97it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                           | 7/19 [00:01<00:02,  4.93it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                         | 8/19 [00:01<00:02,  4.71it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 47%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                       | 9/19 [00:01<00:02,  4.76it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                    | 10/19 [00:01<00:01,  4.88it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                  | 11/19 [00:02<00:01,  4.88it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè               | 12/19 [00:02<00:01,  4.69it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç             | 13/19 [00:02<00:01,  4.51it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã           | 14/19 [00:02<00:01,  4.42it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ         | 15/19 [00:03<00:00,  4.36it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè      | 16/19 [00:03<00:00,  4.35it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 17/19 [00:03<00:00,  4.57it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 18/19 [00:03<00:00,  4.91it/s]\u001b[0m\u001b[A\u001b[0m\n",
      "\u001b[0m\u001b[0m                                                                        \u001b[0m\u001b[A\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[A\u001b[0m{'eval_loss': 0.6560156941413879, 'eval_runtime': 4.0466, 'eval_samples_per_second': 18.534, 'eval_steps_per_second': 4.695, 'epoch': 0.97}\u001b[0m\n",
      " 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1800/1850 [01:40<00:17,  2.79it/s]\u001b[0m\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 19/19 [00:03<00:00,  5.09it/s]\u001b[0m\u001b[A\u001b[0m\u001b[0m\n",
      "                                                                                \u001b[0m\u001b[A\u001b[0m\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./qlora-out/checkpoint-1800)... \u001b[0mDone. 4.6s\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.6618, 'learning_rate': 3.4976225067565593e-07, 'epoch': 0.97}\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.6471, 'learning_rate': 3.3563982394704266e-07, 'epoch': 0.97}\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.5643, 'learning_rate': 3.2180793584345447e-07, 'epoch': 0.97}\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.736, 'learning_rate': 3.0826662668720364e-07, 'epoch': 0.98}\u001b[0mm\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.6592, 'learning_rate': 2.9501593595351317e-07, 'epoch': 0.98}\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.508, 'learning_rate': 2.8205590227040615e-07, 'epoch': 0.98}\u001b[0mm\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.6856, 'learning_rate': 2.6938656341860546e-07, 'epoch': 0.98}\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.7998, 'learning_rate': 2.5700795633138983e-07, 'epoch': 0.98}\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.6129, 'learning_rate': 2.449201170945048e-07, 'epoch': 0.98}\u001b[0mm\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.6968, 'learning_rate': 2.3312308094607382e-07, 'epoch': 0.98}\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.522, 'learning_rate': 2.2161688227647636e-07, 'epoch': 0.98}\u001b[0mm\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.6171, 'learning_rate': 2.1040155462824783e-07, 'epoch': 0.98}\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.7514, 'learning_rate': 1.9947713069595753e-07, 'epoch': 0.98}\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.4086, 'learning_rate': 1.8884364232619744e-07, 'epoch': 0.98}\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.5591, 'learning_rate': 1.7850112051738255e-07, 'epoch': 0.98}\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.708, 'learning_rate': 1.684495954197396e-07, 'epoch': 0.98}\u001b[0m0m\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.778, 'learning_rate': 1.5868909633517393e-07, 'epoch': 0.98}\u001b[0mm\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.6057, 'learning_rate': 1.4921965171720287e-07, 'epoch': 0.98}\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.5466, 'learning_rate': 1.400412891708891e-07, 'epoch': 0.98}\u001b[0mm\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.7125, 'learning_rate': 1.3115403545270743e-07, 'epoch': 0.98}\u001b[0m\n",
      " 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1820/1850 [02:03<00:23,  1.27it/s]\u001b[0m\u001b[0m\n",
      "  0%|                                                    | 0/19 [00:00<?, ?it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 11%|‚ñà‚ñà‚ñà‚ñà‚ñã                                       | 2/19 [00:00<00:01,  8.53it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 16%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                     | 3/19 [00:00<00:02,  7.26it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 21%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                  | 4/19 [00:00<00:02,  5.83it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 26%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                | 5/19 [00:00<00:02,  5.39it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                              | 6/19 [00:01<00:02,  4.99it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                           | 7/19 [00:01<00:02,  4.93it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                         | 8/19 [00:01<00:02,  4.72it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 47%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                       | 9/19 [00:01<00:02,  4.75it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                    | 10/19 [00:01<00:01,  4.88it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                  | 11/19 [00:02<00:01,  4.88it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè               | 12/19 [00:02<00:01,  4.68it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç             | 13/19 [00:02<00:01,  4.53it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã           | 14/19 [00:02<00:01,  4.43it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ         | 15/19 [00:03<00:00,  4.26it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè      | 16/19 [00:03<00:00,  4.28it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 17/19 [00:03<00:00,  4.51it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 18/19 [00:03<00:00,  4.87it/s]\u001b[0m\u001b[A\u001b[0m\n",
      "\u001b[0m\u001b[0m                                                                        \u001b[0m\u001b[A\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[A\u001b[0m{'eval_loss': 0.6557585000991821, 'eval_runtime': 4.063, 'eval_samples_per_second': 18.459, 'eval_steps_per_second': 4.676, 'epoch': 0.98}\u001b[0m\n",
      " 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1820/1850 [02:07<00:23,  1.27it/s]\u001b[0m\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 19/19 [00:03<00:00,  5.05it/s]\u001b[0m\u001b[A\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.5576, 'learning_rate': 1.2255791647053373e-07, 'epoch': 0.98}\u001b[0m[0m\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.7485, 'learning_rate': 1.1425295728352269e-07, 'epoch': 0.98}\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.7087, 'learning_rate': 1.0623918210204142e-07, 'epoch': 0.99}\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.508, 'learning_rate': 9.851661428761371e-08, 'epoch': 0.99}\u001b[0m0m\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.6535, 'learning_rate': 9.108527635284247e-08, 'epoch': 0.99}\u001b[0mm\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.6679, 'learning_rate': 8.394518996135414e-08, 'epoch': 0.99}\u001b[0mm\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.5968, 'learning_rate': 7.709637592770991e-08, 'epoch': 0.99}\u001b[0mm\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.5243, 'learning_rate': 7.053885421737239e-08, 'epoch': 0.99}\u001b[0mm\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.689, 'learning_rate': 6.427264394665011e-08, 'epoch': 0.99}\u001b[0m0m\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.7661, 'learning_rate': 5.8297763382597626e-08, 'epoch': 0.99}\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.8609, 'learning_rate': 5.261422994302656e-08, 'epoch': 0.99}\u001b[0mm\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.6358, 'learning_rate': 4.722206019639464e-08, 'epoch': 0.99}\u001b[0mm\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.6221, 'learning_rate': 4.2121269861805645e-08, 'epoch': 0.99}\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.65, 'learning_rate': 3.731187380893175e-08, 'epoch': 0.99}\u001b[0m[0m\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.6781, 'learning_rate': 3.2793886057991276e-08, 'epoch': 0.99}\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.5902, 'learning_rate': 2.8567319779682078e-08, 'epoch': 0.99}\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.4934, 'learning_rate': 2.463218729515937e-08, 'epoch': 0.99}\u001b[0mm\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.8646, 'learning_rate': 2.0988500076013494e-08, 'epoch': 0.99}\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.4899, 'learning_rate': 1.7636268744225527e-08, 'epoch': 0.99}\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.7006, 'learning_rate': 1.4575503072100649e-08, 'epoch': 0.99}\u001b[0m\n",
      " 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1840/1850 [02:22<00:07,  1.34it/s]\u001b[0m\u001b[0m\n",
      "  0%|                                                    | 0/19 [00:00<?, ?it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 11%|‚ñà‚ñà‚ñà‚ñà‚ñã                                       | 2/19 [00:00<00:01,  8.51it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 16%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                     | 3/19 [00:00<00:02,  7.25it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 21%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                  | 4/19 [00:00<00:02,  5.82it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 26%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                | 5/19 [00:00<00:02,  5.37it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                              | 6/19 [00:01<00:02,  4.96it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                           | 7/19 [00:01<00:02,  4.92it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                         | 8/19 [00:01<00:02,  4.70it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 47%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                       | 9/19 [00:01<00:02,  4.74it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                    | 10/19 [00:01<00:01,  4.84it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                  | 11/19 [00:02<00:01,  4.84it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè               | 12/19 [00:02<00:01,  4.66it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç             | 13/19 [00:02<00:01,  4.51it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã           | 14/19 [00:02<00:01,  4.41it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ         | 15/19 [00:03<00:00,  4.36it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè      | 16/19 [00:03<00:00,  4.34it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 17/19 [00:03<00:00,  4.56it/s]\u001b[0m\u001b[A\u001b[0m\n",
      " 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 18/19 [00:03<00:00,  4.90it/s]\u001b[0m\u001b[A\u001b[0m\n",
      "\u001b[0m\u001b[0m                                                                        \u001b[0m\u001b[A\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[A\u001b[0m{'eval_loss': 0.6558101177215576, 'eval_runtime': 4.0667, 'eval_samples_per_second': 18.443, 'eval_steps_per_second': 4.672, 'epoch': 0.99}\u001b[0m\n",
      " 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1840/1850 [02:26<00:07,  1.34it/s]\u001b[0m\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 19/19 [00:03<00:00,  5.04it/s]\u001b[0m\u001b[A\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.8378, 'learning_rate': 1.1806211982301475e-08, 'epoch': 1.0}\u001b[0mm[0m\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.5803, 'learning_rate': 9.32840354779252e-09, 'epoch': 1.0}\u001b[0m[0m\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.6084, 'learning_rate': 7.142084991806908e-09, 'epoch': 1.0}\u001b[0m0m\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.8825, 'learning_rate': 5.2472626878352635e-09, 'epoch': 1.0}\u001b[0mm\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.9209, 'learning_rate': 3.643942159592406e-09, 'epoch': 1.0}\u001b[0m0m\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.5945, 'learning_rate': 2.3321280810617575e-09, 'epoch': 1.0}\u001b[0mm\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.6779, 'learning_rate': 1.3118242763732191e-09, 'epoch': 1.0}\u001b[0mm\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.6918, 'learning_rate': 5.830337199030922e-10, 'epoch': 1.0}\u001b[0m0m\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 0.7354, 'learning_rate': 1.4575853620746316e-10, 'epoch': 1.0}\u001b[0mm\n",
      "\u001b[0m\u001b[0m\u001b[0m{'loss': 1.1168, 'learning_rate': 0.0, 'epoch': 1.0}\u001b[0m            \u001b[0m\u001b[0m\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1850/1850 [02:34<00:00,  1.29it/s]\u001b[0mThe intermediate checkpoints of PEFT may not be saved correctly, using `TrainerCallback` to save adapter_model.bin in corresponding folders, here are some examples https://github.com/huggingface/peft/issues/96\n",
      "\u001b[0mTraceback (most recent call last):\n",
      "\u001b[0m\u001b[0m  File \"/workspace/axolotl/scripts/finetune.py\", line 273, in <module>\n",
      "    fire.Fire(train)\n",
      "\u001b[0m\u001b[0m  File \"/root/miniconda3/envs/py3.9/lib/python3.9/site-packages/fire/core.py\", line 141, in Fire\n",
      "    component_trace = _Fire(component, args, parsed_flag_args, context, name)\n",
      "\u001b[0m\u001b[0m  File \"/root/miniconda3/envs/py3.9/lib/python3.9/site-packages/fire/core.py\", line 475, in _Fire\n",
      "    component, remaining_args = _CallAndUpdateTrace(\n",
      "\u001b[0m\u001b[0m  File \"/root/miniconda3/envs/py3.9/lib/python3.9/site-packages/fire/core.py\", line 691, in _CallAndUpdateTrace\n",
      "    component = fn(*varargs, **kwargs)\n",
      "\u001b[0m\u001b[0m  File \"/workspace/axolotl/scripts/finetune.py\", line 261, in train\n",
      "    trainer.train(resume_from_checkpoint=resume_from_checkpoint)\n",
      "\u001b[0m\u001b[0m  File \"/root/miniconda3/envs/py3.9/lib/python3.9/site-packages/transformers/trainer.py\", line 1696, in train\n",
      "    return inner_training_loop(\n",
      "\u001b[0m\u001b[0m  File \"/root/miniconda3/envs/py3.9/lib/python3.9/site-packages/transformers/trainer.py\", line 2095, in _inner_training_loop\n",
      "    self._load_best_model()\n",
      "\u001b[0m\u001b[0m  File \"/root/miniconda3/envs/py3.9/lib/python3.9/site-packages/transformers/trainer.py\", line 2292, in _load_best_model\n",
      "    self._issue_warnings_after_load(load_result)\n",
      "\u001b[0m\u001b[0mUnboundLocalError: local variable 'load_result' referenced before assignment\n",
      "\u001b[0m\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[31m(failed 1).\u001b[0m Press Control-C to abort syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               eval/loss ‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            eval/runtime ‚ñÇ‚ñÅ‚ñÇ‚ñà‚ñÉ‚ñÜ‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/samples_per_second ‚ñá‚ñà‚ñá‚ñÅ‚ñÜ‚ñÉ‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   eval/steps_per_second ‚ñÜ‚ñà‚ñá‚ñÅ‚ñÖ‚ñÉ‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             train/epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/global_step ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train/learning_rate ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              train/loss ‚ñÖ‚ñÉ‚ñÅ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÖ‚ñÖ‚ñÉ‚ñÇ‚ñÖ‚ñÖ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÉ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÉ‚ñÜ‚ñÉ‚ñÉ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               eval/loss 0.65581\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            eval/runtime 4.0667\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/samples_per_second 18.443\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   eval/steps_per_second 4.672\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             train/epoch 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/global_step 1850\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train/learning_rate 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              train/loss 1.1168\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run \u001b[33mjolly-bee-2\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/utensil/openllama-qlora-gsm8k/runs/6qux8m6i\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 8 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230530_053900-6qux8m6i/logs\u001b[0m\n",
      "\u001b[0m\u001b[0mTraceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/py3.9/bin/accelerate\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/root/miniconda3/envs/py3.9/lib/python3.9/site-packages/accelerate/commands/accelerate_cli.py\", line 45, in main\n",
      "    args.func(args)\n",
      "  File \"/root/miniconda3/envs/py3.9/lib/python3.9/site-packages/accelerate/commands/launch.py\", line 928, in launch_command\n",
      "    simple_launcher(args)\n",
      "  File \"/root/miniconda3/envs/py3.9/lib/python3.9/site-packages/accelerate/commands/launch.py\", line 588, in simple_launcher\n",
      "    raise subprocess.CalledProcessError(returncode=process.returncode, cmd=cmd)\n",
      "subprocess.CalledProcessError: Command '['/root/miniconda3/envs/py3.9/bin/python3', 'scripts/finetune.py', 'examples/openllama/qlora.yml']' returned non-zero exit status 1.\n"
     ]
    }
   ],
   "source": [
    "!accelerate launch scripts/finetune.py examples/openllama/qlora.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!accelerate launch scripts/finetune.py examples/openllama/qlora.yml"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyP0jHt4WNuLaC5ecmX0YtWl",
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
