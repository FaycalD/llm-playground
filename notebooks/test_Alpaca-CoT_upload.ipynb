{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References:\n",
    "\n",
    "- [Data Persistence](https://huggingface.co/docs/hub/spaces-sdks-docker#data-persistence)\n",
    "- [Create and manage a repository](https://huggingface.co/docs/huggingface_hub/guides/repository)\n",
    "- [Managing local and online repositories](https://huggingface.co/docs/huggingface_hub/v0.13.4/en/package_reference/repository)\n",
    "- [git-lfs tutorial](https://sabicalija.github.io/git-lfs-intro/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/llm-playground\n"
     ]
    }
   ],
   "source": [
    "%cd /workspace/llm-playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "HF_TOKEN = os.environ.get(\"HUGGINGFACE_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/llm-playground/storage is already a clone of https://huggingface.co/datasets/utensil/storage. Make sure you pull the latest changes with `repo.git_pull()`.\n"
     ]
    }
   ],
   "source": [
    "# https://huggingface.co/datasets/utensil/storage\n",
    "repo = Repository(local_dir=\"storage\", clone_from=\"utensil/storage\", repo_type='dataset', skip_lfs_files=True, use_auth_token=HF_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "repo.git_pull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!date --rfc-3339=seconds > storage/time.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-17 17:09:58+00:00\n"
     ]
    }
   ],
   "source": [
    "!cat storage/time.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspaces/llm-playground\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory changed to: /workspace/llm-playground/helper/..\n",
      "/workspace/llm-playground/storage is already a clone of https://huggingface.co/datasets/utensil/storage. Make sure you pull the latest changes with `repo.git_pull()`.\n",
      "To https://huggingface.co/datasets/utensil/storage\n",
      "   febf6ec..74662c3  main -> main\n",
      "\n",
      "Upload succeeded.\n"
     ]
    }
   ],
   "source": [
    "!python helper/upload.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint-117\tcheckpoint-195\tcheckpoint-273\tcheckpoint-351\tcheckpoint-78\n",
      "checkpoint-156\tcheckpoint-234\tcheckpoint-312\tcheckpoint-39\n"
     ]
    }
   ],
   "source": [
    "!ls /workspace/code/saved_models/llama-7b-hf_alpaca/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir -p storage/saved_models/llama-7b-hf_alpaca/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cp -r /workspace/code/saved_models/llama-7b-hf_alpaca/checkpoint-351 storage/saved_models/llama-7b-hf_alpaca/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint-351\n"
     ]
    }
   ],
   "source": [
    "!ls storage/saved_models/llama-7b-hf_alpaca/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 49M\n",
      "drwxr-xr-x 2 root root  160 Apr 17 17:16 .\n",
      "-rw-r--r-- 1 root root  33M Apr 17 17:16 optimizer.pt\n",
      "-rw-r--r-- 1 root root  15K Apr 17 17:16 rng_state.pth\n",
      "-rw-r--r-- 1 root root  557 Apr 17 17:16 scaler.pt\n",
      "-rw-r--r-- 1 root root  627 Apr 17 17:16 scheduler.pt\n",
      "-rw-r--r-- 1 root root 4.2K Apr 17 17:16 trainer_state.json\n",
      "-rw-r--r-- 1 root root  17M Apr 17 17:16 pytorch_model.bin\n",
      "-rw-r--r-- 1 root root 3.5K Apr 17 17:16 training_args.bin\n",
      "drwxr-xr-x 3 root root   28 Apr 17 17:16 ..\n"
     ]
    }
   ],
   "source": [
    "!ls -lhta storage/saved_models/llama-7b-hf_alpaca/checkpoint-351"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory changed to: /workspace/llm-playground/helper/..\n",
      "/workspace/llm-playground/storage is already a clone of https://huggingface.co/datasets/utensil/storage. Make sure you pull the latest changes with `repo.git_pull()`.\n",
      "Upload file saved_models/llama-7b-hf_alpaca/checkpoint-351/optimizer.pt:   0%| |\n",
      "Upload file saved_models/llama-7b-hf_alpaca/checkpoint-351/training_args.bin:   \u001b[A\n",
      "\n",
      "Upload file saved_models/llama-7b-hf_alpaca/checkpoint-351/pytorch_model.bin:   \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Upload file saved_models/llama-7b-hf_alpaca/checkpoint-351/scheduler.pt:   0%| |\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Upload file saved_models/llama-7b-hf_alpaca/checkpoint-351/scaler.pt:   0%| | 1.\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Upload file saved_models/llama-7b-hf_alpaca/checkpoint-351/optimizer.pt:  48%|▍|\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Upload file saved_models/llama-7b-hf_alpaca/checkpoint-351/optimizer.pt:  95%|▉|\u001b[A\u001b[A\n",
      "\n",
      "Upload file saved_models/llama-7b-hf_alpaca/checkpoint-351/optimizer.pt: 45.8MB [00:04, 12.1MB/s]MB/s]\u001b[A\u001b[ATo https://huggingface.co/datasets/utensil/storage\n",
      "   74662c3..68e82e4  main -> main\n",
      "\n",
      "Upload file saved_models/llama-7b-hf_alpaca/checkpoint-351/optimizer.pt: 100%|█|                 \n",
      "\n",
      "Upload file saved_models/llama-7b-hf_alpaca/checkpoint-351/training_args.bin: 10\u001b[A\n",
      "Upload file saved_models/llama-7b-hf_alpaca/checkpoint-351/training_args.bin: 10\u001b[A\n",
      "\n",
      "\n",
      "Upload file saved_models/llama-7b-hf_alpaca/checkpoint-351/pytorch_model.bin: 10                      \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Upload file saved_models/llama-7b-hf_alpaca/checkpoint-351/scheduler.pt: 100%|█|\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Upload file saved_models/llama-7b-hf_alpaca/checkpoint-351/scheduler.pt: 100%|█|\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Upload file saved_models/llama-7b-hf_alpaca/checkpoint-351/scaler.pt: 100%|█| 55\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Upload file saved_models/llama-7b-hf_alpaca/checkpoint-351/scaler.pt: 100%|█| 55\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Upload file saved_models/llama-7b-hf_alpaca/checkpoint-351/rng_state.pth: 100%|█\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Upload file saved_models/llama-7b-hf_alpaca/checkpoint-351/rng_state.pth: 100%|█\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Upload succeeded.\n"
     ]
    }
   ],
   "source": [
    "!python helper/upload.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cp -r /workspace/code/saved_models/llama-7b-hf_alpaca/checkpoint-390 storage/saved_models/llama-7b-hf_alpaca/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 49M\n",
      "drwxr-xr-x 2 root root  160 Apr 17 17:34 .\n",
      "-rw-r--r-- 1 root root  33M Apr 17 17:34 optimizer.pt\n",
      "-rw-r--r-- 1 root root  15K Apr 17 17:34 rng_state.pth\n",
      "-rw-r--r-- 1 root root  557 Apr 17 17:34 scaler.pt\n",
      "-rw-r--r-- 1 root root  627 Apr 17 17:34 scheduler.pt\n",
      "-rw-r--r-- 1 root root 4.7K Apr 17 17:34 trainer_state.json\n",
      "-rw-r--r-- 1 root root  17M Apr 17 17:34 pytorch_model.bin\n",
      "-rw-r--r-- 1 root root 3.5K Apr 17 17:34 training_args.bin\n",
      "drwxr-xr-x 4 root root   50 Apr 17 17:34 ..\n"
     ]
    }
   ],
   "source": [
    "!ls -lhta storage/saved_models/llama-7b-hf_alpaca/checkpoint-390"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cp /workspace/code/saved_models/llama-7b-hf_alpaca/adapter* storage/saved_models/llama-7b-hf_alpaca/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 8.0K\n",
      "drwxr-xr-x 4 root root 102 Apr 17 17:35 .\n",
      "-rw-r--r-- 1 root root 350 Apr 17 17:35 adapter_config.json\n",
      "-rw-r--r-- 1 root root 443 Apr 17 17:35 adapter_model.bin\n",
      "drwxr-xr-x 2 root root 160 Apr 17 17:34 checkpoint-390\n",
      "drwxr-xr-x 2 root root 160 Apr 17 17:16 checkpoint-351\n",
      "drwxr-xr-x 3 root root  32 Apr 17 17:15 ..\n"
     ]
    }
   ],
   "source": [
    "!ls -lhta storage/saved_models/llama-7b-hf_alpaca/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 12K\n",
      "drwxr-xr-x 12 root root 4.0K Apr 17 17:33 .\n",
      "-rw-r--r--  1 root root  350 Apr 17 17:33 adapter_config.json\n",
      "-rw-r--r--  1 root root  443 Apr 17 17:33 adapter_model.bin\n",
      "drwxr-xr-x  2 root root  160 Apr 17 17:33 checkpoint-390\n",
      "drwxr-xr-x  2 root root  160 Apr 17 17:12 checkpoint-351\n",
      "drwxr-xr-x  2 root root  160 Apr 17 16:51 checkpoint-312\n",
      "drwxr-xr-x  2 root root  160 Apr 17 16:30 checkpoint-273\n",
      "drwxr-xr-x  2 root root  160 Apr 17 16:10 checkpoint-234\n",
      "drwxr-xr-x  2 root root  160 Apr 17 15:49 checkpoint-195\n",
      "drwxr-xr-x  2 root root  160 Apr 17 15:28 checkpoint-156\n",
      "drwxr-xr-x  2 root root  160 Apr 17 15:07 checkpoint-117\n",
      "drwxr-xr-x  2 root root  160 Apr 17 14:46 checkpoint-78\n",
      "drwxr-xr-x  2 root root  160 Apr 17 14:25 checkpoint-39\n",
      "drwxr-xr-x  3 root root   32 Apr 17 14:05 ..\n"
     ]
    }
   ],
   "source": [
    "!ls -lhta /workspace/code/saved_models/llama-7b-hf_alpaca/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory changed to: /workspace/llm-playground/helper/..\n",
      "/workspace/llm-playground/storage is already a clone of https://huggingface.co/datasets/utensil/storage. Make sure you pull the latest changes with `repo.git_pull()`.\n",
      "Upload file saved_models/llama-7b-hf_alpaca/checkpoint-390/optimizer.pt:   0%| |\n",
      "Upload file saved_models/llama-7b-hf_alpaca/checkpoint-390/scheduler.pt:   0%| |\u001b[A\n",
      "\n",
      "Upload file saved_models/llama-7b-hf_alpaca/checkpoint-390/scaler.pt:   0%| | 1.\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Upload file saved_models/llama-7b-hf_alpaca/checkpoint-390/pytorch_model.bin:   \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Upload file saved_models/llama-7b-hf_alpaca/checkpoint-390/rng_state.pth:   0%| \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Upload file saved_models/llama-7b-hf_alpaca/checkpoint-390/scaler.pt: 15.3MB [00:01, 16.0MB/s]\u001b[A\u001b[A\n",
      "Upload file saved_models/llama-7b-hf_alpaca/checkpoint-390/scheduler.pt: 15.3MB [00:01, 16.0MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Upload file saved_models/llama-7b-hf_alpaca/checkpoint-390/rng_state.pth: 15.3MB [00:01, 16.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Upload file saved_models/llama-7b-hf_alpaca/checkpoint-390/optimizer.pt:  48%|▍|\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Upload file saved_models/llama-7b-hf_alpaca/checkpoint-390/optimizer.pt: 45.8MB [00:05, 10.3MB/s]MB/s]\u001b[A\u001b[A\u001b[ATo https://huggingface.co/datasets/utensil/storage\n",
      "   68e82e4..3b73be1  main -> main\n",
      "\n",
      "Upload file saved_models/llama-7b-hf_alpaca/checkpoint-390/optimizer.pt: 100%|█|                 \n",
      "\n",
      "Upload file saved_models/llama-7b-hf_alpaca/checkpoint-390/scheduler.pt: 100%|█|                 \u001b[A\n",
      "\n",
      "\n",
      "Upload file saved_models/llama-7b-hf_alpaca/checkpoint-390/scaler.pt: 100%|█| 55              \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Upload file saved_models/llama-7b-hf_alpaca/checkpoint-390/pytorch_model.bin: 10                      \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Upload file saved_models/llama-7b-hf_alpaca/checkpoint-390/rng_state.pth: 100%|█                  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Upload succeeded.\n"
     ]
    }
   ],
   "source": [
    "!python helper/upload.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
