{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/utensil/llm-playground/blob/main/notebooks/text-generation-webui/Colab_LoRA_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LLM text generation notebook for Google Colab\n",
        "\n",
        "This notebook uses https://github.com/utensil/text-generation-webui/tree/dev to train LoRa.\n",
        "\n",
        "Run all the cells and a public gradio URL will appear at the bottom in around 5 minutes.\n",
        "\n",
        "## Parameters\n",
        "\n",
        "* **save_logs_to_google_drive**: saves your chat logs, characters, and softprompts to Google Drive automatically, so that they will persist across sessions.\n",
        "* **text_streaming**: streams the text output in real time instead of waiting for the full response to be completed.\n",
        "* **cai_chat**: makes the interface look like Character.AI. Otherwise, it looks like a standard WhatsApp-like chat.\n",
        "* **load_in_8bit**: loads the model with 8-bit precision, reducing the GPU memory usage by half. This allows you to use the full 2048 prompt length without running out of memory, at a small accuracy and speed cost.\n",
        "* **activate_silero_text_to_speech**: responses will be audios instead of text. There are 118 voices available (`en_0` to `en_117`), which can be set in the \"Extensions\" tab of the interface. You can find samples here: [Silero samples](https://oobabooga.github.io/silero-samples/).\n",
        "* **activate_sending_pictures**: adds a menu for sending pictures to the bot, which are automatically captioned using BLIP.\n",
        "* **activate_character_bias**: an extension that adds an user-defined, hidden string at the beginning of the bot's reply with the goal of biasing the rest of the response.\n",
        "* **chat_language**: if different than English, activates automatic translation using Google Translate, allowing you to communicate with the bot in a different language.\n",
        "\n",
        "## Credits\n",
        "\n",
        "Based on https://colab.research.google.com/github/oobabooga/AI-Notebooks/blob/main/Colab-TextGen-GPU.ipynb from https://github.com/oobabooga/text-generation-webui/wiki/Running-on-Colab.\n"
      ],
      "metadata": {
        "id": "MFQl6-FjSYtY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 1. Keep this tab alive to prevent Colab from disconnecting you { display-mode: \"form\" }\n",
        "\n",
        "#@markdown Press play on the music player that will appear below:\n",
        "%%html\n",
        "<audio src=\"https://oobabooga.github.io/silence.m4a\" controls>"
      ],
      "metadata": {
        "id": "f7TVVj_z4flw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "outputId": "a2689f49-6670-444d-eb14-92e29057e375"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<audio src=\"https://oobabooga.github.io/silence.m4a\" controls>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "!git clone https://github.com/utensil/text-generation-webui\n",
        "!git checkout dev\n",
        "!mkdir text-generation-webui/logs\n",
        "\n",
        "%cd text-generation-webui\n",
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "LGQ8BiMuXMDG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ec2056d-95ca-4521-94ad-a05f4b65a9a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "fatal: destination path 'text-generation-webui' already exists and is not an empty directory.\n",
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "mkdir: cannot create directory ‘text-generation-webui/logs’: File exists\n",
            "/content/text-generation-webui\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/huggingface/transformers (from -r requirements.txt (line 14))\n",
            "  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-jtas1923\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /tmp/pip-req-build-jtas1923\n",
            "  Resolved https://github.com/huggingface/transformers to commit cd73b9a8c140fb74cd93187f5c3d380cfc308023\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: accelerate==0.18.0 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 1)) (0.18.0)\n",
            "Requirement already satisfied: bitsandbytes==0.37.2 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 2)) (0.37.2)\n",
            "Requirement already satisfied: flexgen==0.1.7 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 3)) (0.1.7)\n",
            "Requirement already satisfied: gradio==3.23.0 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 4)) (3.23.0)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 5)) (3.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 6)) (1.22.4)\n",
            "Requirement already satisfied: peft==0.2.0 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 7)) (0.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 8)) (2.27.1)\n",
            "Requirement already satisfied: rwkv==0.7.1 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 9)) (0.7.1)\n",
            "Requirement already satisfied: safetensors==0.3.0 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 10)) (0.3.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 11)) (0.1.97)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 12)) (4.65.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 13)) (2.11.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.9/dist-packages (from accelerate==0.18.0->-r requirements.txt (line 1)) (5.9.4)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.9/dist-packages (from accelerate==0.18.0->-r requirements.txt (line 1)) (6.0)\n",
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.9/dist-packages (from accelerate==0.18.0->-r requirements.txt (line 1)) (1.13.1+cu116)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from accelerate==0.18.0->-r requirements.txt (line 1)) (23.0)\n",
            "Requirement already satisfied: pulp in /usr/local/lib/python3.9/dist-packages (from flexgen==0.1.7->-r requirements.txt (line 3)) (2.7.0)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.9/dist-packages (from flexgen==0.1.7->-r requirements.txt (line 3)) (22.2.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.9/dist-packages (from gradio==3.23.0->-r requirements.txt (line 4)) (0.23.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from gradio==3.23.0->-r requirements.txt (line 4)) (1.4.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from gradio==3.23.0->-r requirements.txt (line 4)) (3.7.1)\n",
            "Requirement already satisfied: orjson in /usr/local/lib/python3.9/dist-packages (from gradio==3.23.0->-r requirements.txt (line 4)) (3.8.9)\n",
            "Requirement already satisfied: semantic-version in /usr/local/lib/python3.9/dist-packages (from gradio==3.23.0->-r requirements.txt (line 4)) (2.10.0)\n",
            "Requirement already satisfied: aiofiles in /usr/local/lib/python3.9/dist-packages (from gradio==3.23.0->-r requirements.txt (line 4)) (23.1.0)\n",
            "Requirement already satisfied: markupsafe in /usr/local/lib/python3.9/dist-packages (from gradio==3.23.0->-r requirements.txt (line 4)) (2.1.2)\n",
            "Requirement already satisfied: mdit-py-plugins<=0.3.3 in /usr/local/lib/python3.9/dist-packages (from gradio==3.23.0->-r requirements.txt (line 4)) (0.3.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from gradio==3.23.0->-r requirements.txt (line 4)) (4.5.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from gradio==3.23.0->-r requirements.txt (line 4)) (3.1.2)\n",
            "Requirement already satisfied: python-multipart in /usr/local/lib/python3.9/dist-packages (from gradio==3.23.0->-r requirements.txt (line 4)) (0.0.6)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.9/dist-packages (from gradio==3.23.0->-r requirements.txt (line 4)) (3.8.4)\n",
            "Requirement already satisfied: altair>=4.2.0 in /usr/local/lib/python3.9/dist-packages (from gradio==3.23.0->-r requirements.txt (line 4)) (4.2.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.9/dist-packages (from gradio==3.23.0->-r requirements.txt (line 4)) (8.4.0)\n",
            "Requirement already satisfied: markdown-it-py[linkify]>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from gradio==3.23.0->-r requirements.txt (line 4)) (2.2.0)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.9/dist-packages (from gradio==3.23.0->-r requirements.txt (line 4)) (1.10.7)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.9/dist-packages (from gradio==3.23.0->-r requirements.txt (line 4)) (0.21.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.9/dist-packages (from gradio==3.23.0->-r requirements.txt (line 4)) (0.13.3)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.9/dist-packages (from gradio==3.23.0->-r requirements.txt (line 4)) (0.95.0)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.9/dist-packages (from gradio==3.23.0->-r requirements.txt (line 4)) (0.3.0)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.9/dist-packages (from gradio==3.23.0->-r requirements.txt (line 4)) (0.25.1)\n",
            "Requirement already satisfied: websockets>=10.0 in /usr/local/lib/python3.9/dist-packages (from gradio==3.23.0->-r requirements.txt (line 4)) (10.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.9/dist-packages (from gradio==3.23.0->-r requirements.txt (line 4)) (2023.3.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.9/dist-packages (from rwkv==0.7.1->-r requirements.txt (line 9)) (0.13.2)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from markdown->-r requirements.txt (line 5)) (6.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->-r requirements.txt (line 8)) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->-r requirements.txt (line 8)) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->-r requirements.txt (line 8)) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->-r requirements.txt (line 8)) (2.0.12)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.9/dist-packages (from datasets->-r requirements.txt (line 13)) (0.70.14)\n",
            "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from datasets->-r requirements.txt (line 13)) (0.3.6)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.9/dist-packages (from datasets->-r requirements.txt (line 13)) (0.18.0)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.9/dist-packages (from datasets->-r requirements.txt (line 13)) (9.0.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.9/dist-packages (from datasets->-r requirements.txt (line 13)) (3.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers==4.28.0.dev0->-r requirements.txt (line 14)) (3.10.7)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers==4.28.0.dev0->-r requirements.txt (line 14)) (2022.10.31)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.9/dist-packages (from altair>=4.2.0->gradio==3.23.0->-r requirements.txt (line 4)) (4.3.3)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.9/dist-packages (from altair>=4.2.0->gradio==3.23.0->-r requirements.txt (line 4)) (0.4)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.9/dist-packages (from altair>=4.2.0->gradio==3.23.0->-r requirements.txt (line 4)) (0.12.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from aiohttp->gradio==3.23.0->-r requirements.txt (line 4)) (1.3.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/dist-packages (from aiohttp->gradio==3.23.0->-r requirements.txt (line 4)) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->gradio==3.23.0->-r requirements.txt (line 4)) (1.8.2)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.9/dist-packages (from aiohttp->gradio==3.23.0->-r requirements.txt (line 4)) (4.0.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from aiohttp->gradio==3.23.0->-r requirements.txt (line 4)) (1.3.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.4->markdown->-r requirements.txt (line 5)) (3.15.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.9/dist-packages (from markdown-it-py[linkify]>=2.0.0->gradio==3.23.0->-r requirements.txt (line 4)) (0.1.2)\n",
            "Requirement already satisfied: linkify-it-py<3,>=1 in /usr/local/lib/python3.9/dist-packages (from markdown-it-py[linkify]>=2.0.0->gradio==3.23.0->-r requirements.txt (line 4)) (2.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->gradio==3.23.0->-r requirements.txt (line 4)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->gradio==3.23.0->-r requirements.txt (line 4)) (2022.7.1)\n",
            "Requirement already satisfied: starlette<0.27.0,>=0.26.1 in /usr/local/lib/python3.9/dist-packages (from fastapi->gradio==3.23.0->-r requirements.txt (line 4)) (0.26.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.9/dist-packages (from httpx->gradio==3.23.0->-r requirements.txt (line 4)) (1.3.0)\n",
            "Requirement already satisfied: rfc3986[idna2008]<2,>=1.3 in /usr/local/lib/python3.9/dist-packages (from httpx->gradio==3.23.0->-r requirements.txt (line 4)) (1.5.0)\n",
            "Requirement already satisfied: httpcore<0.17.0,>=0.15.0 in /usr/local/lib/python3.9/dist-packages (from httpx->gradio==3.23.0->-r requirements.txt (line 4)) (0.16.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->gradio==3.23.0->-r requirements.txt (line 4)) (1.4.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->gradio==3.23.0->-r requirements.txt (line 4)) (1.0.7)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->gradio==3.23.0->-r requirements.txt (line 4)) (4.39.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->gradio==3.23.0->-r requirements.txt (line 4)) (3.0.9)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->gradio==3.23.0->-r requirements.txt (line 4)) (5.12.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib->gradio==3.23.0->-r requirements.txt (line 4)) (0.11.0)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.9/dist-packages (from uvicorn->gradio==3.23.0->-r requirements.txt (line 4)) (0.14.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.9/dist-packages (from uvicorn->gradio==3.23.0->-r requirements.txt (line 4)) (8.1.3)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.9/dist-packages (from httpcore<0.17.0,>=0.15.0->httpx->gradio==3.23.0->-r requirements.txt (line 4)) (3.6.2)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.9/dist-packages (from jsonschema>=3.0->altair>=4.2.0->gradio==3.23.0->-r requirements.txt (line 4)) (0.19.3)\n",
            "Requirement already satisfied: uc-micro-py in /usr/local/lib/python3.9/dist-packages (from linkify-it-py<3,>=1->markdown-it-py[linkify]>=2.0.0->gradio==3.23.0->-r requirements.txt (line 4)) (1.0.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas->gradio==3.23.0->-r requirements.txt (line 4)) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "hKuocueuXnm5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78b78eab-757f-46c7-b30d-f596d03f5027"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "api-example.py\t\t   extensions  prompts\n",
            "api-example-stream.py\t   LICENSE     README.md\n",
            "characters\t\t   logs        requirements.txt\n",
            "convert-to-flexgen.py\t   loras       server.py\n",
            "convert-to-safetensors.py  models      settings-template.json\n",
            "css\t\t\t   modules     softprompts\n",
            "download-model.py\t   presets     training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python download-model.py decapoda-research/llama-7b-hf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ScKs6ZCjKlsx",
        "outputId": "49e3883f-e78e-46a9-ca83-f1e5e7ea1d48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading the model to models/llama-7b-hf\n",
            "Downloading file 1 of 40...\n",
            "100% 8.31k/8.31k [00:00<00:00, 4.68MiB/s]\n",
            "Downloading file 2 of 40...\n",
            "100% 427/427 [00:00<00:00, 422kiB/s]\n",
            "Downloading file 3 of 40...\n",
            "100% 124/124 [00:00<00:00, 120kiB/s]\n",
            "Downloading file 4 of 40...\n",
            "100% 405M/405M [00:04<00:00, 93.7MiB/s]\n",
            "Downloading file 5 of 40...\n",
            "100% 405M/405M [00:05<00:00, 69.4MiB/s]\n",
            "Downloading file 6 of 40...\n",
            "100% 405M/405M [00:04<00:00, 86.2MiB/s]\n",
            "Downloading file 7 of 40...\n",
            "100% 405M/405M [00:04<00:00, 95.0MiB/s]\n",
            "Downloading file 8 of 40...\n",
            "100% 405M/405M [00:06<00:00, 65.4MiB/s]\n",
            "Downloading file 9 of 40...\n",
            "100% 405M/405M [00:04<00:00, 95.9MiB/s]\n",
            "Downloading file 10 of 40...\n",
            "100% 405M/405M [00:04<00:00, 94.3MiB/s]\n",
            "Downloading file 11 of 40...\n",
            "100% 405M/405M [00:05<00:00, 77.3MiB/s]\n",
            "Downloading file 12 of 40...\n",
            "100% 405M/405M [00:04<00:00, 95.5MiB/s]\n",
            "Downloading file 13 of 40...\n",
            "100% 405M/405M [00:06<00:00, 63.3MiB/s]\n",
            "Downloading file 14 of 40...\n",
            "100% 405M/405M [00:04<00:00, 95.3MiB/s]\n",
            "Downloading file 15 of 40...\n",
            "100% 405M/405M [00:04<00:00, 88.1MiB/s]\n",
            "Downloading file 16 of 40...\n",
            "100% 405M/405M [00:04<00:00, 82.2MiB/s]\n",
            "Downloading file 17 of 40...\n",
            "100% 405M/405M [00:04<00:00, 96.3MiB/s]\n",
            "Downloading file 18 of 40...\n",
            "100% 405M/405M [00:05<00:00, 68.1MiB/s]\n",
            "Downloading file 19 of 40...\n",
            "100% 405M/405M [00:04<00:00, 96.8MiB/s]\n",
            "Downloading file 20 of 40...\n",
            "100% 405M/405M [00:04<00:00, 83.8MiB/s]\n",
            "Downloading file 21 of 40...\n",
            "100% 405M/405M [00:04<00:00, 85.5MiB/s]\n",
            "Downloading file 22 of 40...\n",
            "100% 405M/405M [00:04<00:00, 94.8MiB/s]\n",
            "Downloading file 23 of 40...\n",
            "100% 405M/405M [00:06<00:00, 66.4MiB/s]\n",
            "Downloading file 24 of 40...\n",
            "100% 405M/405M [00:04<00:00, 94.6MiB/s]\n",
            "Downloading file 25 of 40...\n",
            "100% 405M/405M [00:05<00:00, 77.4MiB/s]\n",
            "Downloading file 26 of 40...\n",
            "100% 405M/405M [00:04<00:00, 89.8MiB/s]\n",
            "Downloading file 27 of 40...\n",
            "100% 405M/405M [00:04<00:00, 93.3MiB/s]\n",
            "Downloading file 28 of 40...\n",
            "100% 405M/405M [00:05<00:00, 68.5MiB/s]\n",
            "Downloading file 29 of 40...\n",
            "100% 405M/405M [00:04<00:00, 95.2MiB/s]\n",
            "Downloading file 30 of 40...\n",
            "100% 405M/405M [00:05<00:00, 75.3MiB/s]\n",
            "Downloading file 31 of 40...\n",
            "100% 405M/405M [00:04<00:00, 96.6MiB/s]\n",
            "Downloading file 32 of 40...\n",
            "100% 405M/405M [00:04<00:00, 96.2MiB/s]\n",
            "Downloading file 33 of 40...\n",
            "100% 405M/405M [00:05<00:00, 71.0MiB/s]\n",
            "Downloading file 34 of 40...\n",
            "100% 405M/405M [00:04<00:00, 94.4MiB/s]\n",
            "Downloading file 35 of 40...\n",
            "100% 405M/405M [00:05<00:00, 71.8MiB/s]\n",
            "Downloading file 36 of 40...\n",
            "100% 524M/524M [00:05<00:00, 96.9MiB/s]\n",
            "Downloading file 37 of 40...\n",
            "100% 25.5k/25.5k [00:00<00:00, 110kiB/s] \n",
            "Downloading file 38 of 40...\n",
            "100% 2.00/2.00 [00:00<00:00, 1.81kiB/s]\n",
            "Downloading file 39 of 40...\n",
            "100% 500k/500k [00:00<00:00, 44.3MiB/s]\n",
            "Downloading file 40 of 40...\n",
            "100% 141/141 [00:00<00:00, 130kiB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -1 models/**/tokenizer_config.json|xargs sed -i -e 's/LLaMATokenizer/LlamaTokenizer/g'"
      ],
      "metadata": {
        "id": "qZAnKwa_N40Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd training/datasets/\n",
        "!wget https://raw.githubusercontent.com/tloen/alpaca-lora/main/alpaca_data_cleaned.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49mFCTYsO28z",
        "outputId": "0ce72345-b845-4129-e7fe-ccc4da44ab6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/text-generation-webui/training/datasets\n",
            "--2023-03-30 08:02:51--  https://raw.githubusercontent.com/tloen/alpaca-lora/main/alpaca_data_cleaned.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 22680910 (22M) [text/plain]\n",
            "Saving to: ‘alpaca_data_cleaned.json.2’\n",
            "\n",
            "alpaca_data_cleaned 100%[===================>]  21.63M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2023-03-30 08:02:53 (217 MB/s) - ‘alpaca_data_cleaned.json.2’ saved [22680910/22680910]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WnTI_KSOj827",
        "outputId": "12ce1b29-1bb7-4347-d6cd-226105d3e85c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/Colab\\ Notebooks/3b.txt /content/text-generation-webui/training/datasets/"
      ],
      "metadata": {
        "id": "4O5keYD-kOZd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/text-generation-webui/training/datasets"
      ],
      "metadata": {
        "id": "KkVRfcUrk86w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!head /content/text-generation-webui/training/datasets/3b.txt -n 300 | tee /content/text-generation-webui/training/datasets/3b-300.txt"
      ],
      "metadata": {
        "id": "QoeWxLRklbb4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python download-model.py tloen/alpaca-lora-7b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4eUQEA17zMzg",
        "outputId": "79257ee4-56a2-4326-9081-263d779ed1c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading the model to loras/alpaca-lora-7b\n",
            "Downloading file 1 of 3...\n",
            "100% 791/791 [00:00<00:00, 571kiB/s]\n",
            "Downloading file 2 of 3...\n",
            "100% 399/399 [00:00<00:00, 344kiB/s]\n",
            "Downloading file 3 of 3...\n",
            "100% 67.2M/67.2M [00:01<00:00, 64.6MiB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python download-model.py  silk-road/luotuo-lora-7b-1.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V2fkE6zz0UUD",
        "outputId": "8fe34dac-0bbc-4866-9f29-adc4bcbecf7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading the model to loras/luotuo-lora-7b-1.0\n",
            "Downloading file 1 of 3...\n",
            "100% 28.0/28.0 [00:00<00:00, 20.2kiB/s]\n",
            "Downloading file 2 of 3...\n",
            "100% 370/370 [00:00<00:00, 256kiB/s]\n",
            "Downloading file 3 of 3...\n",
            "100% 16.8M/16.8M [00:02<00:00, 6.31MiB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/text-generation-webui\n",
        "!python server.py --model llama-7b-hf --lora luotuo-lora-7b-1.0 --cai-chat --load-in-8bit --share"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6RO6053yPkj",
        "outputId": "90856e19-7db2-4390-f463-cc4460c2a5be"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/text-generation-webui\n",
            "\n",
            "===================================BUG REPORT===================================\n",
            "Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
            "================================================================================\n",
            "/usr/local/lib/python3.9/dist-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: /usr/lib64-nvidia did not contain libcudart.so as expected! Searching further paths...\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.9/dist-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/sys/fs/cgroup/memory.events /var/colab/cgroup/jupyter-children/memory.events')}\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.9/dist-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('--listen_host=172.28.0.12 --target_host=172.28.0.12 --tunnel_background_save_url=https'), PosixPath('//colab.research.google.com/tun/m/cc48301118ce562b961b3c22d803539adc1e0c19/gpu-t4-s-3iqjdg781wur --tunnel_background_save_delay=10s --tunnel_periodic_background_save_frequency=30m0s --enable_output_coalescing=true --output_coalescing_required=true')}\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.9/dist-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/env/python')}\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.9/dist-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('module'), PosixPath('//ipykernel.pylab.backend_inline')}\n",
            "  warn(msg)\n",
            "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching /usr/local/cuda/lib64...\n",
            "CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so\n",
            "CUDA SETUP: Highest compute capability among GPUs detected: 7.5\n",
            "CUDA SETUP: Detected CUDA version 118\n",
            "CUDA SETUP: Loading binary /usr/local/lib/python3.9/dist-packages/bitsandbytes/libbitsandbytes_cuda118.so...\n",
            "2023-03-30 09:30:40.518307: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-30 09:30:40.518454: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-30 09:30:40.518476: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Loading llama-7b-hf...\n",
            "Loading checkpoint shards: 100% 33/33 [01:01<00:00,  1.87s/it]\n",
            "Loaded the model in 65.67 seconds.\n",
            "Adding the LoRA luotuo-lora-7b-1.0 to the model...\n",
            "Loading the extension \"gallery\"... Ok.\n",
            "/usr/local/lib/python3.9/dist-packages/gradio/deprecation.py:40: UserWarning: The 'type' parameter has been deprecated. Use the Number component instead.\n",
            "  warnings.warn(value)\n",
            "Running on local URL:  http://127.0.0.1:7860\n",
            "Running on public URL: https://0e48ac4781a197d41f.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades (NEW!), check out Spaces: https://huggingface.co/spaces\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/generation/utils.py:1211: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
            "  warnings.warn(\n",
            "Output generated in 7.34 seconds (3.13 tokens/s, 23 tokens, context 38)\n",
            "Output generated in 9.28 seconds (4.42 tokens/s, 41 tokens, context 75)\n",
            "Output generated in 18.57 seconds (4.52 tokens/s, 84 tokens, context 135)\n",
            "Output generated in 19.83 seconds (4.79 tokens/s, 95 tokens, context 237)\n",
            "Output generated in 28.13 seconds (4.48 tokens/s, 126 tokens, context 347)\n",
            "Output generated in 45.16 seconds (4.41 tokens/s, 199 tokens, context 688)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/text-generation-webui\n",
        "!python server.py --model llama-7b-hf --lora test --cai-chat --load-in-8bit --share"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bAWDg2pNKuGp",
        "outputId": "93e98ca0-7674-4f81-97c9-a9c7bb4d495e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/text-generation-webui\n",
            "\n",
            "===================================BUG REPORT===================================\n",
            "Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
            "================================================================================\n",
            "/usr/local/lib/python3.9/dist-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: /usr/lib64-nvidia did not contain libcudart.so as expected! Searching further paths...\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.9/dist-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/sys/fs/cgroup/memory.events /var/colab/cgroup/jupyter-children/memory.events')}\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.9/dist-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('--listen_host=172.28.0.12 --target_host=172.28.0.12 --tunnel_background_save_url=https'), PosixPath('//colab.research.google.com/tun/m/cc48301118ce562b961b3c22d803539adc1e0c19/gpu-t4-s-3iqjdg781wur --tunnel_background_save_delay=10s --tunnel_periodic_background_save_frequency=30m0s --enable_output_coalescing=true --output_coalescing_required=true')}\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.9/dist-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/env/python')}\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.9/dist-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('//ipykernel.pylab.backend_inline'), PosixPath('module')}\n",
            "  warn(msg)\n",
            "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching /usr/local/cuda/lib64...\n",
            "CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so\n",
            "CUDA SETUP: Highest compute capability among GPUs detected: 7.5\n",
            "CUDA SETUP: Detected CUDA version 118\n",
            "CUDA SETUP: Loading binary /usr/local/lib/python3.9/dist-packages/bitsandbytes/libbitsandbytes_cuda118.so...\n",
            "2023-03-30 08:53:38.332948: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-30 08:53:38.333322: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-30 08:53:38.333346: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Loading llama-7b-hf...\n",
            "Loading checkpoint shards: 100% 33/33 [01:02<00:00,  1.88s/it]\n",
            "Loaded the model in 64.95 seconds.\n",
            "Adding the LoRA test to the model...\n",
            "/usr/local/lib/python3.9/dist-packages/gradio/deprecation.py:40: UserWarning: The 'type' parameter has been deprecated. Use the Number component instead.\n",
            "  warnings.warn(value)\n",
            "Running on local URL:  http://127.0.0.1:7860\n",
            "Running on public URL: https://d149ad415811cdf4fe.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades (NEW!), check out Spaces: https://huggingface.co/spaces\n",
            "Closing server running on port: 7860\n",
            "/usr/local/lib/python3.9/dist-packages/gradio/deprecation.py:40: UserWarning: The 'type' parameter has been deprecated. Use the Number component instead.\n",
            "  warnings.warn(value)\n",
            "Running on local URL:  http://127.0.0.1:7860\n",
            "Running on public URL: https://737335d9ab1314cadb.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades (NEW!), check out Spaces: https://huggingface.co/spaces\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/generation/utils.py:1211: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
            "  warnings.warn(\n",
            "Output generated in 31.28 seconds (4.32 tokens/s, 135 tokens, context 38)\n",
            "Output generated in 9.50 seconds (3.69 tokens/s, 35 tokens, context 192)\n",
            "Output generated in 4.68 seconds (4.70 tokens/s, 22 tokens, context 252)\n",
            "Output generated in 6.77 seconds (4.73 tokens/s, 32 tokens, context 297)\n",
            "Output generated in 7.18 seconds (4.74 tokens/s, 34 tokens, context 374)\n",
            "Output generated in 48.05 seconds (4.14 tokens/s, 199 tokens, context 427)\n",
            "Error in sys.excepthook:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/rich/traceback.py\", line 97, in excepthook\n",
            "    def excepthook(\n",
            "KeyboardInterrupt\n",
            "\n",
            "Original exception was:\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/text-generation-webui/server.py\", line 521, in <module>\n",
            "    time.sleep(0.5)\n",
            "KeyboardInterrupt\n",
            "Killing tunnel 127.0.0.1:7860 <> https://737335d9ab1314cadb.gradio.live\n",
            "Killing tunnel 127.0.0.1:7860 <> https://d149ad415811cdf4fe.gradio.live\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls loras"
      ],
      "metadata": {
        "id": "s_nwetSWOV3O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22e30ee6-0156-4067-aebc-7f0e0882650f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "place-your-loras-here.txt  test\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OvT7iiD1pQbn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}